{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SymbolAlreadyExposedError",
     "evalue": "Symbol Zeros is already exposed as ().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSymbolAlreadyExposedError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yassinebouaine/code/Yassinoko/dynamic-players-insights/ml_models/model_yassine.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yassinebouaine/code/Yassinoko/dynamic-players-insights/ml_models/model_yassine.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Importing pre-trained model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yassinebouaine/code/Yassinoko/dynamic-players-insights/ml_models/model_yassine.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m ResNet50V2\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m __internal__\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/__internal__/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m losses\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/__internal__/backend/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m _initialize_variables \u001b[39mas\u001b[39;00m initialize_variables\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m track_variable\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/__init__.py:21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/applications/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvnext\u001b[39;00m \u001b[39mimport\u001b[39;00m ConvNeXtBase\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvnext\u001b[39;00m \u001b[39mimport\u001b[39;00m ConvNeXtLarge\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvnext\u001b[39;00m \u001b[39mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/applications/convnext.py:26\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m\"\"\"ConvNeXt models for Keras.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[39mReferences:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m  (CVPR 2022)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/tensorflow/__init__.py:469\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_current_module, \u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    468\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     _keras\u001b[39m.\u001b[39;49m_load()\n\u001b[1;32m    470\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/api/_v2/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_v2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m __internal__\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_v2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_v2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/api/_v2/keras/__internal__/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_v2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_v2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_v2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m losses\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/api/_v2/keras/__internal__/backend/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m _initialize_variables \u001b[39mas\u001b[39;00m initialize_variables\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m track_variable\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/backend.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute_coordinator_utils \u001b[39mas\u001b[39;00m dc\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m dtensor_api \u001b[39mas\u001b[39;00m dtensor\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m control_flow_util\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m object_identity\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/engine/keras_tensor.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m object_identity\n\u001b[1;32m     21\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m structure\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/utils/__init__.py:20\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Public Keras utilities.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[39m# Serialization related\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserialization_lib\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserialization_lib\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize_keras_object\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mobject_registration\u001b[39;00m \u001b[39mimport\u001b[39;00m CustomObjectScope\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m object_registration\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization \u001b[39mas\u001b[39;00m legacy_serialization\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m in_tf_saved_model_scope\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m generic_utils\n\u001b[1;32m     31\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/saving/legacy/saved_model/utils.py:30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_contextlib\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayer_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m CallFunctionSpec\n\u001b[1;32m     32\u001b[0m training_lib \u001b[39m=\u001b[39m LazyLoader(\u001b[39m\"\u001b[39m\u001b[39mtraining_lib\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mglobals\u001b[39m(), \u001b[39m\"\u001b[39m\u001b[39mkeras.src.engine.training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39muse_wrapped_call\u001b[39m(\n\u001b[1;32m     36\u001b[0m     layer, call_fn, call_spec, default_training_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, return_method\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     37\u001b[0m ):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/utils/layer_utils.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m io_utils\n\u001b[1;32m     29\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/initializers/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minitializers\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minitializers\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers_v1\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization_lib\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization \u001b[39mas\u001b[39;00m legacy_serialization\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/src/initializers/initializers_v1.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m _v1_glorot_uniform_initializer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mglorot_uniform_initializer\n\u001b[1;32m     30\u001b[0m _v1_glorot_normal_initializer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mglorot_normal_initializer\n\u001b[0;32m---> 32\u001b[0m keras_export(v1\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mkeras.initializers.Zeros\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mkeras.initializers.zeros\u001b[39;49m\u001b[39m\"\u001b[39;49m])(\n\u001b[1;32m     33\u001b[0m     _v1_zeros_initializer\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m keras_export(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.Ones\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.ones\u001b[39m\u001b[39m\"\u001b[39m])(\n\u001b[1;32m     36\u001b[0m     _v1_ones_initializer\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m keras_export(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.Constant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkeras.initializers.constant\u001b[39m\u001b[39m\"\u001b[39m])(\n\u001b[1;32m     39\u001b[0m     _v1_constant_initializer\n\u001b[1;32m     40\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py:348\u001b[0m, in \u001b[0;36mapi_export.__call__\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[39mdelattr\u001b[39m(undecorated_f, api_names_attr_v1)\n\u001b[1;32m    347\u001b[0m _, undecorated_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(func)\n\u001b[0;32m--> 348\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_attr(undecorated_func, api_names_attr, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_names)\n\u001b[1;32m    349\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_attr(undecorated_func, api_names_attr_v1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_names_v1)\n\u001b[1;32m    351\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_names:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py:363\u001b[0m, in \u001b[0;36mapi_export.set_attr\u001b[0;34m(self, func, api_names_attr, names)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m api_names_attr \u001b[39min\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m    362\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_multiple_exports:\n\u001b[0;32m--> 363\u001b[0m     \u001b[39mraise\u001b[39;00m SymbolAlreadyExposedError(\n\u001b[1;32m    364\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mSymbol \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is already exposed as \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    365\u001b[0m         (func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mgetattr\u001b[39m(func, api_names_attr)))  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39msetattr\u001b[39m(func, api_names_attr, names)\n",
      "\u001b[0;31mSymbolAlreadyExposedError\u001b[0m: Symbol Zeros is already exposed as ()."
     ]
    }
   ],
   "source": [
    "# Importing pre-trained model\n",
    "from keras.applications import ResNet50V2\n",
    "\n",
    "# Importing important layers of Keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Importing data functions\n",
    "from data_library.data_processing import black_white, crop, delete_face_images, encode, to_cat\n",
    "\n",
    "# Importing preprocessing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Saving the model in a variable\n",
    "resnet = ResNet50V2(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Classes from Real Madrid (cropped_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_folder = \"../data_processing/raw_data/faces/\"\n",
    "cropped_faces_directory = \"../data_processing/raw_data/cropped_faces\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RUN ONLY IF YOU DONT HAVE THE CROPPED FACES YET\n",
    "# black_white(faces_folder)\n",
    "# crop(faces_folder, cropped_faces_directory)\n",
    "# delete_face_images(cropped_faces_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = encode(cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 13:07:30.926190: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 228ms/step - loss: 2.3318 - accuracy: 0.2756 - val_loss: 40.7103 - val_accuracy: 0.1250\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 175ms/step - loss: 1.5321 - accuracy: 0.5256 - val_loss: 18.2984 - val_accuracy: 0.1250\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 1.1933 - accuracy: 0.6474 - val_loss: 11.1928 - val_accuracy: 0.1250\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.9986 - accuracy: 0.7500 - val_loss: 7.7443 - val_accuracy: 0.1250\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.5227 - accuracy: 0.8590 - val_loss: 6.5362 - val_accuracy: 0.2250\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 0.3563 - accuracy: 0.8974 - val_loss: 4.0324 - val_accuracy: 0.3000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.3021 - accuracy: 0.9167 - val_loss: 3.2774 - val_accuracy: 0.3250\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 203ms/step - loss: 0.1258 - accuracy: 0.9744 - val_loss: 2.8376 - val_accuracy: 0.3750\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 220ms/step - loss: 0.0858 - accuracy: 0.9872 - val_loss: 1.9281 - val_accuracy: 0.5500\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 217ms/step - loss: 0.0767 - accuracy: 0.9808 - val_loss: 2.6420 - val_accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ceaddbd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 58ms/step - loss: 3.6748 - accuracy: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.6748368740081787, 0.5714285969734192]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 721.4812 - accuracy: 0.0918\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 444.1785 - accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 153.8839 - accuracy: 0.1071\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 81.5715 - accuracy: 0.0867\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 29.0779 - accuracy: 0.1480\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 16.8208 - accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 9.2770 - accuracy: 0.1735\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 5.8155 - accuracy: 0.1531\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 4.1523 - accuracy: 0.1480\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 3.7298 - accuracy: 0.1173\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 3.8036 - accuracy: 0.1327\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 3.4150 - accuracy: 0.1276\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.7737 - accuracy: 0.1327\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.8305 - accuracy: 0.1531\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.5986 - accuracy: 0.1735\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.8562 - accuracy: 0.1327\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.4788 - accuracy: 0.1633\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.5368 - accuracy: 0.1888\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.4460 - accuracy: 0.1939\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 3.0444 - accuracy: 0.1378\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.6614 - accuracy: 0.1633\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.5116 - accuracy: 0.1939\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.4197 - accuracy: 0.1990\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.5055 - accuracy: 0.1939\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.5035 - accuracy: 0.1837\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3958 - accuracy: 0.1684\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.5281 - accuracy: 0.1786\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.5348 - accuracy: 0.1582\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2267 - accuracy: 0.1939\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.5043 - accuracy: 0.1378\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2831 - accuracy: 0.1786\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3002 - accuracy: 0.1735\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.3920 - accuracy: 0.2194\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2588 - accuracy: 0.2092\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3266 - accuracy: 0.1837\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2100 - accuracy: 0.1939\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2166 - accuracy: 0.1888\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3298 - accuracy: 0.2245\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2108 - accuracy: 0.2143\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1953 - accuracy: 0.1735\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2603 - accuracy: 0.1735\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2859 - accuracy: 0.2092\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2789 - accuracy: 0.1684\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3038 - accuracy: 0.1327\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2528 - accuracy: 0.2347\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.3132 - accuracy: 0.1990\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3205 - accuracy: 0.2092\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3951 - accuracy: 0.1990\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1745 - accuracy: 0.2500\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3674 - accuracy: 0.1990\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2836 - accuracy: 0.1735\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2255 - accuracy: 0.2347\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2209 - accuracy: 0.2449\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.1162 - accuracy: 0.2449\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1604 - accuracy: 0.2449\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1885 - accuracy: 0.2092\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2013 - accuracy: 0.2245\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3984 - accuracy: 0.1837\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1288 - accuracy: 0.2347\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.3016 - accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1962 - accuracy: 0.2143\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2243 - accuracy: 0.2347\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1875 - accuracy: 0.1939\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2709 - accuracy: 0.1735\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.1917 - accuracy: 0.2296\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2520 - accuracy: 0.2398\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2305 - accuracy: 0.1939\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1928 - accuracy: 0.2347\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1576 - accuracy: 0.2041\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1451 - accuracy: 0.2755\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1766 - accuracy: 0.2194\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2229 - accuracy: 0.2143\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0732 - accuracy: 0.2704\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.1526 - accuracy: 0.2398\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0874 - accuracy: 0.2347\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0913 - accuracy: 0.2296\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.1191 - accuracy: 0.2245\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1380 - accuracy: 0.2041\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1279 - accuracy: 0.2296\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.0135 - accuracy: 0.2551\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0621 - accuracy: 0.2704\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1516 - accuracy: 0.2092\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0207 - accuracy: 0.2857\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0764 - accuracy: 0.2296\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.1763 - accuracy: 0.2296\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0722 - accuracy: 0.2551\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1293 - accuracy: 0.2908\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1506 - accuracy: 0.2194\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0754 - accuracy: 0.2602\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0419 - accuracy: 0.2755\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2491 - accuracy: 0.2296\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0159 - accuracy: 0.2806\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0508 - accuracy: 0.2500\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0689 - accuracy: 0.2602\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1007 - accuracy: 0.2602\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0964 - accuracy: 0.1990\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0937 - accuracy: 0.2296\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.1069 - accuracy: 0.2194\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.9643 - accuracy: 0.3061\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0567 - accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cea283d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_2 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_2.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1795 - accuracy: 0.2857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1795172691345215, 0.2857142984867096]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 180.3172 - accuracy: 0.0714\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 8.8773 - accuracy: 0.0969\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.8235 - accuracy: 0.1531\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.3463 - accuracy: 0.1020\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3244 - accuracy: 0.0867\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2962 - accuracy: 0.1327\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2856 - accuracy: 0.1173\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3175 - accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3045 - accuracy: 0.1122\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3059 - accuracy: 0.1327\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.3095 - accuracy: 0.0867\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3367 - accuracy: 0.1531\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2952 - accuracy: 0.1071\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3062 - accuracy: 0.0765\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3130 - accuracy: 0.0969\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2990 - accuracy: 0.1276\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3230 - accuracy: 0.0714\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2958 - accuracy: 0.1071\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.3160 - accuracy: 0.1122\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.3229 - accuracy: 0.1071\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2915 - accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.3024 - accuracy: 0.1020\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3033 - accuracy: 0.1276\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3024 - accuracy: 0.0867\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2989 - accuracy: 0.1378\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2928 - accuracy: 0.1276\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2982 - accuracy: 0.1224\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2802 - accuracy: 0.1276\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2913 - accuracy: 0.1327\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 2.2926 - accuracy: 0.1122\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2856 - accuracy: 0.1531\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3585 - accuracy: 0.1480\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2951 - accuracy: 0.1378\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2937 - accuracy: 0.1020\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.2996 - accuracy: 0.1224\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2930 - accuracy: 0.1327\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3394 - accuracy: 0.1224\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3023 - accuracy: 0.1122\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2990 - accuracy: 0.1071\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2923 - accuracy: 0.1122\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3058 - accuracy: 0.1122\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2996 - accuracy: 0.1173\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2977 - accuracy: 0.1173\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.2983 - accuracy: 0.1173\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.2976 - accuracy: 0.1071\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3010 - accuracy: 0.1071\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.2983 - accuracy: 0.1122\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2991 - accuracy: 0.1122\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2945 - accuracy: 0.1173\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2923 - accuracy: 0.1173\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2891 - accuracy: 0.1276\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2969 - accuracy: 0.1327\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3166 - accuracy: 0.1020\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2957 - accuracy: 0.1173\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2987 - accuracy: 0.1071\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2957 - accuracy: 0.1224\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2864 - accuracy: 0.1327\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3030 - accuracy: 0.1173\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2946 - accuracy: 0.1020\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2891 - accuracy: 0.1327\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2954 - accuracy: 0.1071\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2696 - accuracy: 0.1173\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2853 - accuracy: 0.1122\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3123 - accuracy: 0.1224\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3009 - accuracy: 0.0969\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3029 - accuracy: 0.1327\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2980 - accuracy: 0.1071\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2912 - accuracy: 0.0918\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2906 - accuracy: 0.1122\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2946 - accuracy: 0.1173\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3233 - accuracy: 0.1378\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2991 - accuracy: 0.0867\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2978 - accuracy: 0.1173\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2972 - accuracy: 0.1276\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2978 - accuracy: 0.1071\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2970 - accuracy: 0.0969\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2973 - accuracy: 0.0918\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.2944 - accuracy: 0.1378\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2957 - accuracy: 0.1224\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2972 - accuracy: 0.0867\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2973 - accuracy: 0.1276\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2953 - accuracy: 0.1122\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2977 - accuracy: 0.0816\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2964 - accuracy: 0.1276\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2989 - accuracy: 0.0918\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2941 - accuracy: 0.1480\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2970 - accuracy: 0.1122\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2956 - accuracy: 0.1173\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 2.2969 - accuracy: 0.0714\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2965 - accuracy: 0.0867\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2949 - accuracy: 0.1173\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2967 - accuracy: 0.1122\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2934 - accuracy: 0.1071\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2989 - accuracy: 0.1224\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2952 - accuracy: 0.1276\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2952 - accuracy: 0.1020\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2965 - accuracy: 0.1122\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.2949 - accuracy: 0.1071\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2966 - accuracy: 0.1327\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2969 - accuracy: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d3473880>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_3 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_3.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2999 - accuracy: 0.0612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.299858808517456, 0.06122449040412903]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 24ms/step - loss: 29.1012 - accuracy: 0.0867 - val_loss: 7.8460 - val_accuracy: 0.0612 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 7.2830 - accuracy: 0.1276 - val_loss: 6.8762 - val_accuracy: 0.0612 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 6.7763 - accuracy: 0.1122 - val_loss: 6.6517 - val_accuracy: 0.1429 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.5523 - accuracy: 0.1276 - val_loss: 6.5493 - val_accuracy: 0.0816 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.4302 - accuracy: 0.1224 - val_loss: 6.3743 - val_accuracy: 0.1224 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 6.3092 - accuracy: 0.1173 - val_loss: 6.2687 - val_accuracy: 0.0612 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.1862 - accuracy: 0.1429 - val_loss: 6.1693 - val_accuracy: 0.1633 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.0942 - accuracy: 0.1071 - val_loss: 6.0593 - val_accuracy: 0.1633 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 6.0370 - accuracy: 0.1122 - val_loss: 5.9588 - val_accuracy: 0.1429 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.9246 - accuracy: 0.1378 - val_loss: 5.8886 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.8337 - accuracy: 0.1020 - val_loss: 5.8233 - val_accuracy: 0.1633 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.7823 - accuracy: 0.1276 - val_loss: 5.7184 - val_accuracy: 0.1224 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.6786 - accuracy: 0.1122 - val_loss: 5.6712 - val_accuracy: 0.1224 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.6318 - accuracy: 0.1071 - val_loss: 5.6023 - val_accuracy: 0.1224 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.5540 - accuracy: 0.1582 - val_loss: 5.5162 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.4908 - accuracy: 0.1531 - val_loss: 5.4539 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.4264 - accuracy: 0.1378 - val_loss: 5.4188 - val_accuracy: 0.1837 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.3870 - accuracy: 0.1480 - val_loss: 5.3870 - val_accuracy: 0.1224 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.3331 - accuracy: 0.1429 - val_loss: 5.3221 - val_accuracy: 0.0816 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.2787 - accuracy: 0.1327 - val_loss: 5.2589 - val_accuracy: 0.1837 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.2172 - accuracy: 0.1633 - val_loss: 5.1990 - val_accuracy: 0.2449 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.1395 - accuracy: 0.1888 - val_loss: 5.1795 - val_accuracy: 0.0612 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.0962 - accuracy: 0.1684 - val_loss: 5.1262 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 5.0516 - accuracy: 0.1735 - val_loss: 5.0674 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.0150 - accuracy: 0.1276 - val_loss: 4.9870 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.9386 - accuracy: 0.1633 - val_loss: 4.9564 - val_accuracy: 0.1837 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.9357 - accuracy: 0.1531 - val_loss: 4.8038 - val_accuracy: 0.3061 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.9004 - accuracy: 0.1276 - val_loss: 4.9154 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.7975 - accuracy: 0.1684 - val_loss: 4.7946 - val_accuracy: 0.3265 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.8025 - accuracy: 0.1633 - val_loss: 4.7892 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.8627 - accuracy: 0.1378 - val_loss: 4.7598 - val_accuracy: 0.1837 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.7149 - accuracy: 0.1888 - val_loss: 4.7486 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.7216 - accuracy: 0.1071 - val_loss: 4.7182 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.6789 - accuracy: 0.1531 - val_loss: 4.6715 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 4.5479 - accuracy: 0.2245 - val_loss: 4.5890 - val_accuracy: 0.2449 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.5599 - accuracy: 0.2398 - val_loss: 4.6051 - val_accuracy: 0.1837 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.4972 - accuracy: 0.2143 - val_loss: 4.5484 - val_accuracy: 0.2245 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 4.5386 - accuracy: 0.1684 - val_loss: 4.4999 - val_accuracy: 0.3061 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.4462 - accuracy: 0.2143 - val_loss: 4.4362 - val_accuracy: 0.2653 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.4073 - accuracy: 0.2092 - val_loss: 4.3225 - val_accuracy: 0.3265 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.2968 - accuracy: 0.1939 - val_loss: 4.2335 - val_accuracy: 0.3265 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.2167 - accuracy: 0.2347 - val_loss: 4.1907 - val_accuracy: 0.2449 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.2149 - accuracy: 0.2347 - val_loss: 4.2673 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.2116 - accuracy: 0.2041 - val_loss: 4.1604 - val_accuracy: 0.2449 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.1717 - accuracy: 0.2500 - val_loss: 4.1412 - val_accuracy: 0.3469 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.1529 - accuracy: 0.2296 - val_loss: 3.8735 - val_accuracy: 0.4286 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.0670 - accuracy: 0.2551 - val_loss: 3.9101 - val_accuracy: 0.4082 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.1014 - accuracy: 0.2449 - val_loss: 3.9610 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.0182 - accuracy: 0.2602 - val_loss: 3.9525 - val_accuracy: 0.3469 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.9639 - accuracy: 0.3010 - val_loss: 3.9062 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.8470 - accuracy: 0.2959 - val_loss: 3.8509 - val_accuracy: 0.3469 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.8516 - accuracy: 0.3265 - val_loss: 3.9160 - val_accuracy: 0.3061 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.8562 - accuracy: 0.3010 - val_loss: 3.8094 - val_accuracy: 0.4082 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.8277 - accuracy: 0.3316 - val_loss: 3.7889 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7826 - accuracy: 0.3418 - val_loss: 3.8023 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.7830 - accuracy: 0.3061 - val_loss: 3.8671 - val_accuracy: 0.3265 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.8103 - accuracy: 0.2755 - val_loss: 3.7319 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7530 - accuracy: 0.3520 - val_loss: 3.7586 - val_accuracy: 0.3469 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.7600 - accuracy: 0.3214 - val_loss: 3.6914 - val_accuracy: 0.3469 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.7060 - accuracy: 0.3827 - val_loss: 3.7424 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.8173 - accuracy: 0.2806 - val_loss: 3.6730 - val_accuracy: 0.3673 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7205 - accuracy: 0.3776 - val_loss: 3.6836 - val_accuracy: 0.3673 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.6359 - accuracy: 0.3520 - val_loss: 3.6545 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.7599 - accuracy: 0.3469 - val_loss: 3.6480 - val_accuracy: 0.4082 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.6077 - accuracy: 0.4082 - val_loss: 3.6002 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.5768 - accuracy: 0.4082 - val_loss: 3.5795 - val_accuracy: 0.4694 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.5282 - accuracy: 0.4184 - val_loss: 3.5886 - val_accuracy: 0.4694 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.5514 - accuracy: 0.3929 - val_loss: 3.7401 - val_accuracy: 0.4082 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.5856 - accuracy: 0.3724 - val_loss: 3.5456 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.6042 - accuracy: 0.3520 - val_loss: 3.6223 - val_accuracy: 0.4490 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.5825 - accuracy: 0.4031 - val_loss: 3.6887 - val_accuracy: 0.4490 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.6567 - accuracy: 0.4133 - val_loss: 3.4937 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.4661 - accuracy: 0.4592 - val_loss: 3.7349 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.5271 - accuracy: 0.4184 - val_loss: 3.4987 - val_accuracy: 0.4286 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.4051 - accuracy: 0.4388 - val_loss: 3.6444 - val_accuracy: 0.4694 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 3.5064 - accuracy: 0.4439 - val_loss: 3.5747 - val_accuracy: 0.4898 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.4846 - accuracy: 0.4286 - val_loss: 3.5522 - val_accuracy: 0.4898 - lr: 1.0000e-05\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.4937 - accuracy: 0.3878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.493682861328125, 0.3877550959587097]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_4.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_4.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_4.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "model_4.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 84ms/step - loss: 3.7428 - accuracy: 0.0765 - val_loss: 9.2981 - val_accuracy: 0.1224\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.4164 - accuracy: 0.0918 - val_loss: 7.7855 - val_accuracy: 0.1020\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.2929 - accuracy: 0.1224 - val_loss: 8.5709 - val_accuracy: 0.1429\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.9323 - accuracy: 0.1582 - val_loss: 8.2315 - val_accuracy: 0.1020\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.4078 - accuracy: 0.1378 - val_loss: 9.7438 - val_accuracy: 0.0408\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.0643 - accuracy: 0.1837 - val_loss: 9.9507 - val_accuracy: 0.0204\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.1997 - accuracy: 0.1888 - val_loss: 6.0693 - val_accuracy: 0.1020\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 3.0243 - accuracy: 0.1786 - val_loss: 4.4371 - val_accuracy: 0.1837\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.2961 - accuracy: 0.2092 - val_loss: 4.9352 - val_accuracy: 0.1429\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.8398 - accuracy: 0.2551 - val_loss: 5.6463 - val_accuracy: 0.1429\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.8036 - accuracy: 0.2245 - val_loss: 4.5840 - val_accuracy: 0.1020\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.8664 - accuracy: 0.2245 - val_loss: 3.8279 - val_accuracy: 0.1224\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.8397 - accuracy: 0.2449 - val_loss: 3.2550 - val_accuracy: 0.1224\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.9230 - accuracy: 0.2092 - val_loss: 3.1120 - val_accuracy: 0.0612\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.8059 - accuracy: 0.2296 - val_loss: 2.9207 - val_accuracy: 0.1020\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.6625 - accuracy: 0.2449 - val_loss: 2.9372 - val_accuracy: 0.2245\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.6783 - accuracy: 0.2908 - val_loss: 3.2804 - val_accuracy: 0.1429\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.5532 - accuracy: 0.2347 - val_loss: 2.7098 - val_accuracy: 0.1837\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.7929 - accuracy: 0.2245 - val_loss: 2.6012 - val_accuracy: 0.1429\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.6066 - accuracy: 0.2551 - val_loss: 2.7799 - val_accuracy: 0.0816\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.7650 - accuracy: 0.2041 - val_loss: 3.0845 - val_accuracy: 0.0612\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.7038 - accuracy: 0.2704 - val_loss: 3.7469 - val_accuracy: 0.0204\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.8266 - accuracy: 0.1786 - val_loss: 3.7555 - val_accuracy: 0.0612\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.5541 - accuracy: 0.2449 - val_loss: 3.0246 - val_accuracy: 0.0816\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.6488 - accuracy: 0.2908 - val_loss: 3.0759 - val_accuracy: 0.1224\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.5838 - accuracy: 0.2143 - val_loss: 3.0544 - val_accuracy: 0.1224\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.3217 - accuracy: 0.2602 - val_loss: 2.7654 - val_accuracy: 0.2041\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.5106 - accuracy: 0.2449 - val_loss: 2.4055 - val_accuracy: 0.2653\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.4054 - accuracy: 0.2653 - val_loss: 2.6402 - val_accuracy: 0.1633\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.6713 - accuracy: 0.2653 - val_loss: 2.5378 - val_accuracy: 0.1837\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.5876 - accuracy: 0.2500 - val_loss: 2.3511 - val_accuracy: 0.2245\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.3759 - accuracy: 0.2602 - val_loss: 2.4480 - val_accuracy: 0.2449\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.3742 - accuracy: 0.2500 - val_loss: 2.5037 - val_accuracy: 0.2857\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.4907 - accuracy: 0.2755 - val_loss: 2.3979 - val_accuracy: 0.3061\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.2450 - accuracy: 0.3061 - val_loss: 2.4423 - val_accuracy: 0.3061\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.4073 - accuracy: 0.2857 - val_loss: 2.5715 - val_accuracy: 0.2245\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.4673 - accuracy: 0.3316 - val_loss: 2.3022 - val_accuracy: 0.3265\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.2467 - accuracy: 0.2908 - val_loss: 2.5179 - val_accuracy: 0.1837\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.2632 - accuracy: 0.2755 - val_loss: 3.0175 - val_accuracy: 0.1633\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.4478 - accuracy: 0.2959 - val_loss: 3.7713 - val_accuracy: 0.1633\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.5357 - accuracy: 0.2500 - val_loss: 2.2439 - val_accuracy: 0.2041\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.2729 - accuracy: 0.2908 - val_loss: 2.0994 - val_accuracy: 0.2653\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.2636 - accuracy: 0.3061 - val_loss: 2.0360 - val_accuracy: 0.3061\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.3059 - accuracy: 0.3112 - val_loss: 1.8966 - val_accuracy: 0.3061\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.1358 - accuracy: 0.3418 - val_loss: 1.8824 - val_accuracy: 0.3469\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.2901 - accuracy: 0.2449 - val_loss: 1.9751 - val_accuracy: 0.2449\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.3444 - accuracy: 0.2551 - val_loss: 1.9761 - val_accuracy: 0.2245\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.1572 - accuracy: 0.3010 - val_loss: 1.9276 - val_accuracy: 0.3265\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.1416 - accuracy: 0.3163 - val_loss: 1.8874 - val_accuracy: 0.3265\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.9622 - accuracy: 0.3469 - val_loss: 1.8761 - val_accuracy: 0.3469\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.2101 - accuracy: 0.2959 - val_loss: 1.8532 - val_accuracy: 0.3469\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.9658 - accuracy: 0.3316 - val_loss: 1.8513 - val_accuracy: 0.3673\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.1413 - accuracy: 0.3010 - val_loss: 2.0059 - val_accuracy: 0.2857\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.1544 - accuracy: 0.3265 - val_loss: 1.9734 - val_accuracy: 0.3265\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.3013 - accuracy: 0.3010 - val_loss: 1.8896 - val_accuracy: 0.2857\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.1576 - accuracy: 0.2908 - val_loss: 1.9013 - val_accuracy: 0.3061\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.1442 - accuracy: 0.3112 - val_loss: 2.3624 - val_accuracy: 0.2041\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.2225 - accuracy: 0.3214 - val_loss: 2.4800 - val_accuracy: 0.1633\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.1808 - accuracy: 0.3010 - val_loss: 2.2350 - val_accuracy: 0.2245\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.0284 - accuracy: 0.3469 - val_loss: 2.0924 - val_accuracy: 0.2653\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.0439 - accuracy: 0.3163 - val_loss: 1.9076 - val_accuracy: 0.3265\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.1730 - accuracy: 0.2806 - val_loss: 2.0124 - val_accuracy: 0.3265\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8513 - accuracy: 0.3673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.851344347000122, 0.36734694242477417]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_5 = Sequential()\n",
    "model_5.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_5.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(256))\n",
    "model_5.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(128))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "model_5.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_5.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_5.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "model_5.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video - 10 Classes (video_cropped_faces_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_cropped_faces_directory = \"../data_processing/raw_data/video_cropped_faces_0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = encode(video_cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 297ms/step - loss: 1.9391 - accuracy: 0.4000 - val_loss: 2.3818 - val_accuracy: 0.6923\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.9425 - accuracy: 0.7200 - val_loss: 16.2346 - val_accuracy: 0.4615\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.9125 - accuracy: 0.8600 - val_loss: 12.6295 - val_accuracy: 0.4615\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.4429 - accuracy: 0.9600 - val_loss: 33.6319 - val_accuracy: 0.1538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x32378cbe0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model_6 = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_6.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_6.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 3.6977 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.6977198123931885, 0.5]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 353.8517 - accuracy: 0.0952\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 988.5944 - accuracy: 0.2063\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 659.9906 - accuracy: 0.1111\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 465.5725 - accuracy: 0.1111\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 463.4159 - accuracy: 0.0794\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 388.7559 - accuracy: 0.2222\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 293.9539 - accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 213.7339 - accuracy: 0.0635\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 146.0322 - accuracy: 0.1746\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 113.4483 - accuracy: 0.1905\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 84.2166 - accuracy: 0.2222\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 62.8275 - accuracy: 0.2698\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 43.1458 - accuracy: 0.2857\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 39.3879 - accuracy: 0.1746\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 26.0153 - accuracy: 0.1746\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 17.2808 - accuracy: 0.2381\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 12.7045 - accuracy: 0.2698\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 9.1175 - accuracy: 0.2222\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 6.6061 - accuracy: 0.3333\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 4.5866 - accuracy: 0.2698\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.0265 - accuracy: 0.2698\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.7191 - accuracy: 0.3492\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.6759 - accuracy: 0.3968\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.5248 - accuracy: 0.2698\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8985 - accuracy: 0.3810\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0509 - accuracy: 0.3016\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1469 - accuracy: 0.4127\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1115 - accuracy: 0.3810\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9569 - accuracy: 0.3968\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.4069 - accuracy: 0.3492\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7534 - accuracy: 0.4603\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9961 - accuracy: 0.3968\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0475 - accuracy: 0.3651\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8750 - accuracy: 0.3968\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7423 - accuracy: 0.3968\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6772 - accuracy: 0.4762\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8866 - accuracy: 0.3651\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.8343 - accuracy: 0.3651\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7664 - accuracy: 0.3492\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7473 - accuracy: 0.4762\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8970 - accuracy: 0.3810\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9488 - accuracy: 0.3016\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0869 - accuracy: 0.3810\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6342 - accuracy: 0.4444\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6129 - accuracy: 0.4444\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0459 - accuracy: 0.5238\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6580 - accuracy: 0.3651\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5789 - accuracy: 0.4286\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7492 - accuracy: 0.4127\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6268 - accuracy: 0.4762\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5910 - accuracy: 0.5079\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6345 - accuracy: 0.3651\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5757 - accuracy: 0.4921\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.4409 - accuracy: 0.5079\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6919 - accuracy: 0.5079\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6163 - accuracy: 0.4762\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.3986 - accuracy: 0.4921\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6704 - accuracy: 0.4603\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6288 - accuracy: 0.4444\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7483 - accuracy: 0.4762\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8952 - accuracy: 0.4444\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6712 - accuracy: 0.4762\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7077 - accuracy: 0.3968\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.4090 - accuracy: 0.6349\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7617 - accuracy: 0.4921\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.4383 - accuracy: 0.5079\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4370 - accuracy: 0.5397\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7349 - accuracy: 0.5079\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.5489 - accuracy: 0.4603\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4930 - accuracy: 0.5397\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.4200 - accuracy: 0.4921\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3645 - accuracy: 0.5397\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6893 - accuracy: 0.4762\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3330 - accuracy: 0.5714\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.3142 - accuracy: 0.5079\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.3671 - accuracy: 0.6032\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3892 - accuracy: 0.6190\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4322 - accuracy: 0.6349\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.5670 - accuracy: 0.5238\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.3957 - accuracy: 0.6190\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4437 - accuracy: 0.5079\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.4716 - accuracy: 0.6349\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2603 - accuracy: 0.5873\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.4701 - accuracy: 0.5873\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4927 - accuracy: 0.5873\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3684 - accuracy: 0.4921\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2472 - accuracy: 0.5556\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6204 - accuracy: 0.4921\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3474 - accuracy: 0.5079\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2442 - accuracy: 0.5556\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1071 - accuracy: 0.6508\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4116 - accuracy: 0.5714\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0158 - accuracy: 0.6667\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.1450 - accuracy: 0.5873\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.4397 - accuracy: 0.5714\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0710 - accuracy: 0.6190\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.1908 - accuracy: 0.6032\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.3501 - accuracy: 0.6508\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.4141 - accuracy: 0.5556\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1378 - accuracy: 0.6349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3375dc430>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_7 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_7.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_7.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step - loss: 3.0438 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0437562465667725, 0.5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 127.9656 - accuracy: 0.1111\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 84.3686 - accuracy: 0.0476\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 29.2708 - accuracy: 0.0476\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 13.7281 - accuracy: 0.0476\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.9468 - accuracy: 0.0317\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.6466 - accuracy: 0.0476\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.8317 - accuracy: 0.0952\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.9847 - accuracy: 0.0635\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.4616 - accuracy: 0.0635\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.5157 - accuracy: 0.0794\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.4266 - accuracy: 0.0952\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3979 - accuracy: 0.0952\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.4065 - accuracy: 0.1270\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.3924 - accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.4127 - accuracy: 0.1746\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3596 - accuracy: 0.1905\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3730 - accuracy: 0.1429\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3623 - accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3990 - accuracy: 0.1111\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3682 - accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3596 - accuracy: 0.1587\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3697 - accuracy: 0.1587\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3680 - accuracy: 0.0952\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3776 - accuracy: 0.1429\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3654 - accuracy: 0.2063\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3641 - accuracy: 0.2381\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3583 - accuracy: 0.1905\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3610 - accuracy: 0.2063\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3608 - accuracy: 0.1587\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3597 - accuracy: 0.2063\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3766 - accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3450 - accuracy: 0.1587\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.3538 - accuracy: 0.1905\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3838 - accuracy: 0.1111\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3533 - accuracy: 0.1746\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.3571 - accuracy: 0.2063\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3384 - accuracy: 0.1746\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3372 - accuracy: 0.0952\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3483 - accuracy: 0.1746\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3610 - accuracy: 0.2222\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.3350 - accuracy: 0.1587\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3386 - accuracy: 0.1905\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3502 - accuracy: 0.0476\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3401 - accuracy: 0.2222\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3419 - accuracy: 0.1587\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3493 - accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3401 - accuracy: 0.0952\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3349 - accuracy: 0.2222\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3271 - accuracy: 0.1587\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3344 - accuracy: 0.1111\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3360 - accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3339 - accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3374 - accuracy: 0.1429\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3311 - accuracy: 0.1270\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.3357 - accuracy: 0.2222\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3124 - accuracy: 0.1587\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.3223 - accuracy: 0.1587\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3225 - accuracy: 0.1746\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3258 - accuracy: 0.1746\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3194 - accuracy: 0.1746\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3286 - accuracy: 0.1111\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2929 - accuracy: 0.1746\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3125 - accuracy: 0.1270\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3079 - accuracy: 0.1746\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3174 - accuracy: 0.2063\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3093 - accuracy: 0.1270\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2617 - accuracy: 0.2222\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3068 - accuracy: 0.0952\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3058 - accuracy: 0.1746\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3165 - accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3020 - accuracy: 0.1111\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2678 - accuracy: 0.2540\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2863 - accuracy: 0.1587\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3648 - accuracy: 0.2222\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.2883 - accuracy: 0.1746\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.3712 - accuracy: 0.1746\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.2936 - accuracy: 0.1746\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2995 - accuracy: 0.1587\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2912 - accuracy: 0.1746\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.2829 - accuracy: 0.1746\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.2977 - accuracy: 0.2381\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.2877 - accuracy: 0.1587\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.3177 - accuracy: 0.0952\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2689 - accuracy: 0.2698\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2939 - accuracy: 0.2222\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.2931 - accuracy: 0.1746\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2794 - accuracy: 0.1905\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.2983 - accuracy: 0.1587\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.2707 - accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2836 - accuracy: 0.1746\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2850 - accuracy: 0.1270\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2921 - accuracy: 0.1905\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.2926 - accuracy: 0.1270\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.2929 - accuracy: 0.1587\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.2748 - accuracy: 0.1270\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2639 - accuracy: 0.1905\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2823 - accuracy: 0.2063\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2504 - accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2525 - accuracy: 0.2540\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2808 - accuracy: 0.1746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x327744460>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_8 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_8.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_8.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3544 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.35441255569458, 0.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 1s - loss: 17.8325 - accuracy: 0.1250WARNING:tensorflow:5 out of the last 134 calls to <function Model.make_test_function.<locals>.test_function at 0x327a157e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 1s 47ms/step - loss: 19.9186 - accuracy: 0.1429 - val_loss: 11.2547 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 10.1309 - accuracy: 0.1587 - val_loss: 7.7378 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 7.9676 - accuracy: 0.1587 - val_loss: 7.5848 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 7.4027 - accuracy: 0.2063 - val_loss: 7.1942 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 7.1223 - accuracy: 0.1587 - val_loss: 7.0266 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.8365 - accuracy: 0.2381 - val_loss: 6.8746 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.6343 - accuracy: 0.3175 - val_loss: 6.8556 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 6.6238 - accuracy: 0.1270 - val_loss: 6.6652 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.4297 - accuracy: 0.2063 - val_loss: 6.4665 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.3729 - accuracy: 0.2857 - val_loss: 6.3977 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 6.0131 - accuracy: 0.2857 - val_loss: 6.3768 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.0108 - accuracy: 0.3492 - val_loss: 6.2418 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.8357 - accuracy: 0.3333 - val_loss: 6.1785 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.8138 - accuracy: 0.3968 - val_loss: 5.9529 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.7011 - accuracy: 0.2698 - val_loss: 5.9004 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.5673 - accuracy: 0.3810 - val_loss: 5.8848 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.6072 - accuracy: 0.3333 - val_loss: 5.8007 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.5183 - accuracy: 0.4286 - val_loss: 5.8462 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.4270 - accuracy: 0.3810 - val_loss: 5.7787 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.3161 - accuracy: 0.3968 - val_loss: 5.8112 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.0245 - accuracy: 0.4444 - val_loss: 5.5849 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.0825 - accuracy: 0.4444 - val_loss: 5.6596 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.1065 - accuracy: 0.3810 - val_loss: 5.6166 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.9522 - accuracy: 0.3968 - val_loss: 5.5594 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.9929 - accuracy: 0.3492 - val_loss: 6.2169 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 4.9613 - accuracy: 0.3333 - val_loss: 5.4810 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.0169 - accuracy: 0.4127 - val_loss: 5.1622 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.7104 - accuracy: 0.6032 - val_loss: 5.5731 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.6114 - accuracy: 0.4603 - val_loss: 5.2925 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.5091 - accuracy: 0.3968 - val_loss: 5.1981 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.4072 - accuracy: 0.5079 - val_loss: 5.2031 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.3338 - accuracy: 0.4921 - val_loss: 5.2073 - val_accuracy: 0.5000 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_9 = Sequential()\n",
    "model_9.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_9.add(MaxPooling2D((2, 2)))\n",
    "model_9.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_9.add(MaxPooling2D((2, 2)))\n",
    "model_9.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_9.add(MaxPooling2D((2, 2)))\n",
    "model_9.add(Flatten())\n",
    "model_9.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_9.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_9.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_9.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_9.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_9.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 5.1622 - accuracy: 0.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.162161827087402, 0.3125]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 2.9791 - accuracy: 0.0159 - val_loss: 17.7261 - val_accuracy: 0.0625\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 2.7497 - accuracy: 0.1746 - val_loss: 8.0909 - val_accuracy: 0.2500\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.1191 - accuracy: 0.1429 - val_loss: 4.6514 - val_accuracy: 0.2500\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.7099 - accuracy: 0.2540 - val_loss: 4.9547 - val_accuracy: 0.1875\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.4965 - accuracy: 0.2857 - val_loss: 4.6919 - val_accuracy: 0.1875\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.4703 - accuracy: 0.1905 - val_loss: 5.5271 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.7935 - accuracy: 0.3175 - val_loss: 5.8005 - val_accuracy: 0.2500\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.3458 - accuracy: 0.3333 - val_loss: 6.1770 - val_accuracy: 0.2500\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.5211 - accuracy: 0.2857 - val_loss: 4.7416 - val_accuracy: 0.2500\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.1917 - accuracy: 0.3651 - val_loss: 3.4088 - val_accuracy: 0.3750\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.3005 - accuracy: 0.3175 - val_loss: 3.1046 - val_accuracy: 0.3750\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.3302 - accuracy: 0.3651 - val_loss: 3.3818 - val_accuracy: 0.0625\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.2523 - accuracy: 0.3175 - val_loss: 3.5658 - val_accuracy: 0.0625\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.2886 - accuracy: 0.3810 - val_loss: 3.3996 - val_accuracy: 0.1250\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.3652 - accuracy: 0.4127 - val_loss: 3.2180 - val_accuracy: 0.1250\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5239 - accuracy: 0.5238 - val_loss: 3.3589 - val_accuracy: 0.1875\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.2112 - accuracy: 0.3968 - val_loss: 3.6459 - val_accuracy: 0.1875\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.1436 - accuracy: 0.4603 - val_loss: 3.8824 - val_accuracy: 0.1875\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.9426 - accuracy: 0.4127 - val_loss: 3.9498 - val_accuracy: 0.1875\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.2100 - accuracy: 0.3651 - val_loss: 3.9581 - val_accuracy: 0.1875\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.9965 - accuracy: 0.4127 - val_loss: 3.8512 - val_accuracy: 0.1875\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_10 = Sequential()\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(Flatten())\n",
    "model_10.add(Dense(256))\n",
    "model_10.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_10.add(Dropout(0.5))\n",
    "model_10.add(Dense(128))\n",
    "model_10.add(LeakyReLU(alpha=0.1))\n",
    "model_10.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_10.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_10.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 3.1046 - accuracy: 0.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1046385765075684, 0.375]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video + Getty - 10 Classes (video_cropped_faces_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_faces_directory = \"../data_processing/raw_data/video_cropped_faces_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = encode(cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 5s 215ms/step - loss: 2.3762 - accuracy: 0.2598 - val_loss: 450.3246 - val_accuracy: 0.1923\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 2.0315 - accuracy: 0.4216 - val_loss: 135.6507 - val_accuracy: 0.1731\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 177ms/step - loss: 1.1117 - accuracy: 0.6618 - val_loss: 188.9164 - val_accuracy: 0.0962\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 190ms/step - loss: 0.8147 - accuracy: 0.7353 - val_loss: 95.1989 - val_accuracy: 0.1154\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.6117 - accuracy: 0.7745 - val_loss: 92.2703 - val_accuracy: 0.2115\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.8906 - accuracy: 0.7157 - val_loss: 53.0513 - val_accuracy: 0.1538\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.5180 - accuracy: 0.8431 - val_loss: 30.7575 - val_accuracy: 0.1731\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.3886 - accuracy: 0.8824 - val_loss: 15.3701 - val_accuracy: 0.1731\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.3324 - accuracy: 0.9020 - val_loss: 22.6144 - val_accuracy: 0.2115\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.1938 - accuracy: 0.9314 - val_loss: 25.0375 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3283c6890>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model_11 = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_11.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_11.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 70ms/step - loss: 18.0831 - accuracy: 0.2188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[18.08306312561035, 0.21875]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_11.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 770.1324 - accuracy: 0.1133\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 312.3860 - accuracy: 0.1094\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 98.2151 - accuracy: 0.1094\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 31.4954 - accuracy: 0.1250\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 8.4596 - accuracy: 0.1289\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 3.7146 - accuracy: 0.1484\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.8657 - accuracy: 0.1562\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.6987 - accuracy: 0.1602\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.4344 - accuracy: 0.1836\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.4472 - accuracy: 0.1758\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.4451 - accuracy: 0.2109\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3649 - accuracy: 0.2148\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3027 - accuracy: 0.1875\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3647 - accuracy: 0.1953\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3242 - accuracy: 0.1719\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3715 - accuracy: 0.1836\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.4134 - accuracy: 0.1719\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2798 - accuracy: 0.1992\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1977 - accuracy: 0.2305\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2463 - accuracy: 0.2148\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2916 - accuracy: 0.1875\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2930 - accuracy: 0.2070\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2910 - accuracy: 0.2109\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3488 - accuracy: 0.1680\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3157 - accuracy: 0.1758\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2426 - accuracy: 0.1836\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2152 - accuracy: 0.2031\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2375 - accuracy: 0.2266\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2365 - accuracy: 0.2461\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2854 - accuracy: 0.2070\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2308 - accuracy: 0.2148\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1856 - accuracy: 0.2070\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.1420 - accuracy: 0.2383\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.1473 - accuracy: 0.2422\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2556 - accuracy: 0.2109\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1963 - accuracy: 0.2227\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2118 - accuracy: 0.2266\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2043 - accuracy: 0.2656\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1655 - accuracy: 0.2539\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2587 - accuracy: 0.2070\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 2.1613 - accuracy: 0.2344\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1850 - accuracy: 0.2188\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1238 - accuracy: 0.2891\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1958 - accuracy: 0.2031\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1741 - accuracy: 0.2344\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1391 - accuracy: 0.2383\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1670 - accuracy: 0.2227\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2176 - accuracy: 0.2109\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2036 - accuracy: 0.2695\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1211 - accuracy: 0.2305\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1169 - accuracy: 0.2344\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1174 - accuracy: 0.2422\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1291 - accuracy: 0.2305\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0844 - accuracy: 0.2461\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0973 - accuracy: 0.2734\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0999 - accuracy: 0.2539\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1124 - accuracy: 0.2539\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1313 - accuracy: 0.2109\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0383 - accuracy: 0.3047\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0989 - accuracy: 0.2539\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0738 - accuracy: 0.2305\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0417 - accuracy: 0.2969\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0711 - accuracy: 0.2617\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0545 - accuracy: 0.2617\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.0605 - accuracy: 0.2695\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1276 - accuracy: 0.2695\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0649 - accuracy: 0.2383\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.0663 - accuracy: 0.2773\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.1148 - accuracy: 0.2422\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.1554 - accuracy: 0.2461\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0609 - accuracy: 0.2773\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0955 - accuracy: 0.2773\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1210 - accuracy: 0.2500\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0161 - accuracy: 0.2656\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0966 - accuracy: 0.2188\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.0772 - accuracy: 0.2617\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0299 - accuracy: 0.2578\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0318 - accuracy: 0.2812\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.9955 - accuracy: 0.2578\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 2.0064 - accuracy: 0.2969\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.0214 - accuracy: 0.2969\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.1153 - accuracy: 0.2656\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.0333 - accuracy: 0.3164\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0203 - accuracy: 0.2969\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0221 - accuracy: 0.2773\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.0614 - accuracy: 0.2852\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.0050 - accuracy: 0.3164\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.0270 - accuracy: 0.2930\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.9296 - accuracy: 0.3125\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0357 - accuracy: 0.2891\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0579 - accuracy: 0.3242\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.9813 - accuracy: 0.3242\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.0448 - accuracy: 0.3008\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.9818 - accuracy: 0.3242\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0165 - accuracy: 0.3125\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.9949 - accuracy: 0.3008\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 2.0719 - accuracy: 0.2266\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.9771 - accuracy: 0.2500\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0180 - accuracy: 0.3164\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.9102 - accuracy: 0.3477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x346fb6770>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_12 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_12.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_12.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8802 - accuracy: 0.2656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.880157709121704, 0.265625]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 68.1864 - accuracy: 0.0977\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 4.2623 - accuracy: 0.0781\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.4763 - accuracy: 0.0625\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.3128 - accuracy: 0.0977\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.3074 - accuracy: 0.0938\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2991 - accuracy: 0.1016\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2798 - accuracy: 0.0820\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2926 - accuracy: 0.1328\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2574 - accuracy: 0.1602\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2608 - accuracy: 0.1367\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2397 - accuracy: 0.1602\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2617 - accuracy: 0.1250\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2583 - accuracy: 0.1133\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2375 - accuracy: 0.1484\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2446 - accuracy: 0.1758\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2156 - accuracy: 0.1758\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2306 - accuracy: 0.1406\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2255 - accuracy: 0.1445\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.2735 - accuracy: 0.1211\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2628 - accuracy: 0.1562\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2602 - accuracy: 0.1367\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2699 - accuracy: 0.1328\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2153 - accuracy: 0.1719\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2266 - accuracy: 0.1875\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2151 - accuracy: 0.1602\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1903 - accuracy: 0.1641\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.3023 - accuracy: 0.1562\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.2523 - accuracy: 0.1562\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2521 - accuracy: 0.1641\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2597 - accuracy: 0.1289\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1829 - accuracy: 0.2109\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2281 - accuracy: 0.1602\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2325 - accuracy: 0.1406\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2102 - accuracy: 0.1836\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2114 - accuracy: 0.2031\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2314 - accuracy: 0.1484\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2174 - accuracy: 0.1875\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2140 - accuracy: 0.1289\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2454 - accuracy: 0.1992\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2421 - accuracy: 0.2070\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2557 - accuracy: 0.1484\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2388 - accuracy: 0.1602\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2096 - accuracy: 0.1797\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2267 - accuracy: 0.1523\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1943 - accuracy: 0.1602\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.1840 - accuracy: 0.1719\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1939 - accuracy: 0.1914\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 2.1928 - accuracy: 0.1562\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1971 - accuracy: 0.1992\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2313 - accuracy: 0.1680\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2243 - accuracy: 0.1484\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2065 - accuracy: 0.1602\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2575 - accuracy: 0.1367\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2027 - accuracy: 0.1562\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2040 - accuracy: 0.1367\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.1984 - accuracy: 0.1797\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2178 - accuracy: 0.1562\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1903 - accuracy: 0.1719\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.1991 - accuracy: 0.1602\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1826 - accuracy: 0.1758\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2005 - accuracy: 0.1445\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.2474 - accuracy: 0.1406\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2146 - accuracy: 0.1523\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1982 - accuracy: 0.1641\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2390 - accuracy: 0.1680\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2379 - accuracy: 0.1250\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1951 - accuracy: 0.1875\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2106 - accuracy: 0.1680\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2174 - accuracy: 0.1523\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2095 - accuracy: 0.1484\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2016 - accuracy: 0.1445\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.2065 - accuracy: 0.1133\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1927 - accuracy: 0.1758\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2003 - accuracy: 0.1719\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.1962 - accuracy: 0.1758\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1876 - accuracy: 0.1836\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1841 - accuracy: 0.1758\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2540 - accuracy: 0.1836\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1925 - accuracy: 0.1797\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1768 - accuracy: 0.1758\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1695 - accuracy: 0.1641\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1750 - accuracy: 0.1719\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1998 - accuracy: 0.1562\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1686 - accuracy: 0.2070\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2166 - accuracy: 0.1328\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.1970 - accuracy: 0.1719\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2084 - accuracy: 0.1406\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2063 - accuracy: 0.1719\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2041 - accuracy: 0.1797\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2963 - accuracy: 0.1523\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2123 - accuracy: 0.1602\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2558 - accuracy: 0.1445\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2553 - accuracy: 0.1523\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2126 - accuracy: 0.1797\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2655 - accuracy: 0.1367\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2317 - accuracy: 0.1602\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2006 - accuracy: 0.1758\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1974 - accuracy: 0.1367\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.1915 - accuracy: 0.1484\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1830 - accuracy: 0.1797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ddb00b80>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_13 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_13.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_13.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1512 - accuracy: 0.1719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.151215553283691, 0.171875]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_13.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 22ms/step - loss: 17.1474 - accuracy: 0.0977 - val_loss: 7.2742 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.0583 - accuracy: 0.1445 - val_loss: 6.8243 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.6609 - accuracy: 0.1094 - val_loss: 6.5463 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.4437 - accuracy: 0.1055 - val_loss: 6.3237 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.2176 - accuracy: 0.1016 - val_loss: 6.1335 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.0335 - accuracy: 0.1328 - val_loss: 5.9608 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 5.8592 - accuracy: 0.1328 - val_loss: 5.7939 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.6957 - accuracy: 0.1523 - val_loss: 5.6728 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.5678 - accuracy: 0.1289 - val_loss: 5.5329 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.4232 - accuracy: 0.1641 - val_loss: 5.4173 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.2918 - accuracy: 0.1211 - val_loss: 5.4841 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1748 - accuracy: 0.1602 - val_loss: 5.3441 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.0549 - accuracy: 0.1562 - val_loss: 5.3830 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.9364 - accuracy: 0.1641 - val_loss: 5.7844 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.9147 - accuracy: 0.1641 - val_loss: 4.9160 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.8041 - accuracy: 0.1367 - val_loss: 4.8486 - val_accuracy: 0.0469 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.7121 - accuracy: 0.1094 - val_loss: 4.8312 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.6137 - accuracy: 0.1680 - val_loss: 4.8308 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.5134 - accuracy: 0.1602 - val_loss: 4.7311 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.4544 - accuracy: 0.1523 - val_loss: 4.6594 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 4.3336 - accuracy: 0.1758 - val_loss: 4.5276 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.3053 - accuracy: 0.1484 - val_loss: 4.5365 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.2121 - accuracy: 0.1914 - val_loss: 4.4757 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.1906 - accuracy: 0.1641 - val_loss: 4.5928 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.1170 - accuracy: 0.1914 - val_loss: 4.7211 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.0790 - accuracy: 0.1484 - val_loss: 4.9726 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.0225 - accuracy: 0.1992 - val_loss: 4.7913 - val_accuracy: 0.2344 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.0287 - accuracy: 0.1914 - val_loss: 4.6782 - val_accuracy: 0.1562 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_14 = Sequential()\n",
    "model_14.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_14.add(MaxPooling2D((2, 2)))\n",
    "model_14.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_14.add(MaxPooling2D((2, 2)))\n",
    "model_14.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_14.add(MaxPooling2D((2, 2)))\n",
    "model_14.add(Flatten())\n",
    "model_14.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_14.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_14.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_14.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_14.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_14.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 4.4757 - accuracy: 0.1406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.4756550788879395, 0.140625]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_14.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 3.1718 - accuracy: 0.1055 - val_loss: 4.8802 - val_accuracy: 0.1406\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.4431 - accuracy: 0.1133 - val_loss: 7.9642 - val_accuracy: 0.0938\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.4310 - accuracy: 0.1680 - val_loss: 5.9525 - val_accuracy: 0.0781\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.0578 - accuracy: 0.1523 - val_loss: 4.0330 - val_accuracy: 0.0781\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.1684 - accuracy: 0.1328 - val_loss: 3.0378 - val_accuracy: 0.1250\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.9309 - accuracy: 0.1602 - val_loss: 3.3828 - val_accuracy: 0.1250\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.9117 - accuracy: 0.1641 - val_loss: 2.9726 - val_accuracy: 0.1094\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.8397 - accuracy: 0.1953 - val_loss: 2.3690 - val_accuracy: 0.1719\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.8780 - accuracy: 0.1836 - val_loss: 2.3044 - val_accuracy: 0.1719\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.5965 - accuracy: 0.1602 - val_loss: 2.5820 - val_accuracy: 0.1094\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.3615 - accuracy: 0.2383 - val_loss: 2.7474 - val_accuracy: 0.0938\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.6457 - accuracy: 0.1875 - val_loss: 2.5659 - val_accuracy: 0.1250\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.5910 - accuracy: 0.1797 - val_loss: 2.2823 - val_accuracy: 0.1719\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.5144 - accuracy: 0.1875 - val_loss: 2.3123 - val_accuracy: 0.1250\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.4325 - accuracy: 0.1836 - val_loss: 2.4688 - val_accuracy: 0.1719\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.2887 - accuracy: 0.2383 - val_loss: 2.3761 - val_accuracy: 0.1719\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.3184 - accuracy: 0.2539 - val_loss: 2.4912 - val_accuracy: 0.0781\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.2603 - accuracy: 0.2383 - val_loss: 2.7328 - val_accuracy: 0.1094\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.1367 - accuracy: 0.2734 - val_loss: 2.2953 - val_accuracy: 0.1562\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 2.1678 - accuracy: 0.3008 - val_loss: 2.3694 - val_accuracy: 0.1875\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.1373 - accuracy: 0.3125 - val_loss: 2.4124 - val_accuracy: 0.1875\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.0577 - accuracy: 0.2930 - val_loss: 2.3234 - val_accuracy: 0.2344\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.0108 - accuracy: 0.3086 - val_loss: 2.3044 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_15 = Sequential()\n",
    "model_15.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_15.add(MaxPooling2D((2, 2)))\n",
    "model_15.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_15.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_15.add(MaxPooling2D((2, 2)))\n",
    "model_15.add(BatchNormalization())\n",
    "model_15.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_15.add(MaxPooling2D((2, 2)))\n",
    "model_15.add(BatchNormalization())\n",
    "model_15.add(Flatten())\n",
    "model_15.add(Dense(256))\n",
    "model_15.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_15.add(Dropout(0.5))\n",
    "model_15.add(Dense(128))\n",
    "model_15.add(LeakyReLU(alpha=0.1))\n",
    "model_15.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_15.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_15.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 2.2823 - accuracy: 0.1719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2823073863983154, 0.171875]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_15.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video + Getty - 5 Classes (video_cropped_faces_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_faces_directory = \"../data_processing/raw_data/video_cropped_faces_2\"\n",
    "\n",
    "y, X = encode(cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 4s 234ms/step - loss: 0.8407 - accuracy: 0.6810 - val_loss: 15.1895 - val_accuracy: 0.3793\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.5384 - accuracy: 0.8966 - val_loss: 68.8213 - val_accuracy: 0.3793\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.2376 - accuracy: 0.9310 - val_loss: 27.3002 - val_accuracy: 0.4483\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.1937 - accuracy: 0.9310 - val_loss: 15.8512 - val_accuracy: 0.5517\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.3170 - accuracy: 0.4865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.317042350769043, 0.4864864945411682]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model_16 = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_16.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_16.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n",
    "\n",
    "model_16.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 15ms/step - loss: 697.0805 - accuracy: 0.1862\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 482.5548 - accuracy: 0.2069\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 136.1004 - accuracy: 0.2000\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.9276 - accuracy: 0.2069\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.4791 - accuracy: 0.2069\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.2673 - accuracy: 0.2207\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3486 - accuracy: 0.1931\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4486 - accuracy: 0.3103\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4048 - accuracy: 0.2897\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.2501 - accuracy: 0.3517\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4636 - accuracy: 0.2690\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.6486 - accuracy: 0.2897\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.9280 - accuracy: 0.3448\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.9707 - accuracy: 0.3034\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.0410 - accuracy: 0.3172\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4673 - accuracy: 0.3379\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.5032 - accuracy: 0.3103\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4254 - accuracy: 0.3310\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5122 - accuracy: 0.3034\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5332 - accuracy: 0.2828\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2290 - accuracy: 0.3448\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4258 - accuracy: 0.3517\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4454 - accuracy: 0.2966\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5888 - accuracy: 0.3103\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5985 - accuracy: 0.3310\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.8828 - accuracy: 0.2207\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.2250 - accuracy: 0.3517\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4020 - accuracy: 0.3034\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.3307 - accuracy: 0.3241\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2303 - accuracy: 0.3517\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.3539 - accuracy: 0.3103\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.9608 - accuracy: 0.3103\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7813 - accuracy: 0.4069\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8019 - accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.7330 - accuracy: 0.3793\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8940 - accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0773 - accuracy: 0.3241\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8658 - accuracy: 0.4069\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8509 - accuracy: 0.3586\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.1069 - accuracy: 0.3034\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.1214 - accuracy: 0.3034\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6794 - accuracy: 0.3724\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7916 - accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6096 - accuracy: 0.3724\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8069 - accuracy: 0.3862\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7011 - accuracy: 0.3724\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6660 - accuracy: 0.3517\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6187 - accuracy: 0.3862\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7523 - accuracy: 0.3793\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8756 - accuracy: 0.4138\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5908 - accuracy: 0.4138\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4154 - accuracy: 0.4552\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9092 - accuracy: 0.3310\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7041 - accuracy: 0.3448\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7079 - accuracy: 0.3103\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5692 - accuracy: 0.4345\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5035 - accuracy: 0.4207\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7682 - accuracy: 0.3586\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6911 - accuracy: 0.4069\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5247 - accuracy: 0.4759\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5758 - accuracy: 0.4069\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5711 - accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5899 - accuracy: 0.4069\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4400 - accuracy: 0.4414\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6490 - accuracy: 0.3931\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5194 - accuracy: 0.4414\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.5699 - accuracy: 0.4276\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6749 - accuracy: 0.3793\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5474 - accuracy: 0.4207\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4956 - accuracy: 0.4276\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6243 - accuracy: 0.4621\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4884 - accuracy: 0.4345\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5798 - accuracy: 0.4000\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3860 - accuracy: 0.4138\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5614 - accuracy: 0.3931\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4546 - accuracy: 0.4621\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4952 - accuracy: 0.4207\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.5654 - accuracy: 0.4000\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5002 - accuracy: 0.4414\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3734 - accuracy: 0.5379\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.5925 - accuracy: 0.3862\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4951 - accuracy: 0.4069\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4260 - accuracy: 0.4276\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6462 - accuracy: 0.3931\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4910 - accuracy: 0.3931\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4608 - accuracy: 0.4414\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4648 - accuracy: 0.4414\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4003 - accuracy: 0.4690\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4853 - accuracy: 0.4552\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5027 - accuracy: 0.4345\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4865 - accuracy: 0.4069\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3610 - accuracy: 0.4828\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4300 - accuracy: 0.4414\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3498 - accuracy: 0.4345\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4300 - accuracy: 0.4276\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3990 - accuracy: 0.4966\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4682 - accuracy: 0.4483\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4501 - accuracy: 0.4828\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4609 - accuracy: 0.4069\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6150 - accuracy: 0.4345\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6263 - accuracy: 0.4595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6263487339019775, 0.45945945382118225]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_17 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_17.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_17.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n",
    "\n",
    "model_17.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 135.2441 - accuracy: 0.2207\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.2141 - accuracy: 0.2414\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4448 - accuracy: 0.1586\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.6992 - accuracy: 0.1931\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.7472 - accuracy: 0.2207\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6349 - accuracy: 0.2276\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6600 - accuracy: 0.2207\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7309 - accuracy: 0.2207\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6558 - accuracy: 0.1931\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6333 - accuracy: 0.1724\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6321 - accuracy: 0.2138\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6492 - accuracy: 0.2483\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5820 - accuracy: 0.2552\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6181 - accuracy: 0.2552\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6255 - accuracy: 0.2552\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6128 - accuracy: 0.2897\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6579 - accuracy: 0.1724\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6006 - accuracy: 0.2276\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6109 - accuracy: 0.2345\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6218 - accuracy: 0.2414\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6002 - accuracy: 0.2621\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6167 - accuracy: 0.2069\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5861 - accuracy: 0.2690\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6175 - accuracy: 0.2207\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6196 - accuracy: 0.2276\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6008 - accuracy: 0.2345\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5843 - accuracy: 0.2966\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6372 - accuracy: 0.2138\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5693 - accuracy: 0.2621\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5964 - accuracy: 0.2345\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6174 - accuracy: 0.1793\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5965 - accuracy: 0.2276\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6110 - accuracy: 0.2138\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6316 - accuracy: 0.2414\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6020 - accuracy: 0.2621\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6362 - accuracy: 0.1931\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.6141 - accuracy: 0.2414\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6189 - accuracy: 0.2483\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6064 - accuracy: 0.1931\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5996 - accuracy: 0.2414\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5905 - accuracy: 0.1931\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5918 - accuracy: 0.2552\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6045 - accuracy: 0.2414\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5883 - accuracy: 0.2414\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6442 - accuracy: 0.2552\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6098 - accuracy: 0.2483\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6092 - accuracy: 0.2138\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6098 - accuracy: 0.2345\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5826 - accuracy: 0.2621\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6000 - accuracy: 0.2414\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6600 - accuracy: 0.2276\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5986 - accuracy: 0.2276\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5810 - accuracy: 0.2138\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6370 - accuracy: 0.2276\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6069 - accuracy: 0.2621\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5809 - accuracy: 0.2276\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5914 - accuracy: 0.2345\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5809 - accuracy: 0.2345\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5824 - accuracy: 0.2966\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5721 - accuracy: 0.2759\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6296 - accuracy: 0.2828\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6353 - accuracy: 0.2276\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6178 - accuracy: 0.2207\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5900 - accuracy: 0.3172\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6110 - accuracy: 0.2621\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5973 - accuracy: 0.2828\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6231 - accuracy: 0.1931\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6225 - accuracy: 0.1862\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5950 - accuracy: 0.2759\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5842 - accuracy: 0.2276\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5940 - accuracy: 0.2276\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5671 - accuracy: 0.2759\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6099 - accuracy: 0.2414\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5792 - accuracy: 0.2621\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6260 - accuracy: 0.2759\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6159 - accuracy: 0.2138\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5816 - accuracy: 0.3034\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6385 - accuracy: 0.2690\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5845 - accuracy: 0.2552\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6085 - accuracy: 0.1931\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5699 - accuracy: 0.2414\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5745 - accuracy: 0.2690\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6596 - accuracy: 0.2621\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5891 - accuracy: 0.2345\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5833 - accuracy: 0.2276\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6042 - accuracy: 0.1931\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6086 - accuracy: 0.2345\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6251 - accuracy: 0.1793\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5813 - accuracy: 0.2414\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6034 - accuracy: 0.1862\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6121 - accuracy: 0.2483\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5687 - accuracy: 0.2276\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5863 - accuracy: 0.2621\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6151 - accuracy: 0.2552\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6091 - accuracy: 0.2276\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5939 - accuracy: 0.1931\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6114 - accuracy: 0.2759\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5946 - accuracy: 0.2621\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5599 - accuracy: 0.2345\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6245 - accuracy: 0.2966\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5990 - accuracy: 0.2432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5990294218063354, 0.2432432472705841]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_18 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_18.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_18.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n",
    "\n",
    "model_18.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 26ms/step - loss: 24.1407 - accuracy: 0.1586 - val_loss: 7.0775 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 7.1407 - accuracy: 0.2207 - val_loss: 6.1672 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 6.2072 - accuracy: 0.1931 - val_loss: 5.9531 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 5.9052 - accuracy: 0.1379 - val_loss: 5.8152 - val_accuracy: 0.1081 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 5.7635 - accuracy: 0.2207 - val_loss: 5.6920 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 5.6480 - accuracy: 0.2138 - val_loss: 5.6001 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.5390 - accuracy: 0.2000 - val_loss: 5.4426 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.3906 - accuracy: 0.2276 - val_loss: 5.3725 - val_accuracy: 0.1081 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.3375 - accuracy: 0.1724 - val_loss: 5.2457 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.2053 - accuracy: 0.2759 - val_loss: 5.1509 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.1224 - accuracy: 0.2207 - val_loss: 5.0724 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.0146 - accuracy: 0.2897 - val_loss: 4.9920 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.9710 - accuracy: 0.1931 - val_loss: 4.9508 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.8797 - accuracy: 0.2414 - val_loss: 4.8554 - val_accuracy: 0.1081 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.7991 - accuracy: 0.1724 - val_loss: 4.7994 - val_accuracy: 0.1081 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.7269 - accuracy: 0.2207 - val_loss: 4.7010 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 4.6670 - accuracy: 0.2690 - val_loss: 4.6192 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.6006 - accuracy: 0.2345 - val_loss: 4.5830 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.5469 - accuracy: 0.2897 - val_loss: 4.5420 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.5101 - accuracy: 0.2897 - val_loss: 4.5228 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.4227 - accuracy: 0.2552 - val_loss: 4.4864 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.3765 - accuracy: 0.2345 - val_loss: 4.4375 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.2905 - accuracy: 0.2828 - val_loss: 4.3929 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.2560 - accuracy: 0.3103 - val_loss: 4.3110 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.2985 - accuracy: 0.2207 - val_loss: 4.2796 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.2237 - accuracy: 0.1862 - val_loss: 4.2026 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.1179 - accuracy: 0.2414 - val_loss: 4.1559 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.0885 - accuracy: 0.2897 - val_loss: 4.1369 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.0396 - accuracy: 0.2828 - val_loss: 3.9980 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.9621 - accuracy: 0.3034 - val_loss: 3.9363 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.9538 - accuracy: 0.2207 - val_loss: 3.9672 - val_accuracy: 0.0811 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.9263 - accuracy: 0.3034 - val_loss: 3.9283 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 3.8730 - accuracy: 0.3034 - val_loss: 3.8853 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.8373 - accuracy: 0.2483 - val_loss: 3.8700 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.8173 - accuracy: 0.2621 - val_loss: 3.8614 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 3.7644 - accuracy: 0.2276 - val_loss: 3.8802 - val_accuracy: 0.1081 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.7035 - accuracy: 0.2828 - val_loss: 3.9651 - val_accuracy: 0.1081 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.6775 - accuracy: 0.2759 - val_loss: 3.9838 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.6362 - accuracy: 0.2621 - val_loss: 3.9786 - val_accuracy: 0.1622 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6886 - accuracy: 0.2483 - val_loss: 3.9360 - val_accuracy: 0.1622 - lr: 1.0000e-04\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8614 - accuracy: 0.2162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.8613603115081787, 0.21621622145175934]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_19 = Sequential()\n",
    "model_19.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_19.add(MaxPooling2D((2, 2)))\n",
    "model_19.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_19.add(MaxPooling2D((2, 2)))\n",
    "model_19.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_19.add(MaxPooling2D((2, 2)))\n",
    "model_19.add(Flatten())\n",
    "model_19.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_19.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_19.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_19.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_19.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_19.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "model_19.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "3/3 [==============================] - 1s 95ms/step - loss: 2.5536 - accuracy: 0.2207 - val_loss: 25.1510 - val_accuracy: 0.1351\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 2.5058 - accuracy: 0.2690 - val_loss: 5.3763 - val_accuracy: 0.1081\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2.7093 - accuracy: 0.2690 - val_loss: 7.7619 - val_accuracy: 0.2162\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 2.5523 - accuracy: 0.3241 - val_loss: 4.0743 - val_accuracy: 0.2432\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 2.7425 - accuracy: 0.2621 - val_loss: 5.8738 - val_accuracy: 0.1622\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 2.5915 - accuracy: 0.2138 - val_loss: 4.7102 - val_accuracy: 0.1622\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.0056 - accuracy: 0.3586 - val_loss: 3.5605 - val_accuracy: 0.1622\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 2.2851 - accuracy: 0.3241 - val_loss: 3.0070 - val_accuracy: 0.1622\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 2.4047 - accuracy: 0.3034 - val_loss: 2.5931 - val_accuracy: 0.3514\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 2.3776 - accuracy: 0.3103 - val_loss: 2.8433 - val_accuracy: 0.2973\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.3547 - accuracy: 0.3379 - val_loss: 2.5240 - val_accuracy: 0.1892\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2.3270 - accuracy: 0.2966 - val_loss: 2.3618 - val_accuracy: 0.1892\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 2.1650 - accuracy: 0.3103 - val_loss: 2.2798 - val_accuracy: 0.3243\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 2.1914 - accuracy: 0.2828 - val_loss: 2.0422 - val_accuracy: 0.3243\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.9593 - accuracy: 0.3931 - val_loss: 1.7220 - val_accuracy: 0.4054\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.8779 - accuracy: 0.3586 - val_loss: 1.5311 - val_accuracy: 0.3784\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 2.0154 - accuracy: 0.3655 - val_loss: 1.5523 - val_accuracy: 0.4324\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 1.7646 - accuracy: 0.4069 - val_loss: 1.6880 - val_accuracy: 0.3514\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.6821 - accuracy: 0.4276 - val_loss: 1.6167 - val_accuracy: 0.3784\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.8506 - accuracy: 0.3448 - val_loss: 1.5916 - val_accuracy: 0.3514\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 1.6865 - accuracy: 0.4552 - val_loss: 1.6484 - val_accuracy: 0.2973\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.5883 - accuracy: 0.4276 - val_loss: 1.6761 - val_accuracy: 0.2703\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 1.5598 - accuracy: 0.3586 - val_loss: 1.7429 - val_accuracy: 0.1892\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.4463 - accuracy: 0.4138 - val_loss: 1.6595 - val_accuracy: 0.2432\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 1.5338 - accuracy: 0.4207 - val_loss: 1.6122 - val_accuracy: 0.3514\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.6992 - accuracy: 0.3724 - val_loss: 1.5728 - val_accuracy: 0.2432\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5311 - accuracy: 0.3784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5310646295547485, 0.37837839126586914]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_20 = Sequential()\n",
    "model_20.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_20.add(MaxPooling2D((2, 2)))\n",
    "model_20.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_20.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_20.add(MaxPooling2D((2, 2)))\n",
    "model_20.add(BatchNormalization())\n",
    "model_20.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_20.add(MaxPooling2D((2, 2)))\n",
    "model_20.add(BatchNormalization())\n",
    "model_20.add(Flatten())\n",
    "model_20.add(Dense(256))\n",
    "model_20.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_20.add(Dropout(0.5))\n",
    "model_20.add(Dense(128))\n",
    "model_20.add(LeakyReLU(alpha=0.1))\n",
    "model_20.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_20.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_20.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "model_20.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
