{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pre-trained model\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "# Importing important layers of Keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Importing data functions\n",
    "from data_library.data_processing import black_white, crop, delete_face_images, encode, to_cat\n",
    "\n",
    "# Importing preprocessing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 16s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Saving the model in a variable\n",
    "resnet = ResNet50(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Classes from Real Madrid (cropped_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_folder = \"../data_processing/raw_data/faces/\"\n",
    "cropped_faces_directory = \"../data_processing/raw_data/cropped_faces\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = encode(cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 12:40:14.117352: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 232ms/step - loss: 2.2123 - accuracy: 0.3782 - val_loss: 15.1125 - val_accuracy: 0.2250\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 179ms/step - loss: 1.1137 - accuracy: 0.7115 - val_loss: 335.9442 - val_accuracy: 0.1250\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 0.9770 - accuracy: 0.8782 - val_loss: 5980.7432 - val_accuracy: 0.1250\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.5295 - accuracy: 0.8910 - val_loss: 32339.6777 - val_accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d7eaf9d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 67ms/step - loss: 16.7883 - accuracy: 0.1633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.788280487060547, 0.16326530277729034]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 980.6898 - accuracy: 0.0816\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1007.4955 - accuracy: 0.0867\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 304.1216 - accuracy: 0.1122\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 106.2029 - accuracy: 0.0918\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 25.7008 - accuracy: 0.1020\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 9.3852 - accuracy: 0.1684\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.6860 - accuracy: 0.1224\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 4.2978 - accuracy: 0.1224\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 3.8512 - accuracy: 0.1276\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 3.8347 - accuracy: 0.0918\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 3.3621 - accuracy: 0.1531\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 3.0374 - accuracy: 0.1684\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.9655 - accuracy: 0.1684\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.8857 - accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.4962 - accuracy: 0.1327\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.4644 - accuracy: 0.1378\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.4227 - accuracy: 0.1276\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.3324 - accuracy: 0.1122\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.3093 - accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.3182 - accuracy: 0.0969\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.3256 - accuracy: 0.1173\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2465 - accuracy: 0.1480\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2894 - accuracy: 0.1122\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2525 - accuracy: 0.1531\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.2817 - accuracy: 0.1888\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2669 - accuracy: 0.1735\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2598 - accuracy: 0.1888\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.3099 - accuracy: 0.1531\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.3436 - accuracy: 0.1480\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2293 - accuracy: 0.1939\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2851 - accuracy: 0.1173\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.3113 - accuracy: 0.1276\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2299 - accuracy: 0.1684\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2798 - accuracy: 0.1531\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2405 - accuracy: 0.1480\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2563 - accuracy: 0.1684\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2621 - accuracy: 0.1888\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.2474 - accuracy: 0.1531\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2869 - accuracy: 0.1378\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2315 - accuracy: 0.1633\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.3707 - accuracy: 0.1071\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.3112 - accuracy: 0.1480\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2380 - accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2440 - accuracy: 0.1939\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2104 - accuracy: 0.1786\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3327 - accuracy: 0.1378\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2391 - accuracy: 0.1582\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2406 - accuracy: 0.1582\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2840 - accuracy: 0.1173\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2156 - accuracy: 0.1480\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2770 - accuracy: 0.1786\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2360 - accuracy: 0.1684\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2141 - accuracy: 0.1786\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2360 - accuracy: 0.1837\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2592 - accuracy: 0.1378\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.1732 - accuracy: 0.1531\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.3032 - accuracy: 0.1224\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.1961 - accuracy: 0.1786\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3341 - accuracy: 0.0816\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2229 - accuracy: 0.1684\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2582 - accuracy: 0.1531\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.1986 - accuracy: 0.1684\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1824 - accuracy: 0.1684\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2177 - accuracy: 0.1837\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2277 - accuracy: 0.1837\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2444 - accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2594 - accuracy: 0.1327\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1912 - accuracy: 0.1684\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2412 - accuracy: 0.1684\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1818 - accuracy: 0.1786\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2107 - accuracy: 0.1837\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2091 - accuracy: 0.1684\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2220 - accuracy: 0.2092\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2273 - accuracy: 0.1939\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2313 - accuracy: 0.1735\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1808 - accuracy: 0.1939\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1797 - accuracy: 0.1990\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2541 - accuracy: 0.1531\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1830 - accuracy: 0.1684\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1315 - accuracy: 0.2041\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1688 - accuracy: 0.1990\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1970 - accuracy: 0.1582\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1464 - accuracy: 0.2296\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1456 - accuracy: 0.2143\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1771 - accuracy: 0.2092\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1182 - accuracy: 0.1990\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2668 - accuracy: 0.1531\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2736 - accuracy: 0.1480\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.3133 - accuracy: 0.1020\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.1828 - accuracy: 0.2092\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1539 - accuracy: 0.1735\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1508 - accuracy: 0.1837\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1982 - accuracy: 0.1939\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1828 - accuracy: 0.1531\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1717 - accuracy: 0.1837\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.4345 - accuracy: 0.1480\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.3396 - accuracy: 0.1582\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3022 - accuracy: 0.1480\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1770 - accuracy: 0.1888\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2651 - accuracy: 0.1786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d6afb940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_2 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_2.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8762 - accuracy: 0.0816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.876171827316284, 0.08163265138864517]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 123.4912 - accuracy: 0.1173\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 5.1083 - accuracy: 0.1071\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.4844 - accuracy: 0.0816\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3987 - accuracy: 0.0765\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.3471 - accuracy: 0.0918\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3321 - accuracy: 0.1173\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2930 - accuracy: 0.1224\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3089 - accuracy: 0.1020\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2994 - accuracy: 0.1224\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2909 - accuracy: 0.1020\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.3145 - accuracy: 0.1122\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3117 - accuracy: 0.1224\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.3208 - accuracy: 0.0969\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2985 - accuracy: 0.1071\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3047 - accuracy: 0.0969\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 2.3030 - accuracy: 0.1633\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3128 - accuracy: 0.1378\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3088 - accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.3199 - accuracy: 0.1531\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3046 - accuracy: 0.1327\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3017 - accuracy: 0.1173\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3307 - accuracy: 0.1071\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2751 - accuracy: 0.1480\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.3171 - accuracy: 0.1173\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3198 - accuracy: 0.1224\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2985 - accuracy: 0.1276\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2802 - accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2860 - accuracy: 0.1480\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.3104 - accuracy: 0.1378\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3040 - accuracy: 0.1173\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3257 - accuracy: 0.1327\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2768 - accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3052 - accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2993 - accuracy: 0.0969\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2817 - accuracy: 0.1531\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3129 - accuracy: 0.1071\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3021 - accuracy: 0.1122\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2909 - accuracy: 0.1480\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.3323 - accuracy: 0.1071\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.3240 - accuracy: 0.1071\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2837 - accuracy: 0.1224\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3008 - accuracy: 0.1224\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2967 - accuracy: 0.1071\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3051 - accuracy: 0.1173\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3050 - accuracy: 0.1224\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2905 - accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3025 - accuracy: 0.1276\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2994 - accuracy: 0.1327\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2913 - accuracy: 0.1480\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3081 - accuracy: 0.1122\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2867 - accuracy: 0.1531\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2922 - accuracy: 0.1224\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2992 - accuracy: 0.1173\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2795 - accuracy: 0.1378\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.2791 - accuracy: 0.1378\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2963 - accuracy: 0.1276\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2747 - accuracy: 0.1378\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2824 - accuracy: 0.1429\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2748 - accuracy: 0.1531\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2775 - accuracy: 0.1224\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2715 - accuracy: 0.1480\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2766 - accuracy: 0.1531\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2823 - accuracy: 0.1480\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2723 - accuracy: 0.1378\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2724 - accuracy: 0.1735\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2795 - accuracy: 0.1378\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.3495 - accuracy: 0.1378\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2759 - accuracy: 0.1582\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2995 - accuracy: 0.1173\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.3047 - accuracy: 0.1327\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2621 - accuracy: 0.1582\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3295 - accuracy: 0.1378\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2727 - accuracy: 0.1429\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 2.2809 - accuracy: 0.1327\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2992 - accuracy: 0.1327\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2876 - accuracy: 0.1276\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3015 - accuracy: 0.1378\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2757 - accuracy: 0.1378\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2987 - accuracy: 0.1378\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2903 - accuracy: 0.1173\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2987 - accuracy: 0.1173\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2736 - accuracy: 0.1633\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2724 - accuracy: 0.1224\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3067 - accuracy: 0.1122\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3016 - accuracy: 0.1378\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2768 - accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2848 - accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2934 - accuracy: 0.1531\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2933 - accuracy: 0.1378\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3038 - accuracy: 0.1276\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2864 - accuracy: 0.1480\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3027 - accuracy: 0.1276\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2839 - accuracy: 0.1480\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2563 - accuracy: 0.1633\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2774 - accuracy: 0.1378\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2764 - accuracy: 0.1327\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2813 - accuracy: 0.1276\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2788 - accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2925 - accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2669 - accuracy: 0.1378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x305817820>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_3 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_3.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3019 - accuracy: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3019301891326904, 0.10204081982374191]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video - 10 Classes (video_cropped_faces_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_cropped_faces_directory = \"../data_processing/raw_data/video_cropped_faces_0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = encode(video_cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 4s 304ms/step - loss: 2.5330 - accuracy: 0.3800 - val_loss: 22.5859 - val_accuracy: 0.2308\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 2.0179 - accuracy: 0.5800 - val_loss: 131.7289 - val_accuracy: 0.2308\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.5238 - accuracy: 0.8800 - val_loss: 334.8791 - val_accuracy: 0.0769\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 158ms/step - loss: 0.4564 - accuracy: 0.8400 - val_loss: 1184.3062 - val_accuracy: 0.0769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d7273a60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model_1 = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_1.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 21.5645 - accuracy: 0.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[21.564544677734375, 0.1875]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 348.5375 - accuracy: 0.1587\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 761.2393 - accuracy: 0.1111\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 637.9498 - accuracy: 0.0952\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 373.7281 - accuracy: 0.2063\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 233.9421 - accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 188.9757 - accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 109.6864 - accuracy: 0.1111\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 65.4010 - accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 40.9583 - accuracy: 0.2381\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 45.7670 - accuracy: 0.1905\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 35.0556 - accuracy: 0.2063\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 28.4756 - accuracy: 0.1111\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 22.1907 - accuracy: 0.0952\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 19.0693 - accuracy: 0.1111\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 14.1945 - accuracy: 0.1905\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 10.9385 - accuracy: 0.2063\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 8.2808 - accuracy: 0.3016\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 6.9062 - accuracy: 0.2698\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 5.5207 - accuracy: 0.3016\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 4.1337 - accuracy: 0.2857\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.1936 - accuracy: 0.2698\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.6385 - accuracy: 0.1905\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1365 - accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.1221 - accuracy: 0.3016\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.2175 - accuracy: 0.2063\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.2209 - accuracy: 0.2381\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.3359 - accuracy: 0.2063\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1678 - accuracy: 0.2381\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.2151 - accuracy: 0.2063\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.2310 - accuracy: 0.2381\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1065 - accuracy: 0.2540\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.5447 - accuracy: 0.1746\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1871 - accuracy: 0.2063\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.2092 - accuracy: 0.1905\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.2739 - accuracy: 0.1587\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1681 - accuracy: 0.0952\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.3072 - accuracy: 0.1905\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.2954 - accuracy: 0.1587\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.2316 - accuracy: 0.1746\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1768 - accuracy: 0.2381\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.2850 - accuracy: 0.1587\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1436 - accuracy: 0.1746\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1349 - accuracy: 0.2063\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1902 - accuracy: 0.2063\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1993 - accuracy: 0.2063\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1470 - accuracy: 0.2381\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1668 - accuracy: 0.2222\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1281 - accuracy: 0.1905\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.2230 - accuracy: 0.1111\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1771 - accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1715 - accuracy: 0.1905\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1033 - accuracy: 0.2222\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1619 - accuracy: 0.1905\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0491 - accuracy: 0.2222\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1061 - accuracy: 0.2540\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1344 - accuracy: 0.1746\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1722 - accuracy: 0.1905\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0907 - accuracy: 0.2381\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0645 - accuracy: 0.2381\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.1316 - accuracy: 0.2540\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0703 - accuracy: 0.2222\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0364 - accuracy: 0.2540\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0913 - accuracy: 0.1905\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0883 - accuracy: 0.2222\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1176 - accuracy: 0.2222\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0450 - accuracy: 0.2222\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0951 - accuracy: 0.2222\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8928 - accuracy: 0.3333\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0506 - accuracy: 0.3016\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9283 - accuracy: 0.2381\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8883 - accuracy: 0.3651\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9352 - accuracy: 0.3810\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9784 - accuracy: 0.2857\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9484 - accuracy: 0.3333\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7638 - accuracy: 0.3968\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.1336 - accuracy: 0.3492\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9297 - accuracy: 0.2381\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8174 - accuracy: 0.3810\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7911 - accuracy: 0.3333\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8793 - accuracy: 0.3492\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8376 - accuracy: 0.3333\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.8481 - accuracy: 0.3333\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7077 - accuracy: 0.5079\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8103 - accuracy: 0.4286\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8285 - accuracy: 0.3651\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7364 - accuracy: 0.4603\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7412 - accuracy: 0.4762\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7761 - accuracy: 0.3175\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9062 - accuracy: 0.3333\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7528 - accuracy: 0.3016\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6066 - accuracy: 0.4127\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8051 - accuracy: 0.4762\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8411 - accuracy: 0.3968\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8774 - accuracy: 0.3016\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7822 - accuracy: 0.4127\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7951 - accuracy: 0.3333\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8126 - accuracy: 0.3810\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6945 - accuracy: 0.4444\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7525 - accuracy: 0.3333\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7744 - accuracy: 0.3492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d6d086a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_2 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_2.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 24 calls to <function Model.make_test_function.<locals>.test_function at 0x2fa65bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.2410 - accuracy: 0.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.241020679473877, 0.4375]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 49.0447 - accuracy: 0.0952\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 68.1441 - accuracy: 0.0635\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 26.8890 - accuracy: 0.1111\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 14.8381 - accuracy: 0.0794\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.9774 - accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.0450 - accuracy: 0.1746\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.7462 - accuracy: 0.0635\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.6509 - accuracy: 0.1111\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.5149 - accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.4391 - accuracy: 0.1270\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.5703 - accuracy: 0.1270\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.4425 - accuracy: 0.0794\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.4395 - accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.4408 - accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.4485 - accuracy: 0.0952\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.3899 - accuracy: 0.1587\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.4055 - accuracy: 0.1111\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3185 - accuracy: 0.1111\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2812 - accuracy: 0.1905\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3891 - accuracy: 0.2063\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3700 - accuracy: 0.1270\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2766 - accuracy: 0.1746\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2524 - accuracy: 0.1905\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3142 - accuracy: 0.1746\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2976 - accuracy: 0.2063\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3061 - accuracy: 0.1746\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2982 - accuracy: 0.2381\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.2778 - accuracy: 0.2063\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1741 - accuracy: 0.2063\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.2511 - accuracy: 0.2222\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.2257 - accuracy: 0.2063\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.3406 - accuracy: 0.1905\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.3176 - accuracy: 0.1905\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.2863 - accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2520 - accuracy: 0.2540\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.2149 - accuracy: 0.2381\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1834 - accuracy: 0.3016\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1928 - accuracy: 0.3333\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.4111 - accuracy: 0.2540\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.2327 - accuracy: 0.2222\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.2513 - accuracy: 0.2540\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1535 - accuracy: 0.3810\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2474 - accuracy: 0.2222\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.3471 - accuracy: 0.2857\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.2248 - accuracy: 0.2063\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1587 - accuracy: 0.2698\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0885 - accuracy: 0.3175\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3404 - accuracy: 0.2222\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1464 - accuracy: 0.3016\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1448 - accuracy: 0.3175\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.1920 - accuracy: 0.3016\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0303 - accuracy: 0.3333\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2348 - accuracy: 0.3333\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0416 - accuracy: 0.2698\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9160 - accuracy: 0.3175\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0562 - accuracy: 0.2857\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0238 - accuracy: 0.3333\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1204 - accuracy: 0.2698\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.1838 - accuracy: 0.2222\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9592 - accuracy: 0.3175\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.2281 - accuracy: 0.3333\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1550 - accuracy: 0.3968\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0049 - accuracy: 0.3810\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2093 - accuracy: 0.3016\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2200 - accuracy: 0.2698\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0311 - accuracy: 0.3175\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0636 - accuracy: 0.3175\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0563 - accuracy: 0.3175\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.1274 - accuracy: 0.2381\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.1402 - accuracy: 0.2698\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9842 - accuracy: 0.4286\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0378 - accuracy: 0.3333\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9052 - accuracy: 0.3810\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0485 - accuracy: 0.2698\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0517 - accuracy: 0.3175\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0447 - accuracy: 0.2381\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1901 - accuracy: 0.3016\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8541 - accuracy: 0.3968\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.8729 - accuracy: 0.3651\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9717 - accuracy: 0.3492\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.8951 - accuracy: 0.3492\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0232 - accuracy: 0.3175\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8862 - accuracy: 0.3175\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0780 - accuracy: 0.3651\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0400 - accuracy: 0.3333\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8938 - accuracy: 0.3651\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0454 - accuracy: 0.3333\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.8627 - accuracy: 0.3810\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8751 - accuracy: 0.4127\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6870 - accuracy: 0.4603\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7663 - accuracy: 0.3651\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0624 - accuracy: 0.3651\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.2764 - accuracy: 0.2857\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8016 - accuracy: 0.4127\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.8233 - accuracy: 0.4762\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8638 - accuracy: 0.3968\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9161 - accuracy: 0.3968\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1084 - accuracy: 0.4127\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.1597 - accuracy: 0.4127\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.9249 - accuracy: 0.3651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fdc350f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_3 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_3.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x3334bc9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.8065 - accuracy: 0.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8064758777618408, 0.4375]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 49ms/step - loss: 31.8144 - accuracy: 0.0794 - val_loss: 13.5082 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 12.1870 - accuracy: 0.1270 - val_loss: 7.7278 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 7.7952 - accuracy: 0.0952 - val_loss: 7.3807 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 7.1831 - accuracy: 0.1270 - val_loss: 7.0096 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.8917 - accuracy: 0.2063 - val_loss: 6.6498 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 6.6689 - accuracy: 0.1429 - val_loss: 6.6314 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.5239 - accuracy: 0.1270 - val_loss: 6.5403 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.3768 - accuracy: 0.3175 - val_loss: 6.3734 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.2725 - accuracy: 0.1587 - val_loss: 6.2729 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.1628 - accuracy: 0.2698 - val_loss: 6.2051 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.0471 - accuracy: 0.2381 - val_loss: 5.8882 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.9908 - accuracy: 0.3492 - val_loss: 5.8578 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.0771 - accuracy: 0.1905 - val_loss: 5.8627 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.7019 - accuracy: 0.3492 - val_loss: 5.7827 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.7032 - accuracy: 0.3651 - val_loss: 5.7966 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.7351 - accuracy: 0.2381 - val_loss: 5.6625 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.7443 - accuracy: 0.2063 - val_loss: 5.5715 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.5512 - accuracy: 0.2540 - val_loss: 5.4075 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.4349 - accuracy: 0.3492 - val_loss: 5.2433 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.5057 - accuracy: 0.3810 - val_loss: 5.1396 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.5504 - accuracy: 0.3651 - val_loss: 5.2845 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.2202 - accuracy: 0.3810 - val_loss: 5.3367 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 5.3161 - accuracy: 0.3492 - val_loss: 5.0470 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.0802 - accuracy: 0.3651 - val_loss: 4.8466 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.9342 - accuracy: 0.4127 - val_loss: 4.8061 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 5.0401 - accuracy: 0.3810 - val_loss: 4.7072 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.8964 - accuracy: 0.3810 - val_loss: 4.8056 - val_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.7008 - accuracy: 0.4286 - val_loss: 4.8466 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.9883 - accuracy: 0.4444 - val_loss: 4.7244 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.8594 - accuracy: 0.4762 - val_loss: 4.7214 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 4.7636 - accuracy: 0.4127 - val_loss: 4.7450 - val_accuracy: 0.4375 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_4.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_4.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_4.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 4.7072 - accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.707248210906982, 0.625]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 2.9954 - accuracy: 0.0794 - val_loss: 14.4994 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.9037 - accuracy: 0.2063 - val_loss: 13.3427 - val_accuracy: 0.0625\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.0453 - accuracy: 0.2222 - val_loss: 6.3568 - val_accuracy: 0.0625\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.6630 - accuracy: 0.2698 - val_loss: 7.0638 - val_accuracy: 0.0625\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.9225 - accuracy: 0.2381 - val_loss: 7.6025 - val_accuracy: 0.0625\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.5968 - accuracy: 0.2381 - val_loss: 6.5506 - val_accuracy: 0.0625\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.1709 - accuracy: 0.3492 - val_loss: 6.0982 - val_accuracy: 0.0625\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.0576 - accuracy: 0.4286 - val_loss: 5.6781 - val_accuracy: 0.0625\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.6035 - accuracy: 0.3016 - val_loss: 5.2281 - val_accuracy: 0.0625\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.3014 - accuracy: 0.3651 - val_loss: 4.6466 - val_accuracy: 0.1875\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2445 - accuracy: 0.3492 - val_loss: 4.3794 - val_accuracy: 0.2500\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.4667 - accuracy: 0.4286 - val_loss: 4.3151 - val_accuracy: 0.2500\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.3113 - accuracy: 0.3651 - val_loss: 4.5395 - val_accuracy: 0.2500\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.8303 - accuracy: 0.5238 - val_loss: 4.4861 - val_accuracy: 0.2500\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.7127 - accuracy: 0.4127 - val_loss: 4.3513 - val_accuracy: 0.2500\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.9869 - accuracy: 0.3016 - val_loss: 4.0700 - val_accuracy: 0.3750\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0850 - accuracy: 0.4127 - val_loss: 3.8829 - val_accuracy: 0.3125\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.6758 - accuracy: 0.2222 - val_loss: 3.9260 - val_accuracy: 0.1250\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.5127 - accuracy: 0.5238 - val_loss: 4.0554 - val_accuracy: 0.1250\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.3211 - accuracy: 0.3968 - val_loss: 4.1481 - val_accuracy: 0.1250\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.5549 - accuracy: 0.5397 - val_loss: 4.0808 - val_accuracy: 0.1250\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.6882 - accuracy: 0.4286 - val_loss: 3.9502 - val_accuracy: 0.1250\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4448 - accuracy: 0.5079 - val_loss: 3.7455 - val_accuracy: 0.1250\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.7382 - accuracy: 0.4603 - val_loss: 3.5401 - val_accuracy: 0.1250\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.9353 - accuracy: 0.4603 - val_loss: 3.3536 - val_accuracy: 0.1250\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.5920 - accuracy: 0.5556 - val_loss: 3.3369 - val_accuracy: 0.1250\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.7587 - accuracy: 0.4444 - val_loss: 3.3982 - val_accuracy: 0.1875\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5812 - accuracy: 0.5397 - val_loss: 3.5048 - val_accuracy: 0.0625\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.5494 - accuracy: 0.4762 - val_loss: 3.6075 - val_accuracy: 0.0625\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.5349 - accuracy: 0.4921 - val_loss: 3.7136 - val_accuracy: 0.0625\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.8195 - accuracy: 0.4444 - val_loss: 3.7162 - val_accuracy: 0.0625\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1980 - accuracy: 0.5397 - val_loss: 3.4601 - val_accuracy: 0.0625\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.5011 - accuracy: 0.5079 - val_loss: 3.2420 - val_accuracy: 0.1875\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.8632 - accuracy: 0.4921 - val_loss: 3.0408 - val_accuracy: 0.2500\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2600 - accuracy: 0.6190 - val_loss: 2.8846 - val_accuracy: 0.2500\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.2859 - accuracy: 0.5397 - val_loss: 2.7860 - val_accuracy: 0.2500\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3540 - accuracy: 0.5556 - val_loss: 2.6527 - val_accuracy: 0.2500\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1714 - accuracy: 0.6984 - val_loss: 2.4695 - val_accuracy: 0.2500\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5545 - accuracy: 0.5556 - val_loss: 2.3026 - val_accuracy: 0.2500\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.9135 - accuracy: 0.6508 - val_loss: 2.1740 - val_accuracy: 0.3125\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.3257 - accuracy: 0.5556 - val_loss: 2.1858 - val_accuracy: 0.4375\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2738 - accuracy: 0.5397 - val_loss: 2.1761 - val_accuracy: 0.4375\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.4934 - accuracy: 0.5238 - val_loss: 2.2006 - val_accuracy: 0.3750\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2717 - accuracy: 0.6032 - val_loss: 2.1862 - val_accuracy: 0.3750\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3348 - accuracy: 0.5079 - val_loss: 2.1876 - val_accuracy: 0.3750\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.3574 - accuracy: 0.6032 - val_loss: 2.3282 - val_accuracy: 0.3750\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.2379 - accuracy: 0.5873 - val_loss: 2.4508 - val_accuracy: 0.3125\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.8581 - accuracy: 0.5714 - val_loss: 2.6121 - val_accuracy: 0.2500\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.0756 - accuracy: 0.6825 - val_loss: 2.7550 - val_accuracy: 0.1875\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.3429 - accuracy: 0.6825 - val_loss: 2.8876 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_5 = Sequential()\n",
    "model_5.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_5.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(256))\n",
    "model_5.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(128))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "model_5.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_5.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_5.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 2.1740 - accuracy: 0.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1739940643310547, 0.3125]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video + Getty - 10 Classes (video_cropped_faces_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_faces_directory = \"../data_processing/raw_data/video_cropped_faces_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = encode(cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 6s 244ms/step - loss: 2.9072 - accuracy: 0.4118 - val_loss: 39067.3164 - val_accuracy: 0.1154\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 3s 202ms/step - loss: 2.5454 - accuracy: 0.5049 - val_loss: 12423.9062 - val_accuracy: 0.0962\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 1.9935 - accuracy: 0.5098 - val_loss: 60125.4531 - val_accuracy: 0.0962\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 3s 211ms/step - loss: 1.9865 - accuracy: 0.5686 - val_loss: 89333.4844 - val_accuracy: 0.0769\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 3s 224ms/step - loss: 1.3524 - accuracy: 0.6373 - val_loss: 2755.1169 - val_accuracy: 0.0385\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 3s 232ms/step - loss: 0.8082 - accuracy: 0.7549 - val_loss: 1261.1185 - val_accuracy: 0.0385\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 215ms/step - loss: 0.6787 - accuracy: 0.8088 - val_loss: 672.5253 - val_accuracy: 0.0577\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.6041 - accuracy: 0.8480 - val_loss: 712.1670 - val_accuracy: 0.0385\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 0.2518 - accuracy: 0.9314 - val_loss: 41.5900 - val_accuracy: 0.0962\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 3s 197ms/step - loss: 0.3987 - accuracy: 0.9706 - val_loss: 21.4534 - val_accuracy: 0.0962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fd16b490>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model_1 = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_1.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 78ms/step - loss: 23.1061 - accuracy: 0.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[23.10612678527832, 0.1875]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 914.4391 - accuracy: 0.1133\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 374.5955 - accuracy: 0.1055\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 79.0396 - accuracy: 0.0898\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 26.5781 - accuracy: 0.1211\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 7.8244 - accuracy: 0.1016\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 3.7817 - accuracy: 0.1211\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.5276 - accuracy: 0.1016\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.4878 - accuracy: 0.1055\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3278 - accuracy: 0.1016\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.4341 - accuracy: 0.1016\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2953 - accuracy: 0.1016\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3486 - accuracy: 0.1016\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3438 - accuracy: 0.1016\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3057 - accuracy: 0.0977\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2996 - accuracy: 0.1016\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3011 - accuracy: 0.1016\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3008 - accuracy: 0.0977\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2890 - accuracy: 0.1094\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2904 - accuracy: 0.1055\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3374 - accuracy: 0.1055\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3235 - accuracy: 0.1016\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2989 - accuracy: 0.0977\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2988 - accuracy: 0.1055\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2937 - accuracy: 0.1055\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2987 - accuracy: 0.1016\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3293 - accuracy: 0.1094\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3015 - accuracy: 0.1289\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2928 - accuracy: 0.1289\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3110 - accuracy: 0.1289\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3069 - accuracy: 0.1289\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2971 - accuracy: 0.1289\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2969 - accuracy: 0.1289\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2946 - accuracy: 0.1289\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3003 - accuracy: 0.1250\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2961 - accuracy: 0.1289\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3065 - accuracy: 0.1328\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2956 - accuracy: 0.1289\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2954 - accuracy: 0.1289\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2908 - accuracy: 0.1328\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.2918 - accuracy: 0.1289\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.3007 - accuracy: 0.1289\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2944 - accuracy: 0.1289\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2994 - accuracy: 0.1328\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3096 - accuracy: 0.1289\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3226 - accuracy: 0.1289\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2959 - accuracy: 0.1289\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.2933 - accuracy: 0.1289\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2934 - accuracy: 0.1289\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2933 - accuracy: 0.1289\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2927 - accuracy: 0.1289\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2936 - accuracy: 0.1289\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.2919 - accuracy: 0.1289\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2935 - accuracy: 0.1289\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2918 - accuracy: 0.1289\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2919 - accuracy: 0.1289\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2914 - accuracy: 0.1289\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2913 - accuracy: 0.1289\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2911 - accuracy: 0.1289\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2909 - accuracy: 0.1289\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2907 - accuracy: 0.1289\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2905 - accuracy: 0.1289\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2904 - accuracy: 0.1289\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2881 - accuracy: 0.1289\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2900 - accuracy: 0.1289\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2907 - accuracy: 0.1289\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2896 - accuracy: 0.1289\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2896 - accuracy: 0.1250\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2893 - accuracy: 0.1289\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2891 - accuracy: 0.1289\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2890 - accuracy: 0.1289\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2948 - accuracy: 0.1289\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2887 - accuracy: 0.1289\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2885 - accuracy: 0.1289\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2884 - accuracy: 0.1289\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2882 - accuracy: 0.1289\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2905 - accuracy: 0.1289\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2879 - accuracy: 0.1289\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2878 - accuracy: 0.1289\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2876 - accuracy: 0.1289\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2875 - accuracy: 0.1289\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2873 - accuracy: 0.1289\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2872 - accuracy: 0.1289\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2871 - accuracy: 0.1289\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2870 - accuracy: 0.1289\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2869 - accuracy: 0.1289\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2867 - accuracy: 0.1289\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2866 - accuracy: 0.1289\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2865 - accuracy: 0.1289\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2863 - accuracy: 0.1289\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2862 - accuracy: 0.1289\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2861 - accuracy: 0.1289\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2860 - accuracy: 0.1289\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2859 - accuracy: 0.1289\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2858 - accuracy: 0.1289\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2856 - accuracy: 0.1289\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2856 - accuracy: 0.1289\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2854 - accuracy: 0.1289\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2854 - accuracy: 0.1289\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2852 - accuracy: 0.1289\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2851 - accuracy: 0.1289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fd27d2a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_2 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_2.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2857 - accuracy: 0.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.285698413848877, 0.125]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 53.5368 - accuracy: 0.0703\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.8196 - accuracy: 0.1133\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3288 - accuracy: 0.0938\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.3195 - accuracy: 0.1094\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.3070 - accuracy: 0.0898\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2924 - accuracy: 0.1289\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2902 - accuracy: 0.1172\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.3283 - accuracy: 0.1328\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.3006 - accuracy: 0.1250\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2691 - accuracy: 0.1562\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3334 - accuracy: 0.1133\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3090 - accuracy: 0.1406\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2911 - accuracy: 0.1523\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.3032 - accuracy: 0.1133\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2841 - accuracy: 0.1523\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.3090 - accuracy: 0.1055\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2984 - accuracy: 0.1172\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2976 - accuracy: 0.1055\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.3007 - accuracy: 0.0977\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2859 - accuracy: 0.1367\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2908 - accuracy: 0.1406\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2852 - accuracy: 0.1289\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2992 - accuracy: 0.1172\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2943 - accuracy: 0.1367\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2885 - accuracy: 0.1250\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2794 - accuracy: 0.1328\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2783 - accuracy: 0.1172\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2711 - accuracy: 0.1445\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2749 - accuracy: 0.1484\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3165 - accuracy: 0.1133\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2843 - accuracy: 0.1289\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2866 - accuracy: 0.1133\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.3005 - accuracy: 0.1445\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2821 - accuracy: 0.1133\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3058 - accuracy: 0.1172\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2657 - accuracy: 0.1328\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2879 - accuracy: 0.1016\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2834 - accuracy: 0.1484\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2837 - accuracy: 0.1445\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2820 - accuracy: 0.1211\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2811 - accuracy: 0.1211\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2619 - accuracy: 0.1445\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.2952 - accuracy: 0.1094\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2649 - accuracy: 0.1289\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2959 - accuracy: 0.1211\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2556 - accuracy: 0.1641\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2699 - accuracy: 0.1328\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.2961 - accuracy: 0.1328\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2819 - accuracy: 0.1172\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2858 - accuracy: 0.1289\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2656 - accuracy: 0.1641\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2945 - accuracy: 0.1289\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2589 - accuracy: 0.1328\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2908 - accuracy: 0.1133\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2780 - accuracy: 0.1289\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2528 - accuracy: 0.1523\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2809 - accuracy: 0.1328\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2908 - accuracy: 0.1172\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2857 - accuracy: 0.1211\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2780 - accuracy: 0.1211\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2789 - accuracy: 0.1328\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2846 - accuracy: 0.1250\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2830 - accuracy: 0.1445\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.2728 - accuracy: 0.1289\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2800 - accuracy: 0.1445\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2710 - accuracy: 0.1250\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2759 - accuracy: 0.1289\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2816 - accuracy: 0.1250\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2701 - accuracy: 0.1211\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2746 - accuracy: 0.1367\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2506 - accuracy: 0.1289\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2783 - accuracy: 0.1133\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2968 - accuracy: 0.1172\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2815 - accuracy: 0.1055\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2732 - accuracy: 0.1172\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2863 - accuracy: 0.1172\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2762 - accuracy: 0.1523\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2885 - accuracy: 0.1367\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2790 - accuracy: 0.1211\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2720 - accuracy: 0.1484\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2887 - accuracy: 0.1328\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2704 - accuracy: 0.1328\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2650 - accuracy: 0.1289\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2611 - accuracy: 0.1406\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2673 - accuracy: 0.1406\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2882 - accuracy: 0.1328\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2738 - accuracy: 0.1250\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2710 - accuracy: 0.1250\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2622 - accuracy: 0.1562\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2831 - accuracy: 0.1445\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2699 - accuracy: 0.1406\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.2589 - accuracy: 0.1367\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2890 - accuracy: 0.1250\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2902 - accuracy: 0.1406\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2768 - accuracy: 0.1328\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2710 - accuracy: 0.1094\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2892 - accuracy: 0.1250\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.2683 - accuracy: 0.1523\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2723 - accuracy: 0.1484\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2875 - accuracy: 0.1367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fd5057b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_3 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_3.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2692 - accuracy: 0.1406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.269165515899658, 0.140625]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 21ms/step - loss: 18.0604 - accuracy: 0.0781 - val_loss: 7.2218 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.9503 - accuracy: 0.1094 - val_loss: 6.7495 - val_accuracy: 0.0312 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.6170 - accuracy: 0.1367 - val_loss: 6.4980 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.4001 - accuracy: 0.1406 - val_loss: 6.3007 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.2040 - accuracy: 0.1211 - val_loss: 6.1111 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.0245 - accuracy: 0.1445 - val_loss: 5.9336 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.8554 - accuracy: 0.1250 - val_loss: 5.7767 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.7108 - accuracy: 0.1211 - val_loss: 5.6788 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.5878 - accuracy: 0.1484 - val_loss: 5.5185 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.4751 - accuracy: 0.1367 - val_loss: 5.3759 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.3395 - accuracy: 0.1445 - val_loss: 5.2558 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.2100 - accuracy: 0.1367 - val_loss: 5.1374 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1084 - accuracy: 0.1133 - val_loss: 5.0337 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.0022 - accuracy: 0.1406 - val_loss: 4.9465 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.8991 - accuracy: 0.1367 - val_loss: 4.8404 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.8127 - accuracy: 0.1133 - val_loss: 4.7466 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.7172 - accuracy: 0.1641 - val_loss: 4.6672 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.6599 - accuracy: 0.1289 - val_loss: 4.5905 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.5741 - accuracy: 0.1367 - val_loss: 4.5253 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.5028 - accuracy: 0.1367 - val_loss: 4.4486 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.4078 - accuracy: 0.1602 - val_loss: 4.3552 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.3405 - accuracy: 0.1406 - val_loss: 4.2974 - val_accuracy: 0.2031 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.2921 - accuracy: 0.1406 - val_loss: 4.2406 - val_accuracy: 0.2031 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.2277 - accuracy: 0.1445 - val_loss: 4.1590 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 4.1747 - accuracy: 0.1289 - val_loss: 4.0976 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.1157 - accuracy: 0.1562 - val_loss: 4.0664 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.0573 - accuracy: 0.1445 - val_loss: 4.0122 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.0141 - accuracy: 0.1289 - val_loss: 3.9600 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.9563 - accuracy: 0.1523 - val_loss: 3.8826 - val_accuracy: 0.2031 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.8813 - accuracy: 0.1289 - val_loss: 3.8042 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.8625 - accuracy: 0.1172 - val_loss: 3.8139 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.8453 - accuracy: 0.1602 - val_loss: 3.7869 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.7725 - accuracy: 0.1367 - val_loss: 3.7583 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.7694 - accuracy: 0.1445 - val_loss: 3.7032 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.7015 - accuracy: 0.1133 - val_loss: 3.6306 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.7095 - accuracy: 0.1211 - val_loss: 3.6663 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.6428 - accuracy: 0.1562 - val_loss: 3.6379 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.6410 - accuracy: 0.1758 - val_loss: 3.6076 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.6013 - accuracy: 0.1328 - val_loss: 3.5846 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.5582 - accuracy: 0.1367 - val_loss: 3.5403 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.5250 - accuracy: 0.1406 - val_loss: 3.4990 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.4796 - accuracy: 0.1406 - val_loss: 3.4651 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.4369 - accuracy: 0.1484 - val_loss: 3.4262 - val_accuracy: 0.2031 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.4109 - accuracy: 0.1445 - val_loss: 3.3789 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.3743 - accuracy: 0.1445 - val_loss: 3.3539 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.3328 - accuracy: 0.1484 - val_loss: 3.3831 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.3314 - accuracy: 0.1406 - val_loss: 3.2938 - val_accuracy: 0.2031 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.3125 - accuracy: 0.1367 - val_loss: 3.2636 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.2817 - accuracy: 0.1523 - val_loss: 3.2636 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.2605 - accuracy: 0.1445 - val_loss: 3.2149 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.2162 - accuracy: 0.1797 - val_loss: 3.2313 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.2290 - accuracy: 0.1484 - val_loss: 3.1913 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.1841 - accuracy: 0.1484 - val_loss: 3.1505 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.1961 - accuracy: 0.1328 - val_loss: 3.1226 - val_accuracy: 0.2031 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.1731 - accuracy: 0.1289 - val_loss: 3.1290 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.1307 - accuracy: 0.1719 - val_loss: 3.0993 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.1214 - accuracy: 0.1562 - val_loss: 3.0875 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.0913 - accuracy: 0.1641 - val_loss: 3.0976 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.0831 - accuracy: 0.1289 - val_loss: 3.0594 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.0729 - accuracy: 0.1484 - val_loss: 3.0418 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.0377 - accuracy: 0.1562 - val_loss: 3.0111 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.9917 - accuracy: 0.1484 - val_loss: 3.0090 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.9596 - accuracy: 0.1133 - val_loss: 2.9961 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.9810 - accuracy: 0.1406 - val_loss: 3.0189 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.9326 - accuracy: 0.1523 - val_loss: 3.0022 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.9580 - accuracy: 0.1602 - val_loss: 2.9308 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.9379 - accuracy: 0.1445 - val_loss: 2.9132 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.8893 - accuracy: 0.1523 - val_loss: 2.9003 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.9185 - accuracy: 0.1367 - val_loss: 2.8687 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.8962 - accuracy: 0.1484 - val_loss: 2.8315 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8394 - accuracy: 0.1406 - val_loss: 2.8371 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8740 - accuracy: 0.1523 - val_loss: 2.8109 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8458 - accuracy: 0.1367 - val_loss: 2.7979 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.8207 - accuracy: 0.1445 - val_loss: 2.7581 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.8102 - accuracy: 0.1445 - val_loss: 2.7832 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.8140 - accuracy: 0.1562 - val_loss: 2.7836 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.8489 - accuracy: 0.1367 - val_loss: 2.8433 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.8351 - accuracy: 0.1367 - val_loss: 2.8448 - val_accuracy: 0.1406 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.8362 - accuracy: 0.1484 - val_loss: 2.8415 - val_accuracy: 0.1406 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_4.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_4.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_4.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 2.7581 - accuracy: 0.1719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.7581448554992676, 0.171875]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 87ms/step - loss: 3.2009 - accuracy: 0.1211 - val_loss: 11.4369 - val_accuracy: 0.1562\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.4948 - accuracy: 0.1250 - val_loss: 7.3437 - val_accuracy: 0.0938\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.2415 - accuracy: 0.1367 - val_loss: 6.2547 - val_accuracy: 0.1094\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.0423 - accuracy: 0.1562 - val_loss: 5.6266 - val_accuracy: 0.1094\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.8201 - accuracy: 0.1992 - val_loss: 4.9246 - val_accuracy: 0.1250\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.9792 - accuracy: 0.2148 - val_loss: 4.5927 - val_accuracy: 0.0625\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.7867 - accuracy: 0.1523 - val_loss: 4.1531 - val_accuracy: 0.1250\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.5714 - accuracy: 0.2227 - val_loss: 3.5308 - val_accuracy: 0.1719\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.5868 - accuracy: 0.2109 - val_loss: 3.9119 - val_accuracy: 0.1250\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.6017 - accuracy: 0.2539 - val_loss: 3.8578 - val_accuracy: 0.0469\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.6005 - accuracy: 0.2422 - val_loss: 3.4813 - val_accuracy: 0.0469\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.5439 - accuracy: 0.2539 - val_loss: 2.4798 - val_accuracy: 0.2344\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.5848 - accuracy: 0.2539 - val_loss: 2.1903 - val_accuracy: 0.2500\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.3285 - accuracy: 0.3242 - val_loss: 2.1282 - val_accuracy: 0.2188\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.3525 - accuracy: 0.2656 - val_loss: 2.1045 - val_accuracy: 0.2656\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.3359 - accuracy: 0.2500 - val_loss: 2.1250 - val_accuracy: 0.2188\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.2685 - accuracy: 0.2422 - val_loss: 2.0683 - val_accuracy: 0.2812\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.2285 - accuracy: 0.3203 - val_loss: 2.0604 - val_accuracy: 0.2188\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.1202 - accuracy: 0.3125 - val_loss: 2.0882 - val_accuracy: 0.2344\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.0755 - accuracy: 0.2930 - val_loss: 2.1386 - val_accuracy: 0.1875\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.2719 - accuracy: 0.2695 - val_loss: 2.1362 - val_accuracy: 0.1875\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.2195 - accuracy: 0.2969 - val_loss: 2.0768 - val_accuracy: 0.2344\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.0772 - accuracy: 0.3125 - val_loss: 2.1386 - val_accuracy: 0.2031\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.1766 - accuracy: 0.2852 - val_loss: 2.1925 - val_accuracy: 0.1719\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.0438 - accuracy: 0.3438 - val_loss: 2.0783 - val_accuracy: 0.2500\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.0228 - accuracy: 0.3438 - val_loss: 1.9211 - val_accuracy: 0.3438\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.1679 - accuracy: 0.3047 - val_loss: 2.0411 - val_accuracy: 0.1875\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1.9630 - accuracy: 0.3047 - val_loss: 1.9667 - val_accuracy: 0.2344\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 1.9702 - accuracy: 0.3750 - val_loss: 1.8720 - val_accuracy: 0.2344\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.9865 - accuracy: 0.3242 - val_loss: 1.8258 - val_accuracy: 0.2656\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 1.8583 - accuracy: 0.3516 - val_loss: 1.8371 - val_accuracy: 0.2500\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 1.8982 - accuracy: 0.3633 - val_loss: 1.8338 - val_accuracy: 0.3281\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 1.7839 - accuracy: 0.3828 - val_loss: 1.8211 - val_accuracy: 0.3281\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.0023 - accuracy: 0.3438 - val_loss: 1.7723 - val_accuracy: 0.2812\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 1.7848 - accuracy: 0.3945 - val_loss: 1.7863 - val_accuracy: 0.2812\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.6905 - accuracy: 0.4336 - val_loss: 1.8299 - val_accuracy: 0.3438\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1.8676 - accuracy: 0.3438 - val_loss: 1.8821 - val_accuracy: 0.3281\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 1.7887 - accuracy: 0.3555 - val_loss: 1.8040 - val_accuracy: 0.3281\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 1.7002 - accuracy: 0.4297 - val_loss: 1.7558 - val_accuracy: 0.3281\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1.8035 - accuracy: 0.4258 - val_loss: 1.7022 - val_accuracy: 0.3438\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1.7252 - accuracy: 0.4102 - val_loss: 1.8488 - val_accuracy: 0.3438\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.7956 - accuracy: 0.4180 - val_loss: 1.7211 - val_accuracy: 0.3125\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1.7330 - accuracy: 0.4102 - val_loss: 1.7448 - val_accuracy: 0.3594\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 1.6020 - accuracy: 0.4258 - val_loss: 1.8067 - val_accuracy: 0.4844\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 1.6741 - accuracy: 0.4141 - val_loss: 1.9303 - val_accuracy: 0.4062\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.7344 - accuracy: 0.4453 - val_loss: 2.1027 - val_accuracy: 0.2812\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.7708 - accuracy: 0.4180 - val_loss: 2.1868 - val_accuracy: 0.2188\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 1.5947 - accuracy: 0.4453 - val_loss: 2.1005 - val_accuracy: 0.2969\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 1.7994 - accuracy: 0.3906 - val_loss: 2.0301 - val_accuracy: 0.2969\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 1.7821 - accuracy: 0.3789 - val_loss: 1.9990 - val_accuracy: 0.3125\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_5 = Sequential()\n",
    "model_5.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_5.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(256))\n",
    "model_5.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(128))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "model_5.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_5.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_5.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 1.7022 - accuracy: 0.3438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7022076845169067, 0.34375]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video + Getty - 5 Classes (video_cropped_faces_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_faces_directory = \"../data_processing/raw_data/video_cropped_faces_2\"\n",
    "\n",
    "y, X = encode(cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 5s 283ms/step - loss: 1.3356 - accuracy: 0.5603 - val_loss: 249.2358 - val_accuracy: 0.1724\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.8585 - accuracy: 0.8190 - val_loss: 807.2657 - val_accuracy: 0.3103\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.5429 - accuracy: 0.8190 - val_loss: 1742.6189 - val_accuracy: 0.2759\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.5770 - accuracy: 0.8448 - val_loss: 1705.7964 - val_accuracy: 0.2759\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 187.1584 - accuracy: 0.2432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[187.15835571289062, 0.2432432472705841]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model_1 = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_1.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n",
    "\n",
    "model_1.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1219.3690 - accuracy: 0.2276\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 487.6217 - accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 214.3429 - accuracy: 0.1931\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 113.7920 - accuracy: 0.1724\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 62.5287 - accuracy: 0.1862\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.1502 - accuracy: 0.2552\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.6125 - accuracy: 0.2966\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.2949 - accuracy: 0.2621\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6691 - accuracy: 0.2897\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.8384 - accuracy: 0.3310\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9196 - accuracy: 0.2828\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2384 - accuracy: 0.3172\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3491 - accuracy: 0.2759\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.9243 - accuracy: 0.3310\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9196 - accuracy: 0.3310\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9916 - accuracy: 0.2759\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5337 - accuracy: 0.3034\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2309 - accuracy: 0.3517\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.7258 - accuracy: 0.2828\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7075 - accuracy: 0.2759\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.2426 - accuracy: 0.3103\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.5432 - accuracy: 0.2483\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.2644 - accuracy: 0.2690\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1365 - accuracy: 0.3241\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.2363 - accuracy: 0.2828\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8482 - accuracy: 0.3517\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8633 - accuracy: 0.3034\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2407 - accuracy: 0.3172\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.1298 - accuracy: 0.2897\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9367 - accuracy: 0.2966\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8380 - accuracy: 0.3172\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8693 - accuracy: 0.3517\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8949 - accuracy: 0.3793\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.0397 - accuracy: 0.3034\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7408 - accuracy: 0.3586\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9406 - accuracy: 0.3379\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9980 - accuracy: 0.2966\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6587 - accuracy: 0.4069\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.0232 - accuracy: 0.2690\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9211 - accuracy: 0.3448\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8469 - accuracy: 0.3310\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7064 - accuracy: 0.3034\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.9507 - accuracy: 0.3034\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8159 - accuracy: 0.3793\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7012 - accuracy: 0.3655\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7660 - accuracy: 0.3448\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6103 - accuracy: 0.3586\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5719 - accuracy: 0.3655\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6629 - accuracy: 0.3379\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7458 - accuracy: 0.3448\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7496 - accuracy: 0.3655\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6737 - accuracy: 0.3586\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6128 - accuracy: 0.3103\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7472 - accuracy: 0.3310\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6996 - accuracy: 0.3310\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.7419 - accuracy: 0.3103\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5427 - accuracy: 0.3862\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7608 - accuracy: 0.3724\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8920 - accuracy: 0.3655\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6416 - accuracy: 0.2897\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4844 - accuracy: 0.4345\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6572 - accuracy: 0.3379\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4350 - accuracy: 0.4207\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4984 - accuracy: 0.4069\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6997 - accuracy: 0.3724\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4452 - accuracy: 0.4069\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7069 - accuracy: 0.4069\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8260 - accuracy: 0.3103\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5645 - accuracy: 0.4069\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5368 - accuracy: 0.3931\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5035 - accuracy: 0.3793\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4911 - accuracy: 0.4069\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6143 - accuracy: 0.3793\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5042 - accuracy: 0.3793\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4973 - accuracy: 0.3724\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5569 - accuracy: 0.3379\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4985 - accuracy: 0.4000\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7052 - accuracy: 0.3793\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4809 - accuracy: 0.4276\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5443 - accuracy: 0.4000\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4128 - accuracy: 0.4345\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3697 - accuracy: 0.4345\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5722 - accuracy: 0.3172\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4481 - accuracy: 0.4207\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6735 - accuracy: 0.3655\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3514 - accuracy: 0.4000\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4901 - accuracy: 0.3724\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4566 - accuracy: 0.4414\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5352 - accuracy: 0.4207\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5282 - accuracy: 0.3586\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6407 - accuracy: 0.3241\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4870 - accuracy: 0.3931\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4889 - accuracy: 0.3862\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3739 - accuracy: 0.4345\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5017 - accuracy: 0.4276\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3921 - accuracy: 0.4552\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4818 - accuracy: 0.4414\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3664 - accuracy: 0.4414\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4437 - accuracy: 0.4138\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4008 - accuracy: 0.4345\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5022 - accuracy: 0.4865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5021618604660034, 0.4864864945411682]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_2 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_2.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n",
    "\n",
    "model_2.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71.9034 - accuracy: 0.1724\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.2521 - accuracy: 0.1724\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4456 - accuracy: 0.1793\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9234 - accuracy: 0.1586\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.7385 - accuracy: 0.2414\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6558 - accuracy: 0.2069\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6352 - accuracy: 0.2345\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5772 - accuracy: 0.2483\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6146 - accuracy: 0.1862\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6544 - accuracy: 0.2276\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5975 - accuracy: 0.2207\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6059 - accuracy: 0.2276\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6442 - accuracy: 0.2000\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6238 - accuracy: 0.2483\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6343 - accuracy: 0.2207\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6097 - accuracy: 0.2069\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6132 - accuracy: 0.2345\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6272 - accuracy: 0.2207\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6270 - accuracy: 0.2483\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6038 - accuracy: 0.2000\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5855 - accuracy: 0.2414\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6088 - accuracy: 0.2552\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5911 - accuracy: 0.2621\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6174 - accuracy: 0.1793\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5955 - accuracy: 0.2000\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6052 - accuracy: 0.2690\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5896 - accuracy: 0.2552\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6025 - accuracy: 0.2207\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5998 - accuracy: 0.2345\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5730 - accuracy: 0.2207\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6013 - accuracy: 0.1655\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5843 - accuracy: 0.2483\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5890 - accuracy: 0.2414\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6024 - accuracy: 0.2828\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5884 - accuracy: 0.2690\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6142 - accuracy: 0.2069\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6374 - accuracy: 0.1862\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6040 - accuracy: 0.2621\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5989 - accuracy: 0.1793\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5951 - accuracy: 0.2345\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6224 - accuracy: 0.2621\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5958 - accuracy: 0.2759\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6399 - accuracy: 0.2552\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6064 - accuracy: 0.2552\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5961 - accuracy: 0.2897\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5776 - accuracy: 0.2414\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6055 - accuracy: 0.2621\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5316 - accuracy: 0.2690\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5333 - accuracy: 0.2414\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5890 - accuracy: 0.2552\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5789 - accuracy: 0.2897\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6389 - accuracy: 0.2897\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5677 - accuracy: 0.2414\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5784 - accuracy: 0.2276\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5512 - accuracy: 0.2621\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5658 - accuracy: 0.2552\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5775 - accuracy: 0.2414\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5264 - accuracy: 0.2690\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5379 - accuracy: 0.2897\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5536 - accuracy: 0.2828\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5800 - accuracy: 0.2414\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6517 - accuracy: 0.2414\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5458 - accuracy: 0.2828\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5985 - accuracy: 0.2276\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5454 - accuracy: 0.2966\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5457 - accuracy: 0.2414\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6483 - accuracy: 0.2759\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5650 - accuracy: 0.2690\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5681 - accuracy: 0.2759\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5978 - accuracy: 0.2345\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5743 - accuracy: 0.2690\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6347 - accuracy: 0.2276\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5772 - accuracy: 0.2414\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5747 - accuracy: 0.2483\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5687 - accuracy: 0.2759\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5316 - accuracy: 0.2690\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5288 - accuracy: 0.3034\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5422 - accuracy: 0.2828\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5662 - accuracy: 0.2621\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5370 - accuracy: 0.2828\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5335 - accuracy: 0.2483\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5340 - accuracy: 0.2966\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6217 - accuracy: 0.2897\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5486 - accuracy: 0.2966\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5492 - accuracy: 0.2828\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6439 - accuracy: 0.2207\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6164 - accuracy: 0.2207\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5979 - accuracy: 0.2276\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6059 - accuracy: 0.2000\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5857 - accuracy: 0.2483\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5801 - accuracy: 0.2069\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5895 - accuracy: 0.2207\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.6008 - accuracy: 0.2138\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5879 - accuracy: 0.2276\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5993 - accuracy: 0.2345\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6013 - accuracy: 0.2138\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6104 - accuracy: 0.1862\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5647 - accuracy: 0.2483\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5882 - accuracy: 0.2414\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5936 - accuracy: 0.2621\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5881 - accuracy: 0.3243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5880852937698364, 0.3243243098258972]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_3 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_3.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n",
    "\n",
    "model_3.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 27ms/step - loss: 34.2202 - accuracy: 0.1310 - val_loss: 8.1036 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 7.6123 - accuracy: 0.1793 - val_loss: 6.1818 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 6.0844 - accuracy: 0.1931 - val_loss: 5.9404 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.8836 - accuracy: 0.2483 - val_loss: 5.7774 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.7184 - accuracy: 0.2138 - val_loss: 5.6521 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.5926 - accuracy: 0.2345 - val_loss: 5.5279 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.5350 - accuracy: 0.2138 - val_loss: 5.4480 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.5615 - accuracy: 0.2069 - val_loss: 5.3794 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.3391 - accuracy: 0.2138 - val_loss: 5.2830 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.2653 - accuracy: 0.1655 - val_loss: 5.1896 - val_accuracy: 0.3243 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.1216 - accuracy: 0.3103 - val_loss: 5.1148 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 5.1458 - accuracy: 0.2138 - val_loss: 5.0408 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.0720 - accuracy: 0.2828 - val_loss: 4.9956 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.9034 - accuracy: 0.2966 - val_loss: 4.9740 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.9938 - accuracy: 0.2138 - val_loss: 4.8285 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.8019 - accuracy: 0.2759 - val_loss: 4.7636 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.7407 - accuracy: 0.3103 - val_loss: 4.5611 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.7419 - accuracy: 0.2759 - val_loss: 4.6762 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.6698 - accuracy: 0.2828 - val_loss: 4.6540 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.6597 - accuracy: 0.2897 - val_loss: 4.6203 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.6135 - accuracy: 0.2069 - val_loss: 4.6120 - val_accuracy: 0.2432 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.6026 - accuracy: 0.2828 - val_loss: 4.6002 - val_accuracy: 0.2432 - lr: 1.0000e-04\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.5611 - accuracy: 0.3784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.561069965362549, 0.37837839126586914]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_4.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_4.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_4.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "model_4.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "3/3 [==============================] - 1s 91ms/step - loss: 2.3551 - accuracy: 0.2207 - val_loss: 15.2924 - val_accuracy: 0.1892\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2.9239 - accuracy: 0.2621 - val_loss: 12.1130 - val_accuracy: 0.1892\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.3497 - accuracy: 0.3379 - val_loss: 3.5174 - val_accuracy: 0.1892\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 2.7979 - accuracy: 0.2414 - val_loss: 5.0240 - val_accuracy: 0.1892\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 2.3812 - accuracy: 0.3034 - val_loss: 6.6793 - val_accuracy: 0.1622\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 2.1652 - accuracy: 0.3448 - val_loss: 7.3753 - val_accuracy: 0.1622\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.4691 - accuracy: 0.2207 - val_loss: 5.2448 - val_accuracy: 0.1622\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.0687 - accuracy: 0.3310 - val_loss: 3.9160 - val_accuracy: 0.1892\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 2.3894 - accuracy: 0.3034 - val_loss: 5.1746 - val_accuracy: 0.1892\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2.0806 - accuracy: 0.3379 - val_loss: 6.1906 - val_accuracy: 0.1892\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 2.1630 - accuracy: 0.3103 - val_loss: 5.5201 - val_accuracy: 0.2162\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.8614 - accuracy: 0.4069 - val_loss: 3.6805 - val_accuracy: 0.2162\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 2.2278 - accuracy: 0.2897 - val_loss: 3.0718 - val_accuracy: 0.2162\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 2.0775 - accuracy: 0.3379 - val_loss: 3.1967 - val_accuracy: 0.2432\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 2.0622 - accuracy: 0.3103 - val_loss: 2.9228 - val_accuracy: 0.2162\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 2.0341 - accuracy: 0.4069 - val_loss: 2.8183 - val_accuracy: 0.2432\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.8634 - accuracy: 0.3586 - val_loss: 2.4157 - val_accuracy: 0.2703\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 1.8438 - accuracy: 0.3448 - val_loss: 2.5836 - val_accuracy: 0.2973\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.9277 - accuracy: 0.3862 - val_loss: 1.8539 - val_accuracy: 0.3243\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1.7822 - accuracy: 0.3724 - val_loss: 1.2648 - val_accuracy: 0.5676\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.9114 - accuracy: 0.3793 - val_loss: 1.4112 - val_accuracy: 0.4054\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1.5887 - accuracy: 0.4621 - val_loss: 1.6802 - val_accuracy: 0.2973\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.6347 - accuracy: 0.3931 - val_loss: 1.6933 - val_accuracy: 0.2703\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.8156 - accuracy: 0.3517 - val_loss: 1.6568 - val_accuracy: 0.3243\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1.9466 - accuracy: 0.3310 - val_loss: 1.7591 - val_accuracy: 0.3243\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.8444 - accuracy: 0.3862 - val_loss: 1.7225 - val_accuracy: 0.2973\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.6447 - accuracy: 0.4069 - val_loss: 1.8285 - val_accuracy: 0.3243\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.8744 - accuracy: 0.3586 - val_loss: 1.8826 - val_accuracy: 0.3243\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.4625 - accuracy: 0.4138 - val_loss: 1.8273 - val_accuracy: 0.4595\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.2987 - accuracy: 0.4483 - val_loss: 2.0734 - val_accuracy: 0.4324\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2648 - accuracy: 0.5676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2647937536239624, 0.5675675868988037]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_5 = Sequential()\n",
    "model_5.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_5.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(256))\n",
    "model_5.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(128))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "model_5.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_5.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_5.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "model_5.evaluate(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
