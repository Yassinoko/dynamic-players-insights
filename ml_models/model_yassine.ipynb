{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pre-trained model\n",
    "from keras.applications import ResNet50V2\n",
    "\n",
    "# Importing important layers of Keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Importing data functions\n",
    "from data_library.data_processing import black_white, crop, delete_face_images, encode, to_cat\n",
    "\n",
    "# Importing preprocessing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Saving the model in a variable\n",
    "resnet = ResNet50V2(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Classes from Real Madrid (cropped_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_folder = \"../data_processing/raw_data/faces/\"\n",
    "cropped_faces_directory = \"../data_processing/raw_data/cropped_faces\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RUN ONLY IF YOU DONT HAVE THE CROPPED FACES YET\n",
    "# black_white(faces_folder)\n",
    "# crop(faces_folder, cropped_faces_directory)\n",
    "# delete_face_images(cropped_faces_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = encode(cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 14:17:47.472006: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 224ms/step - loss: 2.3223 - accuracy: 0.2564 - val_loss: 23.9073 - val_accuracy: 0.0500\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 167ms/step - loss: 1.3502 - accuracy: 0.5064 - val_loss: 60.0865 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 176ms/step - loss: 0.8245 - accuracy: 0.7885 - val_loss: 39.2152 - val_accuracy: 0.0750\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 0.7260 - accuracy: 0.8077 - val_loss: 23.0652 - val_accuracy: 0.1250\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.5079 - accuracy: 0.8397 - val_loss: 21.9407 - val_accuracy: 0.2000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.2986 - accuracy: 0.9167 - val_loss: 18.1469 - val_accuracy: 0.2000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.1976 - accuracy: 0.9423 - val_loss: 12.2690 - val_accuracy: 0.2000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.1883 - accuracy: 0.9551 - val_loss: 15.6459 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.3598 - accuracy: 0.9103 - val_loss: 7.8903 - val_accuracy: 0.3000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 202ms/step - loss: 0.3190 - accuracy: 0.9103 - val_loss: 10.5489 - val_accuracy: 0.1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e70f21a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 41ms/step - loss: 10.4259 - accuracy: 0.2041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.425868034362793, 0.20408163964748383]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 502.6071 - accuracy: 0.1582\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 342.1305 - accuracy: 0.1122\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 91.2219 - accuracy: 0.1224\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 14.4351 - accuracy: 0.1327\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2588 - accuracy: 0.0867\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 3.1977 - accuracy: 0.1173\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.8643 - accuracy: 0.1531\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.5858 - accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.6589 - accuracy: 0.1480\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.6923 - accuracy: 0.1276\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.4535 - accuracy: 0.1327\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.4169 - accuracy: 0.1429\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3646 - accuracy: 0.1684\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.5092 - accuracy: 0.2245\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.4098 - accuracy: 0.1480\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.5700 - accuracy: 0.1378\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3813 - accuracy: 0.1684\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.5241 - accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.5129 - accuracy: 0.1633\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2.4559 - accuracy: 0.1684\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.4231 - accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2707 - accuracy: 0.1939\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.5840 - accuracy: 0.1224\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2751 - accuracy: 0.1786\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.4736 - accuracy: 0.1531\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3235 - accuracy: 0.1888\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.3006 - accuracy: 0.1888\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2668 - accuracy: 0.1531\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.3563 - accuracy: 0.1990\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3259 - accuracy: 0.1633\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2690 - accuracy: 0.1837\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1915 - accuracy: 0.2194\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3019 - accuracy: 0.2194\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2369 - accuracy: 0.2041\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1855 - accuracy: 0.2194\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.3626 - accuracy: 0.1327\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3072 - accuracy: 0.1633\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2848 - accuracy: 0.1582\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2797 - accuracy: 0.2194\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1991 - accuracy: 0.2449\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2109 - accuracy: 0.2245\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2705 - accuracy: 0.1582\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2992 - accuracy: 0.1684\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2622 - accuracy: 0.1786\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1944 - accuracy: 0.2245\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.1438 - accuracy: 0.2245\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.1811 - accuracy: 0.2092\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1497 - accuracy: 0.2041\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.3094 - accuracy: 0.1633\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2407 - accuracy: 0.2041\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1009 - accuracy: 0.2602\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.2541 - accuracy: 0.1735\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.0427 - accuracy: 0.2908\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1815 - accuracy: 0.2296\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0979 - accuracy: 0.2092\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1630 - accuracy: 0.1990\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1270 - accuracy: 0.2347\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1763 - accuracy: 0.2398\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.2107 - accuracy: 0.2500\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0918 - accuracy: 0.2194\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3413 - accuracy: 0.2347\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2097 - accuracy: 0.2398\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1647 - accuracy: 0.2041\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1832 - accuracy: 0.2194\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2647 - accuracy: 0.2194\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2.1173 - accuracy: 0.2398\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.3490 - accuracy: 0.2449\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1423 - accuracy: 0.2143\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0789 - accuracy: 0.2755\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.1629 - accuracy: 0.2857\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1171 - accuracy: 0.2449\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1429 - accuracy: 0.2551\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2160 - accuracy: 0.2194\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.2775 - accuracy: 0.2092\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1771 - accuracy: 0.2092\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.2836 - accuracy: 0.2245\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.1804 - accuracy: 0.2653\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1222 - accuracy: 0.2449\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1154 - accuracy: 0.2245\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.0724 - accuracy: 0.2092\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0106 - accuracy: 0.2653\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1134 - accuracy: 0.2245\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.0738 - accuracy: 0.2500\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.1420 - accuracy: 0.2755\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0936 - accuracy: 0.2806\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1163 - accuracy: 0.2500\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1127 - accuracy: 0.2602\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.1447 - accuracy: 0.2551\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0780 - accuracy: 0.2704\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0450 - accuracy: 0.2653\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.0724 - accuracy: 0.2449\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2.0873 - accuracy: 0.2908\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0703 - accuracy: 0.2449\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.9246 - accuracy: 0.2908\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.0248 - accuracy: 0.3214\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0771 - accuracy: 0.2500\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0383 - accuracy: 0.2653\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.0761 - accuracy: 0.2347\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.0472 - accuracy: 0.2806\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.0000 - accuracy: 0.2653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e2d19570>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_2 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_2.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3625 - accuracy: 0.2653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3625125885009766, 0.26530611515045166]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 123.3358 - accuracy: 0.1173\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 10.3514 - accuracy: 0.0918\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.6886 - accuracy: 0.0867\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3335 - accuracy: 0.0969\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.3457 - accuracy: 0.0969\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3029 - accuracy: 0.0714\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3216 - accuracy: 0.0969\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.3272 - accuracy: 0.0969\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3052 - accuracy: 0.1224\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3560 - accuracy: 0.1020\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2876 - accuracy: 0.0969\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3410 - accuracy: 0.0816\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2793 - accuracy: 0.1173\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2969 - accuracy: 0.1224\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.3152 - accuracy: 0.0816\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2975 - accuracy: 0.1224\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2958 - accuracy: 0.0867\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.3030 - accuracy: 0.1020\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3059 - accuracy: 0.1173\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2980 - accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3060 - accuracy: 0.1071\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2992 - accuracy: 0.1071\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.3030 - accuracy: 0.1020\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3314 - accuracy: 0.0969\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3000 - accuracy: 0.1327\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.3085 - accuracy: 0.1633\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3063 - accuracy: 0.1071\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3328 - accuracy: 0.0969\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2860 - accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2808 - accuracy: 0.1480\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2925 - accuracy: 0.1122\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2967 - accuracy: 0.1173\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3256 - accuracy: 0.1378\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3026 - accuracy: 0.1327\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2806 - accuracy: 0.1327\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3372 - accuracy: 0.1173\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.3215 - accuracy: 0.1735\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3017 - accuracy: 0.1276\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3071 - accuracy: 0.0969\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.3023 - accuracy: 0.1327\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3020 - accuracy: 0.1327\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2917 - accuracy: 0.1378\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2974 - accuracy: 0.1327\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2868 - accuracy: 0.1684\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 2.2898 - accuracy: 0.1531\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2840 - accuracy: 0.1327\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 2.2920 - accuracy: 0.1327\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2881 - accuracy: 0.1276\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2861 - accuracy: 0.1531\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2753 - accuracy: 0.1531\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2799 - accuracy: 0.1633\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2792 - accuracy: 0.1735\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3004 - accuracy: 0.1276\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2942 - accuracy: 0.1224\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2873 - accuracy: 0.1224\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2761 - accuracy: 0.1582\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2879 - accuracy: 0.1531\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3209 - accuracy: 0.1327\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2983 - accuracy: 0.1378\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3096 - accuracy: 0.1378\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2865 - accuracy: 0.1735\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3084 - accuracy: 0.1531\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2900 - accuracy: 0.1429\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2883 - accuracy: 0.1327\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2784 - accuracy: 0.1531\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2867 - accuracy: 0.1173\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2788 - accuracy: 0.1531\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.2873 - accuracy: 0.1327\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2748 - accuracy: 0.1173\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.3124 - accuracy: 0.1122\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2.2944 - accuracy: 0.1378\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2893 - accuracy: 0.1684\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 2.2955 - accuracy: 0.1531\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2964 - accuracy: 0.1582\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3236 - accuracy: 0.1173\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2814 - accuracy: 0.1276\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2975 - accuracy: 0.1378\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2801 - accuracy: 0.1276\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2726 - accuracy: 0.1531\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2566 - accuracy: 0.1735\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.3386 - accuracy: 0.1224\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3000 - accuracy: 0.1480\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2734 - accuracy: 0.1429\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2869 - accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2944 - accuracy: 0.1633\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2782 - accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.3203 - accuracy: 0.1071\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3095 - accuracy: 0.1276\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2691 - accuracy: 0.1684\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2812 - accuracy: 0.1531\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3030 - accuracy: 0.1837\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2769 - accuracy: 0.1786\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2768 - accuracy: 0.1582\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2818 - accuracy: 0.1327\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 2.2934 - accuracy: 0.1276\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2966 - accuracy: 0.1224\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2636 - accuracy: 0.1786\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.2579 - accuracy: 0.1582\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2768 - accuracy: 0.1684\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 2.2702 - accuracy: 0.1480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ed6eb940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_3 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_3.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3279 - accuracy: 0.0816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3279380798339844, 0.08163265138864517]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 25ms/step - loss: 20.3172 - accuracy: 0.1224 - val_loss: 7.4262 - val_accuracy: 0.0816 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 7.1977 - accuracy: 0.1276 - val_loss: 6.8212 - val_accuracy: 0.1224 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 6.7182 - accuracy: 0.1122 - val_loss: 6.5903 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 6.4913 - accuracy: 0.1327 - val_loss: 6.3649 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 6.3076 - accuracy: 0.1582 - val_loss: 6.2227 - val_accuracy: 0.2245 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 6.1535 - accuracy: 0.1480 - val_loss: 6.0806 - val_accuracy: 0.1224 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.9992 - accuracy: 0.1327 - val_loss: 5.8871 - val_accuracy: 0.1633 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.9208 - accuracy: 0.1480 - val_loss: 5.8412 - val_accuracy: 0.1633 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 5.7977 - accuracy: 0.1582 - val_loss: 5.7401 - val_accuracy: 0.1429 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.6793 - accuracy: 0.1480 - val_loss: 5.6457 - val_accuracy: 0.0816 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 5.5943 - accuracy: 0.1990 - val_loss: 5.5987 - val_accuracy: 0.0204 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 5.4763 - accuracy: 0.1633 - val_loss: 5.4398 - val_accuracy: 0.1429 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.3677 - accuracy: 0.1786 - val_loss: 5.3683 - val_accuracy: 0.1429 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.2752 - accuracy: 0.1735 - val_loss: 5.4465 - val_accuracy: 0.0612 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.1765 - accuracy: 0.2092 - val_loss: 5.3364 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 5.1770 - accuracy: 0.1888 - val_loss: 5.0559 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 5.0483 - accuracy: 0.1939 - val_loss: 5.0558 - val_accuracy: 0.1633 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 5.0064 - accuracy: 0.2092 - val_loss: 5.0195 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.9613 - accuracy: 0.1786 - val_loss: 5.0221 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.8231 - accuracy: 0.2245 - val_loss: 4.7964 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.7872 - accuracy: 0.2194 - val_loss: 4.7376 - val_accuracy: 0.1633 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 4.6242 - accuracy: 0.2551 - val_loss: 4.7940 - val_accuracy: 0.1429 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.5878 - accuracy: 0.2245 - val_loss: 4.5260 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 4.5181 - accuracy: 0.2296 - val_loss: 4.5061 - val_accuracy: 0.1429 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.5283 - accuracy: 0.2092 - val_loss: 4.5493 - val_accuracy: 0.3265 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.3524 - accuracy: 0.2449 - val_loss: 4.4576 - val_accuracy: 0.1429 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.3362 - accuracy: 0.2908 - val_loss: 4.3437 - val_accuracy: 0.2857 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.2954 - accuracy: 0.2500 - val_loss: 4.4897 - val_accuracy: 0.1020 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.3485 - accuracy: 0.1888 - val_loss: 4.2244 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.1582 - accuracy: 0.2347 - val_loss: 4.1872 - val_accuracy: 0.1633 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.1904 - accuracy: 0.2347 - val_loss: 4.0905 - val_accuracy: 0.2653 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.1306 - accuracy: 0.2296 - val_loss: 4.1709 - val_accuracy: 0.1837 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 4.0420 - accuracy: 0.2806 - val_loss: 3.9337 - val_accuracy: 0.2449 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 4.0085 - accuracy: 0.2908 - val_loss: 4.0150 - val_accuracy: 0.2041 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 3.9850 - accuracy: 0.2755 - val_loss: 3.9367 - val_accuracy: 0.2449 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.9222 - accuracy: 0.2653 - val_loss: 3.9649 - val_accuracy: 0.1429 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.8744 - accuracy: 0.2704 - val_loss: 3.9481 - val_accuracy: 0.1224 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 3.8253 - accuracy: 0.3214 - val_loss: 3.8454 - val_accuracy: 0.2245 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.7857 - accuracy: 0.2806 - val_loss: 3.8314 - val_accuracy: 0.2041 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.7730 - accuracy: 0.2806 - val_loss: 3.7699 - val_accuracy: 0.1837 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.7489 - accuracy: 0.3163 - val_loss: 3.7354 - val_accuracy: 0.2041 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.6920 - accuracy: 0.3367 - val_loss: 3.7065 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.7018 - accuracy: 0.3214 - val_loss: 3.6870 - val_accuracy: 0.2857 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.7485 - accuracy: 0.2959 - val_loss: 3.6525 - val_accuracy: 0.3061 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 3.6035 - accuracy: 0.3112 - val_loss: 3.6637 - val_accuracy: 0.2653 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.6293 - accuracy: 0.3673 - val_loss: 3.6513 - val_accuracy: 0.3469 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.6732 - accuracy: 0.3622 - val_loss: 3.6762 - val_accuracy: 0.2449 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.6493 - accuracy: 0.3571 - val_loss: 3.6773 - val_accuracy: 0.2653 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.6262 - accuracy: 0.3827 - val_loss: 3.5724 - val_accuracy: 0.3878 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.6616 - accuracy: 0.3316 - val_loss: 3.5803 - val_accuracy: 0.3469 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.5582 - accuracy: 0.4082 - val_loss: 3.5498 - val_accuracy: 0.3061 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.6206 - accuracy: 0.3367 - val_loss: 3.5383 - val_accuracy: 0.3469 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.5184 - accuracy: 0.3622 - val_loss: 3.5108 - val_accuracy: 0.3673 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.5298 - accuracy: 0.3622 - val_loss: 3.7719 - val_accuracy: 0.3061 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.6569 - accuracy: 0.2959 - val_loss: 3.6098 - val_accuracy: 0.2041 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 3.5963 - accuracy: 0.3265 - val_loss: 3.5280 - val_accuracy: 0.3469 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 3.4924 - accuracy: 0.3469 - val_loss: 3.5304 - val_accuracy: 0.3469 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 3.5360 - accuracy: 0.3469 - val_loss: 3.5273 - val_accuracy: 0.3469 - lr: 1.0000e-05\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5108 - accuracy: 0.3673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5108349323272705, 0.36734694242477417]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_4.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_4.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_4.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_4.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "model_4.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 107ms/step - loss: 3.8174 - accuracy: 0.1224 - val_loss: 11.8685 - val_accuracy: 0.0612\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 3.6347 - accuracy: 0.1633 - val_loss: 6.1903 - val_accuracy: 0.1224\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.1312 - accuracy: 0.1684 - val_loss: 5.2107 - val_accuracy: 0.0612\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.3831 - accuracy: 0.1582 - val_loss: 5.4113 - val_accuracy: 0.1224\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 3.4657 - accuracy: 0.1429 - val_loss: 5.5982 - val_accuracy: 0.0408\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 3.0794 - accuracy: 0.2041 - val_loss: 5.4814 - val_accuracy: 0.1020\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.9666 - accuracy: 0.2245 - val_loss: 6.3304 - val_accuracy: 0.0816\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.2095 - accuracy: 0.1582 - val_loss: 6.7428 - val_accuracy: 0.0612\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.8975 - accuracy: 0.2092 - val_loss: 6.1750 - val_accuracy: 0.0408\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.0400 - accuracy: 0.1837 - val_loss: 4.8489 - val_accuracy: 0.1429\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.9440 - accuracy: 0.2143 - val_loss: 4.1427 - val_accuracy: 0.1633\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.7840 - accuracy: 0.2245 - val_loss: 3.8815 - val_accuracy: 0.1633\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.9174 - accuracy: 0.2296 - val_loss: 3.4195 - val_accuracy: 0.1633\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.9169 - accuracy: 0.1990 - val_loss: 4.1079 - val_accuracy: 0.0612\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.0387 - accuracy: 0.2449 - val_loss: 4.9249 - val_accuracy: 0.0612\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.7654 - accuracy: 0.2449 - val_loss: 4.8092 - val_accuracy: 0.0816\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.7757 - accuracy: 0.2449 - val_loss: 4.4858 - val_accuracy: 0.0612\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.9774 - accuracy: 0.2398 - val_loss: 3.6353 - val_accuracy: 0.0816\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.7489 - accuracy: 0.2653 - val_loss: 2.5538 - val_accuracy: 0.1224\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.7784 - accuracy: 0.2806 - val_loss: 3.4838 - val_accuracy: 0.0816\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.8987 - accuracy: 0.2347 - val_loss: 4.3651 - val_accuracy: 0.0816\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.8918 - accuracy: 0.2449 - val_loss: 3.8041 - val_accuracy: 0.0612\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.9464 - accuracy: 0.2347 - val_loss: 2.6772 - val_accuracy: 0.2245\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 2.7006 - accuracy: 0.2500 - val_loss: 2.2754 - val_accuracy: 0.2449\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.6235 - accuracy: 0.2449 - val_loss: 2.8864 - val_accuracy: 0.2245\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 2.6073 - accuracy: 0.2551 - val_loss: 3.2646 - val_accuracy: 0.2041\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.5837 - accuracy: 0.2551 - val_loss: 3.1501 - val_accuracy: 0.1020\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.2583 - accuracy: 0.2908 - val_loss: 2.8353 - val_accuracy: 0.1633\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.6686 - accuracy: 0.2449 - val_loss: 2.6571 - val_accuracy: 0.2041\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.4434 - accuracy: 0.2959 - val_loss: 2.5277 - val_accuracy: 0.1633\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.6739 - accuracy: 0.2092 - val_loss: 2.6542 - val_accuracy: 0.1633\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.5673 - accuracy: 0.2398 - val_loss: 2.5672 - val_accuracy: 0.1633\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.5077 - accuracy: 0.2296 - val_loss: 2.5134 - val_accuracy: 0.2245\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.5761 - accuracy: 0.3061 - val_loss: 2.6431 - val_accuracy: 0.3265\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2754 - accuracy: 0.2449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.275377035140991, 0.2448979616165161]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_5 = Sequential()\n",
    "model_5.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_5.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(256))\n",
    "model_5.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(128))\n",
    "model_5.add(LeakyReLU(alpha=0.1))\n",
    "model_5.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_5.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_5.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "model_5.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video - 10 Classes (video_cropped_faces_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_cropped_faces_directory = \"../data_processing/raw_data/video_cropped_faces_0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = encode(video_cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 300ms/step - loss: 2.4580 - accuracy: 0.3200 - val_loss: 5.4721 - val_accuracy: 0.3846\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.2694 - accuracy: 0.7000 - val_loss: 6.5433 - val_accuracy: 0.3077\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.7697 - accuracy: 0.7800 - val_loss: 40.3561 - val_accuracy: 0.0769\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.3518 - accuracy: 0.9000 - val_loss: 48.2298 - val_accuracy: 0.0769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f847e650>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model_6 = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_6.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_6.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 5.3977 - accuracy: 0.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.397744178771973, 0.4375]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 367.1548 - accuracy: 0.0794\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 453.9112 - accuracy: 0.2063\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 259.1899 - accuracy: 0.1270\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 171.7191 - accuracy: 0.0952\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 125.9402 - accuracy: 0.0635\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 102.1645 - accuracy: 0.2698\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 85.0283 - accuracy: 0.2698\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 64.5194 - accuracy: 0.3492\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 44.7028 - accuracy: 0.3492\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 40.3336 - accuracy: 0.2222\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 27.3837 - accuracy: 0.2222\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 17.8482 - accuracy: 0.2540\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 14.7586 - accuracy: 0.2698\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 9.9267 - accuracy: 0.3016\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 7.1551 - accuracy: 0.2540\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 5.3179 - accuracy: 0.2540\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.8536 - accuracy: 0.2857\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.4814 - accuracy: 0.4127\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.9243 - accuracy: 0.4286\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.1423 - accuracy: 0.4127\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.9977 - accuracy: 0.3968\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.6240 - accuracy: 0.4127\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.9241 - accuracy: 0.3175\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.7132 - accuracy: 0.3651\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.2590 - accuracy: 0.3175\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7762 - accuracy: 0.3968\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.5531 - accuracy: 0.3968\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0823 - accuracy: 0.3175\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7366 - accuracy: 0.3810\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9486 - accuracy: 0.3968\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8893 - accuracy: 0.3968\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8317 - accuracy: 0.4286\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1705 - accuracy: 0.3175\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.6046 - accuracy: 0.3651\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.1842 - accuracy: 0.4127\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.3350 - accuracy: 0.4762\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0533 - accuracy: 0.4444\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0641 - accuracy: 0.4286\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9091 - accuracy: 0.4127\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6249 - accuracy: 0.4444\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8253 - accuracy: 0.4286\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5070 - accuracy: 0.5873\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.2207 - accuracy: 0.4921\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6102 - accuracy: 0.3968\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7202 - accuracy: 0.5079\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7913 - accuracy: 0.3968\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.8561 - accuracy: 0.4603\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8112 - accuracy: 0.4921\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.9059 - accuracy: 0.4444\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8356 - accuracy: 0.4286\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.4409 - accuracy: 0.4603\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.8213 - accuracy: 0.4286\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9165 - accuracy: 0.4762\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5515 - accuracy: 0.4762\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6559 - accuracy: 0.4286\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6359 - accuracy: 0.5714\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6719 - accuracy: 0.4762\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.5388 - accuracy: 0.4921\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.5026 - accuracy: 0.5079\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.5760 - accuracy: 0.5397\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.4841 - accuracy: 0.5873\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2193 - accuracy: 0.4603\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.5316 - accuracy: 0.4762\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.4397 - accuracy: 0.5238\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.4729 - accuracy: 0.5397\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9676 - accuracy: 0.4603\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5514 - accuracy: 0.4921\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.1743 - accuracy: 0.4444\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.4481 - accuracy: 0.5079\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4319 - accuracy: 0.5556\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6916 - accuracy: 0.4762\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7358 - accuracy: 0.4286\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.5626 - accuracy: 0.5238\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4256 - accuracy: 0.6190\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8592 - accuracy: 0.4921\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.5814 - accuracy: 0.5079\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6062 - accuracy: 0.5714\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5482 - accuracy: 0.5714\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.5599 - accuracy: 0.4921\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7168 - accuracy: 0.4444\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5597 - accuracy: 0.5079\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2052 - accuracy: 0.5873\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7645 - accuracy: 0.3492\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3201 - accuracy: 0.5397\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.4821 - accuracy: 0.5556\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5304 - accuracy: 0.5873\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5172 - accuracy: 0.5556\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.3119 - accuracy: 0.5873\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.4312 - accuracy: 0.5556\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2965 - accuracy: 0.5873\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.5162 - accuracy: 0.5873\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4157 - accuracy: 0.5397\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6080 - accuracy: 0.5079\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2101 - accuracy: 0.6349\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7454 - accuracy: 0.4762\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6231 - accuracy: 0.5714\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.1372 - accuracy: 0.6032\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6909 - accuracy: 0.4921\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5497 - accuracy: 0.5079\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7821 - accuracy: 0.4603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x32b3fd9f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_7 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_7.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_7.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0431 - accuracy: 0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.043073296546936, 0.5625]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 21.5049 - accuracy: 0.0952\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 21.8414 - accuracy: 0.0635\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.4386 - accuracy: 0.0952\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.1465 - accuracy: 0.1746\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.7752 - accuracy: 0.0952\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.4116 - accuracy: 0.1905\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.7030 - accuracy: 0.1111\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3904 - accuracy: 0.0794\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.3126 - accuracy: 0.0952\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3411 - accuracy: 0.2698\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2926 - accuracy: 0.2063\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.4069 - accuracy: 0.2222\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.4290 - accuracy: 0.2222\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2696 - accuracy: 0.1905\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2981 - accuracy: 0.2698\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3104 - accuracy: 0.2063\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2707 - accuracy: 0.2698\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2553 - accuracy: 0.2381\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.3279 - accuracy: 0.3016\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2426 - accuracy: 0.3492\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3370 - accuracy: 0.2857\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3397 - accuracy: 0.3016\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2221 - accuracy: 0.2857\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1679 - accuracy: 0.2857\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2197 - accuracy: 0.2540\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1819 - accuracy: 0.3016\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1292 - accuracy: 0.2698\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1725 - accuracy: 0.3810\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2434 - accuracy: 0.2381\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.1347 - accuracy: 0.2857\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3183 - accuracy: 0.3175\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1356 - accuracy: 0.3333\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2160 - accuracy: 0.2698\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1383 - accuracy: 0.3651\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1846 - accuracy: 0.2857\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1068 - accuracy: 0.3016\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1591 - accuracy: 0.2698\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.1934 - accuracy: 0.2698\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1298 - accuracy: 0.3016\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1570 - accuracy: 0.3492\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.2795 - accuracy: 0.3016\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1817 - accuracy: 0.3810\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1315 - accuracy: 0.3651\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1343 - accuracy: 0.3492\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0157 - accuracy: 0.3175\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0908 - accuracy: 0.3333\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.2249 - accuracy: 0.2698\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0829 - accuracy: 0.3492\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2437 - accuracy: 0.3333\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.2939 - accuracy: 0.2857\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1070 - accuracy: 0.3016\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1735 - accuracy: 0.3016\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0525 - accuracy: 0.4286\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0025 - accuracy: 0.3968\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0830 - accuracy: 0.2540\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.9223 - accuracy: 0.4127\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3988 - accuracy: 0.2381\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9653 - accuracy: 0.3175\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1543 - accuracy: 0.3016\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1654 - accuracy: 0.3175\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1617 - accuracy: 0.2063\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3319 - accuracy: 0.2540\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0959 - accuracy: 0.2698\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0051 - accuracy: 0.2857\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1209 - accuracy: 0.3175\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0415 - accuracy: 0.3651\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0814 - accuracy: 0.3175\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0411 - accuracy: 0.3651\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.9869 - accuracy: 0.3333\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1236 - accuracy: 0.3175\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.9495 - accuracy: 0.3333\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.9967 - accuracy: 0.3968\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.8831 - accuracy: 0.3016\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.9010 - accuracy: 0.3492\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0476 - accuracy: 0.3016\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0695 - accuracy: 0.3016\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0072 - accuracy: 0.2698\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0083 - accuracy: 0.3968\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9117 - accuracy: 0.3333\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1280 - accuracy: 0.3651\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1216 - accuracy: 0.3016\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9995 - accuracy: 0.3810\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0927 - accuracy: 0.2698\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9074 - accuracy: 0.3492\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9783 - accuracy: 0.2540\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9362 - accuracy: 0.3333\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0861 - accuracy: 0.2698\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9274 - accuracy: 0.4444\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9438 - accuracy: 0.3968\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0244 - accuracy: 0.3810\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9197 - accuracy: 0.3810\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.9160 - accuracy: 0.3810\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0276 - accuracy: 0.3492\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9084 - accuracy: 0.3333\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8984 - accuracy: 0.4286\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.9301 - accuracy: 0.4127\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8941 - accuracy: 0.3016\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.8301 - accuracy: 0.3968\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1871 - accuracy: 0.3651\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9932 - accuracy: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3192fdd80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_8 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_8.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_8.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step - loss: 1.8340 - accuracy: 0.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.833991289138794, 0.4375]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 1s - loss: 24.3944 - accuracy: 0.0000e+00WARNING:tensorflow:5 out of the last 78 calls to <function Model.make_test_function.<locals>.test_function at 0x2f2539870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 1s 49ms/step - loss: 21.0827 - accuracy: 0.0794 - val_loss: 12.9664 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 12.0272 - accuracy: 0.1111 - val_loss: 8.6023 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 8.8311 - accuracy: 0.1746 - val_loss: 7.5499 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 7.5964 - accuracy: 0.1111 - val_loss: 7.1713 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 7.0736 - accuracy: 0.2381 - val_loss: 7.0089 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 6.9963 - accuracy: 0.2222 - val_loss: 6.8592 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.8719 - accuracy: 0.1905 - val_loss: 6.6824 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 6.6155 - accuracy: 0.2698 - val_loss: 6.5665 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 6.4789 - accuracy: 0.3492 - val_loss: 6.4873 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 6.4412 - accuracy: 0.2063 - val_loss: 6.4789 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 6.3098 - accuracy: 0.4286 - val_loss: 6.3572 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 6.2853 - accuracy: 0.3016 - val_loss: 6.3065 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 6.3218 - accuracy: 0.2698 - val_loss: 6.2016 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 6.1019 - accuracy: 0.1905 - val_loss: 6.1211 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 6.0483 - accuracy: 0.3175 - val_loss: 5.9967 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 5.9399 - accuracy: 0.2857 - val_loss: 5.8894 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 5.7801 - accuracy: 0.3810 - val_loss: 5.8268 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 5.6508 - accuracy: 0.3651 - val_loss: 5.7240 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 5.7084 - accuracy: 0.4127 - val_loss: 5.6664 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 5.5564 - accuracy: 0.3492 - val_loss: 5.6288 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 5.6983 - accuracy: 0.3333 - val_loss: 5.5996 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.5103 - accuracy: 0.3333 - val_loss: 5.7204 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 5.4975 - accuracy: 0.3016 - val_loss: 5.5256 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.5969 - accuracy: 0.2540 - val_loss: 5.4134 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 5.4141 - accuracy: 0.4286 - val_loss: 5.3381 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.5938 - accuracy: 0.3333 - val_loss: 5.2982 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 5.4431 - accuracy: 0.3333 - val_loss: 5.3113 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.1679 - accuracy: 0.3810 - val_loss: 5.1591 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.2502 - accuracy: 0.3175 - val_loss: 5.0605 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.2290 - accuracy: 0.4127 - val_loss: 5.0001 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 4.9710 - accuracy: 0.3968 - val_loss: 4.8510 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 5.1160 - accuracy: 0.3016 - val_loss: 4.7061 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 4.8509 - accuracy: 0.5238 - val_loss: 4.9115 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 5.1838 - accuracy: 0.3968 - val_loss: 4.6487 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 4.8350 - accuracy: 0.4444 - val_loss: 4.6744 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 4.9739 - accuracy: 0.3333 - val_loss: 4.6069 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 4.8397 - accuracy: 0.5079 - val_loss: 4.5450 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.8145 - accuracy: 0.3333 - val_loss: 4.3894 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 4.6003 - accuracy: 0.4286 - val_loss: 4.4236 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 4.6218 - accuracy: 0.4444 - val_loss: 4.3737 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.7456 - accuracy: 0.3810 - val_loss: 4.3464 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 4.6205 - accuracy: 0.4762 - val_loss: 4.4395 - val_accuracy: 0.4375 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.5388 - accuracy: 0.4603 - val_loss: 4.4472 - val_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.6139 - accuracy: 0.4286 - val_loss: 4.5834 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.4638 - accuracy: 0.4603 - val_loss: 4.5491 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.5504 - accuracy: 0.4286 - val_loss: 4.5226 - val_accuracy: 0.5000 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_9 = Sequential()\n",
    "model_9.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_9.add(MaxPooling2D((2, 2)))\n",
    "model_9.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_9.add(MaxPooling2D((2, 2)))\n",
    "model_9.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_9.add(MaxPooling2D((2, 2)))\n",
    "model_9.add(Flatten())\n",
    "model_9.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_9.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_9.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_9.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_9.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_9.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 4.3464 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.346424102783203, 0.5]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 3.0810 - accuracy: 0.0952 - val_loss: 12.0135 - val_accuracy: 0.0625\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 3.0917 - accuracy: 0.1746 - val_loss: 14.8459 - val_accuracy: 0.1250\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.2399 - accuracy: 0.1270 - val_loss: 13.2046 - val_accuracy: 0.1250\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 3.0123 - accuracy: 0.2222 - val_loss: 7.9506 - val_accuracy: 0.1250\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 3.0556 - accuracy: 0.1905 - val_loss: 7.2680 - val_accuracy: 0.0625\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.6237 - accuracy: 0.3651 - val_loss: 6.1577 - val_accuracy: 0.0625\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.5636 - accuracy: 0.3016 - val_loss: 4.6323 - val_accuracy: 0.0625\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.1485 - accuracy: 0.2698 - val_loss: 3.7410 - val_accuracy: 0.2500\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.8592 - accuracy: 0.4286 - val_loss: 3.0539 - val_accuracy: 0.3125\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.4104 - accuracy: 0.4444 - val_loss: 2.4832 - val_accuracy: 0.2500\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.8377 - accuracy: 0.3175 - val_loss: 2.2518 - val_accuracy: 0.2500\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.8128 - accuracy: 0.2540 - val_loss: 2.1173 - val_accuracy: 0.3750\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.0367 - accuracy: 0.4286 - val_loss: 1.9134 - val_accuracy: 0.4375\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.0563 - accuracy: 0.3651 - val_loss: 1.8204 - val_accuracy: 0.4375\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.0746 - accuracy: 0.4127 - val_loss: 1.9392 - val_accuracy: 0.3750\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.0995 - accuracy: 0.4127 - val_loss: 2.2279 - val_accuracy: 0.0625\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 2.3118 - accuracy: 0.4444 - val_loss: 2.5958 - val_accuracy: 0.0625\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.8654 - accuracy: 0.4762 - val_loss: 2.8059 - val_accuracy: 0.1250\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.6642 - accuracy: 0.3333 - val_loss: 2.5777 - val_accuracy: 0.1250\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.1850 - accuracy: 0.3968 - val_loss: 2.4214 - val_accuracy: 0.0625\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.9112 - accuracy: 0.4444 - val_loss: 2.3404 - val_accuracy: 0.0625\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.4688 - accuracy: 0.4921 - val_loss: 2.3242 - val_accuracy: 0.0625\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.7412 - accuracy: 0.5079 - val_loss: 2.3037 - val_accuracy: 0.0625\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8569 - accuracy: 0.5079 - val_loss: 2.2371 - val_accuracy: 0.0625\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_10 = Sequential()\n",
    "model_10.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_10.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_10.add(MaxPooling2D((2, 2)))\n",
    "model_10.add(BatchNormalization())\n",
    "model_10.add(Flatten())\n",
    "model_10.add(Dense(256))\n",
    "model_10.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_10.add(Dropout(0.5))\n",
    "model_10.add(Dense(128))\n",
    "model_10.add(LeakyReLU(alpha=0.1))\n",
    "model_10.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_10.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_10.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8204 - accuracy: 0.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.820360779762268, 0.4375]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video + Getty - 10 Classes (video_cropped_faces_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_faces_directory = \"../data_processing/raw_data/video_cropped_faces_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = encode(cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 5s 238ms/step - loss: 2.2978 - accuracy: 0.3333 - val_loss: 500.6413 - val_accuracy: 0.0962\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 1.5708 - accuracy: 0.4657 - val_loss: 230.2468 - val_accuracy: 0.0769\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 1.1044 - accuracy: 0.6716 - val_loss: 66.1253 - val_accuracy: 0.0962\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 1.0823 - accuracy: 0.7157 - val_loss: 63.3593 - val_accuracy: 0.1731\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.6578 - accuracy: 0.8039 - val_loss: 124.3338 - val_accuracy: 0.1731\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.4426 - accuracy: 0.8725 - val_loss: 174.7360 - val_accuracy: 0.1346\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.4038 - accuracy: 0.8873 - val_loss: 222.5828 - val_accuracy: 0.1154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3198bd030>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model_11 = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_11.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_11.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 89ms/step - loss: 102.5028 - accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[102.50282287597656, 0.25]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_11.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 918.5413 - accuracy: 0.0781\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 316.7346 - accuracy: 0.1055\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 95.3333 - accuracy: 0.1055\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 42.5824 - accuracy: 0.0859\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 23.1921 - accuracy: 0.1562\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 11.2264 - accuracy: 0.1328\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 5.6333 - accuracy: 0.1133\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 4.0300 - accuracy: 0.1289\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 3.5746 - accuracy: 0.1250\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 3.2352 - accuracy: 0.1719\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 3.4423 - accuracy: 0.1758\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.9303 - accuracy: 0.1797\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.7554 - accuracy: 0.1914\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.8210 - accuracy: 0.1406\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.8898 - accuracy: 0.1602\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.4775 - accuracy: 0.1523\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.7440 - accuracy: 0.1797\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.5764 - accuracy: 0.1797\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.5615 - accuracy: 0.2070\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.8677 - accuracy: 0.1602\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.7791 - accuracy: 0.2031\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.4927 - accuracy: 0.1992\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.4710 - accuracy: 0.1797\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.4443 - accuracy: 0.2266\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3376 - accuracy: 0.1992\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.5445 - accuracy: 0.2188\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3396 - accuracy: 0.2305\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.5199 - accuracy: 0.1914\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.6209 - accuracy: 0.2188\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3714 - accuracy: 0.2227\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2935 - accuracy: 0.2109\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.1416 - accuracy: 0.2578\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.5079 - accuracy: 0.2031\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2716 - accuracy: 0.2500\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.4081 - accuracy: 0.2305\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.4055 - accuracy: 0.2070\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.3426 - accuracy: 0.1992\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3945 - accuracy: 0.2305\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.1942 - accuracy: 0.2148\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.5438 - accuracy: 0.2500\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3268 - accuracy: 0.1953\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2371 - accuracy: 0.2617\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.3849 - accuracy: 0.2305\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1892 - accuracy: 0.2539\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2075 - accuracy: 0.2305\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1932 - accuracy: 0.2852\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.3357 - accuracy: 0.2305\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1699 - accuracy: 0.2695\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2857 - accuracy: 0.2539\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 2.1938 - accuracy: 0.2227\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2282 - accuracy: 0.3164\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2342 - accuracy: 0.2617\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1813 - accuracy: 0.2852\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1801 - accuracy: 0.2891\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.3040 - accuracy: 0.2891\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0986 - accuracy: 0.3008\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.3282 - accuracy: 0.2969\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1960 - accuracy: 0.2695\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1305 - accuracy: 0.2734\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2737 - accuracy: 0.3047\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.0344 - accuracy: 0.3008\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1683 - accuracy: 0.2930\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2120 - accuracy: 0.2344\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1471 - accuracy: 0.2578\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2022 - accuracy: 0.2383\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.2194 - accuracy: 0.2812\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.1912 - accuracy: 0.2930\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.0333 - accuracy: 0.3359\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1876 - accuracy: 0.3008\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1126 - accuracy: 0.2852\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.1212 - accuracy: 0.2539\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1917 - accuracy: 0.3008\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1935 - accuracy: 0.2969\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1869 - accuracy: 0.2969\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0948 - accuracy: 0.2930\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1122 - accuracy: 0.2930\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0300 - accuracy: 0.2969\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.1930 - accuracy: 0.2656\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0525 - accuracy: 0.2969\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0630 - accuracy: 0.3125\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1213 - accuracy: 0.2656\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1453 - accuracy: 0.2539\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0840 - accuracy: 0.3398\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0184 - accuracy: 0.3398\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0730 - accuracy: 0.3047\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0514 - accuracy: 0.3125\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0323 - accuracy: 0.2812\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0101 - accuracy: 0.3008\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1627 - accuracy: 0.2891\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0526 - accuracy: 0.3242\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.0453 - accuracy: 0.3164\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1794 - accuracy: 0.3047\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1965 - accuracy: 0.2969\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.0589 - accuracy: 0.3203\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1725 - accuracy: 0.2578\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2111 - accuracy: 0.2852\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.9827 - accuracy: 0.3008\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0316 - accuracy: 0.3438\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.0378 - accuracy: 0.2852\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.9487 - accuracy: 0.3086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f2bfc280>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_12 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_12.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_12.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1155 - accuracy: 0.1719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1155338287353516, 0.171875]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 66.4934 - accuracy: 0.0742\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 3.6263 - accuracy: 0.1016\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.3825 - accuracy: 0.0820\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.3290 - accuracy: 0.1016\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3017 - accuracy: 0.0820\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3126 - accuracy: 0.1094\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3029 - accuracy: 0.0859\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.3026 - accuracy: 0.1172\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2967 - accuracy: 0.1055\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2875 - accuracy: 0.1055\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.3070 - accuracy: 0.0938\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.3197 - accuracy: 0.0820\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2975 - accuracy: 0.1367\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3092 - accuracy: 0.1289\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2770 - accuracy: 0.1172\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2814 - accuracy: 0.1094\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2673 - accuracy: 0.1562\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2782 - accuracy: 0.1172\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2700 - accuracy: 0.1016\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2337 - accuracy: 0.1133\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2609 - accuracy: 0.1484\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2884 - accuracy: 0.1523\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2897 - accuracy: 0.1172\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2848 - accuracy: 0.1289\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2910 - accuracy: 0.1484\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2849 - accuracy: 0.1289\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.2956 - accuracy: 0.1133\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2664 - accuracy: 0.1562\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 2.2676 - accuracy: 0.1562\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2605 - accuracy: 0.1562\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2716 - accuracy: 0.1211\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.3124 - accuracy: 0.1055\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2555 - accuracy: 0.1367\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2982 - accuracy: 0.1211\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.3073 - accuracy: 0.1211\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2742 - accuracy: 0.1484\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2365 - accuracy: 0.1250\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2247 - accuracy: 0.1602\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.3032 - accuracy: 0.1328\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2997 - accuracy: 0.1055\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2332 - accuracy: 0.1406\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.3005 - accuracy: 0.1641\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2728 - accuracy: 0.1328\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2549 - accuracy: 0.1328\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2655 - accuracy: 0.1367\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2678 - accuracy: 0.1641\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2729 - accuracy: 0.1406\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2701 - accuracy: 0.1406\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2678 - accuracy: 0.1328\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2807 - accuracy: 0.1406\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2500 - accuracy: 0.1719\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2590 - accuracy: 0.1602\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2419 - accuracy: 0.1641\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2717 - accuracy: 0.1641\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.2342 - accuracy: 0.1445\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2307 - accuracy: 0.1445\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2258 - accuracy: 0.1602\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2529 - accuracy: 0.1289\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2418 - accuracy: 0.1562\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2353 - accuracy: 0.1719\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2895 - accuracy: 0.1406\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2541 - accuracy: 0.1484\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 2.2259 - accuracy: 0.1445\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2167 - accuracy: 0.1758\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2388 - accuracy: 0.1680\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2152 - accuracy: 0.1523\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2602 - accuracy: 0.1562\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2867 - accuracy: 0.1367\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2554 - accuracy: 0.1719\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2745 - accuracy: 0.1055\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.2783 - accuracy: 0.1367\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2564 - accuracy: 0.1680\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2495 - accuracy: 0.1445\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2728 - accuracy: 0.1406\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2566 - accuracy: 0.1680\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2767 - accuracy: 0.1328\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2736 - accuracy: 0.1523\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2736 - accuracy: 0.1367\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2321 - accuracy: 0.1445\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.2403 - accuracy: 0.1875\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2754 - accuracy: 0.1367\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2801 - accuracy: 0.1406\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2493 - accuracy: 0.1406\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2759 - accuracy: 0.1055\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2797 - accuracy: 0.1562\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2358 - accuracy: 0.1641\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2546 - accuracy: 0.1172\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2390 - accuracy: 0.1758\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2778 - accuracy: 0.1602\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 2.2653 - accuracy: 0.1484\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.2484 - accuracy: 0.1758\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2604 - accuracy: 0.1406\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.2530 - accuracy: 0.1328\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.2650 - accuracy: 0.1406\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2359 - accuracy: 0.1719\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2443 - accuracy: 0.1172\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2404 - accuracy: 0.1641\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2472 - accuracy: 0.1406\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.2437 - accuracy: 0.1758\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 2.2597 - accuracy: 0.1172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x34b6d8cd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_13 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_13.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_13.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2528 - accuracy: 0.1094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.252798080444336, 0.109375]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_13.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 23ms/step - loss: 17.1859 - accuracy: 0.1367 - val_loss: 7.5361 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 7.3219 - accuracy: 0.0820 - val_loss: 7.0795 - val_accuracy: 0.0469 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.9548 - accuracy: 0.1211 - val_loss: 6.8261 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 6.7022 - accuracy: 0.1484 - val_loss: 6.5906 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.4862 - accuracy: 0.1211 - val_loss: 6.4014 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.3101 - accuracy: 0.1133 - val_loss: 6.2232 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.1255 - accuracy: 0.1133 - val_loss: 6.0521 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.9490 - accuracy: 0.1445 - val_loss: 5.9092 - val_accuracy: 0.1406 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.8062 - accuracy: 0.1133 - val_loss: 5.8928 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 5.6676 - accuracy: 0.1914 - val_loss: 5.6446 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.5925 - accuracy: 0.1094 - val_loss: 5.5272 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.4834 - accuracy: 0.1094 - val_loss: 5.4042 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 5.3447 - accuracy: 0.1641 - val_loss: 5.2937 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.2408 - accuracy: 0.1445 - val_loss: 5.1831 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 5.1591 - accuracy: 0.1758 - val_loss: 5.0996 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.0497 - accuracy: 0.1367 - val_loss: 4.9998 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.9351 - accuracy: 0.1758 - val_loss: 4.9147 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.8996 - accuracy: 0.1523 - val_loss: 4.8406 - val_accuracy: 0.0938 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.8006 - accuracy: 0.1602 - val_loss: 4.7657 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.6782 - accuracy: 0.2109 - val_loss: 4.6762 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.6583 - accuracy: 0.1602 - val_loss: 4.6571 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 4.5421 - accuracy: 0.2148 - val_loss: 4.5110 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.5121 - accuracy: 0.1016 - val_loss: 4.5093 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.4150 - accuracy: 0.1875 - val_loss: 4.4136 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.3482 - accuracy: 0.1680 - val_loss: 4.3690 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.3487 - accuracy: 0.1914 - val_loss: 4.3298 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.2562 - accuracy: 0.1953 - val_loss: 4.3197 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.2294 - accuracy: 0.1641 - val_loss: 4.1415 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.1503 - accuracy: 0.1953 - val_loss: 4.1488 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.1168 - accuracy: 0.1719 - val_loss: 4.1138 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.0804 - accuracy: 0.1602 - val_loss: 4.1083 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.0640 - accuracy: 0.1484 - val_loss: 4.0503 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.9808 - accuracy: 0.1758 - val_loss: 3.9733 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.9354 - accuracy: 0.1602 - val_loss: 3.8911 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.8206 - accuracy: 0.2031 - val_loss: 3.8713 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.8572 - accuracy: 0.1719 - val_loss: 3.8388 - val_accuracy: 0.0625 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.7885 - accuracy: 0.1523 - val_loss: 3.7727 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.7428 - accuracy: 0.1992 - val_loss: 3.7492 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.7244 - accuracy: 0.1602 - val_loss: 3.6972 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 3.6539 - accuracy: 0.1875 - val_loss: 3.5941 - val_accuracy: 0.2031 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.6152 - accuracy: 0.2344 - val_loss: 3.5629 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.5498 - accuracy: 0.2148 - val_loss: 3.5375 - val_accuracy: 0.2031 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.5634 - accuracy: 0.2539 - val_loss: 3.5219 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.5064 - accuracy: 0.2305 - val_loss: 3.5628 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.5349 - accuracy: 0.2109 - val_loss: 3.5326 - val_accuracy: 0.2344 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.4958 - accuracy: 0.2148 - val_loss: 3.4808 - val_accuracy: 0.2344 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.4734 - accuracy: 0.1836 - val_loss: 3.4646 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.4744 - accuracy: 0.2031 - val_loss: 3.4624 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.4096 - accuracy: 0.1953 - val_loss: 3.3041 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.2721 - accuracy: 0.2461 - val_loss: 3.2204 - val_accuracy: 0.2969 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.3356 - accuracy: 0.1797 - val_loss: 3.3677 - val_accuracy: 0.0781 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.2735 - accuracy: 0.1680 - val_loss: 3.3888 - val_accuracy: 0.1562 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.2621 - accuracy: 0.1680 - val_loss: 3.2225 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.2227 - accuracy: 0.2188 - val_loss: 3.1960 - val_accuracy: 0.1875 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.1462 - accuracy: 0.2266 - val_loss: 3.1931 - val_accuracy: 0.2188 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.1543 - accuracy: 0.2617 - val_loss: 3.1709 - val_accuracy: 0.2344 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 3.1553 - accuracy: 0.2383 - val_loss: 3.1566 - val_accuracy: 0.2656 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.1925 - accuracy: 0.2305 - val_loss: 3.1519 - val_accuracy: 0.2812 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.0625 - accuracy: 0.2695 - val_loss: 3.1464 - val_accuracy: 0.2344 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.0285 - accuracy: 0.2852 - val_loss: 3.1329 - val_accuracy: 0.2656 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.0919 - accuracy: 0.2734 - val_loss: 3.0783 - val_accuracy: 0.2344 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.1520 - accuracy: 0.2539 - val_loss: 3.0701 - val_accuracy: 0.2500 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.0533 - accuracy: 0.2891 - val_loss: 3.0162 - val_accuracy: 0.2969 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.9958 - accuracy: 0.2852 - val_loss: 3.0094 - val_accuracy: 0.3906 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.9897 - accuracy: 0.3008 - val_loss: 2.9651 - val_accuracy: 0.2812 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.9881 - accuracy: 0.3203 - val_loss: 2.8913 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 2.8761 - accuracy: 0.3516 - val_loss: 2.8693 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.9150 - accuracy: 0.3281 - val_loss: 2.9060 - val_accuracy: 0.3594 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.9323 - accuracy: 0.3125 - val_loss: 2.9109 - val_accuracy: 0.4062 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.9072 - accuracy: 0.3047 - val_loss: 2.8907 - val_accuracy: 0.4219 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8645 - accuracy: 0.3516 - val_loss: 2.8517 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8784 - accuracy: 0.2812 - val_loss: 2.8417 - val_accuracy: 0.4219 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8954 - accuracy: 0.3203 - val_loss: 2.8478 - val_accuracy: 0.4531 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8949 - accuracy: 0.3281 - val_loss: 2.8356 - val_accuracy: 0.4531 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.7882 - accuracy: 0.3672 - val_loss: 2.8314 - val_accuracy: 0.4531 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.8489 - accuracy: 0.3281 - val_loss: 2.8331 - val_accuracy: 0.4375 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.7710 - accuracy: 0.3906 - val_loss: 2.8388 - val_accuracy: 0.4219 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8271 - accuracy: 0.3203 - val_loss: 2.8371 - val_accuracy: 0.4219 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8911 - accuracy: 0.3516 - val_loss: 2.8360 - val_accuracy: 0.4375 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8248 - accuracy: 0.3320 - val_loss: 2.8353 - val_accuracy: 0.4375 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_14 = Sequential()\n",
    "model_14.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_14.add(MaxPooling2D((2, 2)))\n",
    "model_14.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_14.add(MaxPooling2D((2, 2)))\n",
    "model_14.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_14.add(MaxPooling2D((2, 2)))\n",
    "model_14.add(Flatten())\n",
    "model_14.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_14.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_14.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_14.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_14.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_14.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 2.8314 - accuracy: 0.4531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8313820362091064, 0.453125]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_14.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 3.3672 - accuracy: 0.1094 - val_loss: 6.9599 - val_accuracy: 0.0938\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.3915 - accuracy: 0.1211 - val_loss: 7.9883 - val_accuracy: 0.1094\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.8884 - accuracy: 0.1797 - val_loss: 5.3758 - val_accuracy: 0.1406\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.0495 - accuracy: 0.1641 - val_loss: 3.2933 - val_accuracy: 0.1250\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.8453 - accuracy: 0.1719 - val_loss: 5.7002 - val_accuracy: 0.0938\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.6154 - accuracy: 0.1523 - val_loss: 3.5932 - val_accuracy: 0.1406\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.8588 - accuracy: 0.1875 - val_loss: 3.2351 - val_accuracy: 0.0938\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 2.6404 - accuracy: 0.2031 - val_loss: 3.8457 - val_accuracy: 0.1094\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.5853 - accuracy: 0.2227 - val_loss: 2.6870 - val_accuracy: 0.0469\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.7300 - accuracy: 0.2344 - val_loss: 2.3742 - val_accuracy: 0.1562\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.4818 - accuracy: 0.2305 - val_loss: 2.4252 - val_accuracy: 0.2344\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.3565 - accuracy: 0.2461 - val_loss: 2.4040 - val_accuracy: 0.1719\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.3337 - accuracy: 0.2812 - val_loss: 2.3833 - val_accuracy: 0.1562\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.3630 - accuracy: 0.2734 - val_loss: 2.4662 - val_accuracy: 0.1250\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.1090 - accuracy: 0.2539 - val_loss: 2.3680 - val_accuracy: 0.1094\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.0624 - accuracy: 0.3008 - val_loss: 2.3366 - val_accuracy: 0.2188\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.1148 - accuracy: 0.2891 - val_loss: 2.2844 - val_accuracy: 0.1875\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.0834 - accuracy: 0.3203 - val_loss: 2.0973 - val_accuracy: 0.2188\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 1.8857 - accuracy: 0.3672 - val_loss: 2.4130 - val_accuracy: 0.2344\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.0154 - accuracy: 0.3242 - val_loss: 2.3445 - val_accuracy: 0.2969\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.1514 - accuracy: 0.3125 - val_loss: 2.0231 - val_accuracy: 0.2812\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.0266 - accuracy: 0.3320 - val_loss: 2.6650 - val_accuracy: 0.1719\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.9270 - accuracy: 0.3398 - val_loss: 1.9763 - val_accuracy: 0.2656\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 1.9142 - accuracy: 0.3398 - val_loss: 2.0841 - val_accuracy: 0.2969\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.0314 - accuracy: 0.3281 - val_loss: 2.0010 - val_accuracy: 0.2812\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.8747 - accuracy: 0.3359 - val_loss: 1.9451 - val_accuracy: 0.3750\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.1143 - accuracy: 0.3164 - val_loss: 2.0411 - val_accuracy: 0.3750\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 1.8032 - accuracy: 0.3906 - val_loss: 1.9688 - val_accuracy: 0.2969\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 1.8330 - accuracy: 0.3672 - val_loss: 1.9127 - val_accuracy: 0.3125\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 1.8516 - accuracy: 0.3867 - val_loss: 1.9834 - val_accuracy: 0.3594\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 1.9369 - accuracy: 0.3438 - val_loss: 2.0498 - val_accuracy: 0.3125\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 1.8199 - accuracy: 0.3711 - val_loss: 2.2864 - val_accuracy: 0.2188\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 1.7541 - accuracy: 0.4062 - val_loss: 2.7345 - val_accuracy: 0.1719\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.8342 - accuracy: 0.3672 - val_loss: 2.1681 - val_accuracy: 0.2812\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 1.7536 - accuracy: 0.3750 - val_loss: 2.3114 - val_accuracy: 0.2344\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 1.6194 - accuracy: 0.4180 - val_loss: 2.1009 - val_accuracy: 0.2812\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.7853 - accuracy: 0.4102 - val_loss: 1.9376 - val_accuracy: 0.3438\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 1.7093 - accuracy: 0.3789 - val_loss: 2.0338 - val_accuracy: 0.3594\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 1.6765 - accuracy: 0.4414 - val_loss: 2.1962 - val_accuracy: 0.2969\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_15 = Sequential()\n",
    "model_15.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_15.add(MaxPooling2D((2, 2)))\n",
    "model_15.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_15.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_15.add(MaxPooling2D((2, 2)))\n",
    "model_15.add(BatchNormalization())\n",
    "model_15.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_15.add(MaxPooling2D((2, 2)))\n",
    "model_15.add(BatchNormalization())\n",
    "model_15.add(Flatten())\n",
    "model_15.add(Dense(256))\n",
    "model_15.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_15.add(Dropout(0.5))\n",
    "model_15.add(Dense(128))\n",
    "model_15.add(LeakyReLU(alpha=0.1))\n",
    "model_15.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_15.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_15.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 1.9127 - accuracy: 0.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9126980304718018, 0.3125]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_15.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video + Getty - 5 Classes (video_cropped_faces_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_faces_directory = \"../data_processing/raw_data/video_cropped_faces_2\"\n",
    "\n",
    "y, X = encode(cropped_faces_directory)\n",
    "y_cat = to_cat(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 4s 246ms/step - loss: 1.3650 - accuracy: 0.5948 - val_loss: 2921.5955 - val_accuracy: 0.1034\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.7080 - accuracy: 0.7500 - val_loss: 1087.4312 - val_accuracy: 0.1034\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.4975 - accuracy: 0.8362 - val_loss: 77.4192 - val_accuracy: 0.0690\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.3822 - accuracy: 0.8707 - val_loss: 34.5097 - val_accuracy: 0.1034\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.4215 - accuracy: 0.8707 - val_loss: 168.5349 - val_accuracy: 0.0345\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.3427 - accuracy: 0.8966 - val_loss: 315.2168 - val_accuracy: 0.1724\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.3287 - accuracy: 0.8793 - val_loss: 71.7688 - val_accuracy: 0.1724\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 20.9034 - accuracy: 0.1892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.903432846069336, 0.18918919563293457]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new classification head\n",
    "layer = resnet.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(layer)\n",
    "\n",
    "model_16 = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_16.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model_16.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=16,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es]\n",
    "         )\n",
    "\n",
    "model_16.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1130.9338 - accuracy: 0.1310\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 715.9363 - accuracy: 0.1862\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 171.3322 - accuracy: 0.1931\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 122.4031 - accuracy: 0.2276\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82.0305 - accuracy: 0.2276\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36.9867 - accuracy: 0.2690\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.4112 - accuracy: 0.3586\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.5632 - accuracy: 0.2138\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.9128 - accuracy: 0.2207\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8153 - accuracy: 0.2138\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8936 - accuracy: 0.2069\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5806 - accuracy: 0.3241\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.1676 - accuracy: 0.3586\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.8038 - accuracy: 0.3034\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.8355 - accuracy: 0.3103\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.4632 - accuracy: 0.3931\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5484 - accuracy: 0.3241\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2002 - accuracy: 0.2759\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.9186 - accuracy: 0.3103\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.0908 - accuracy: 0.2759\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9474 - accuracy: 0.4207\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8343 - accuracy: 0.3862\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9709 - accuracy: 0.3379\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.3532 - accuracy: 0.3724\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.2384 - accuracy: 0.3241\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0585 - accuracy: 0.3862\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.0487 - accuracy: 0.3793\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2355 - accuracy: 0.3310\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6949 - accuracy: 0.3931\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7384 - accuracy: 0.3517\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9395 - accuracy: 0.3103\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7717 - accuracy: 0.3517\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8732 - accuracy: 0.3241\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7559 - accuracy: 0.3517\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5633 - accuracy: 0.3862\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7518 - accuracy: 0.3241\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.7444 - accuracy: 0.3103\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6145 - accuracy: 0.4069\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5817 - accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5830 - accuracy: 0.3793\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6090 - accuracy: 0.3586\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7307 - accuracy: 0.4069\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7127 - accuracy: 0.3517\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4805 - accuracy: 0.4207\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8389 - accuracy: 0.3793\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6587 - accuracy: 0.3379\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4970 - accuracy: 0.4207\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8288 - accuracy: 0.3172\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8107 - accuracy: 0.3517\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8407 - accuracy: 0.3655\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9636 - accuracy: 0.3034\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9021 - accuracy: 0.3448\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8785 - accuracy: 0.2897\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6157 - accuracy: 0.4345\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6108 - accuracy: 0.4345\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6705 - accuracy: 0.3448\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6858 - accuracy: 0.3931\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5483 - accuracy: 0.3793\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5807 - accuracy: 0.3793\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6702 - accuracy: 0.3724\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5289 - accuracy: 0.4207\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6570 - accuracy: 0.3724\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7318 - accuracy: 0.3517\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8648 - accuracy: 0.3448\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6923 - accuracy: 0.3448\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5041 - accuracy: 0.4000\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6138 - accuracy: 0.3655\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5321 - accuracy: 0.4414\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5703 - accuracy: 0.4000\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6605 - accuracy: 0.3655\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6237 - accuracy: 0.3931\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5725 - accuracy: 0.3931\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4866 - accuracy: 0.3586\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5151 - accuracy: 0.4069\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4354 - accuracy: 0.4276\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6297 - accuracy: 0.3655\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7066 - accuracy: 0.4069\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6204 - accuracy: 0.3724\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5584 - accuracy: 0.4621\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5955 - accuracy: 0.3724\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4506 - accuracy: 0.4483\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6404 - accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5778 - accuracy: 0.4000\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4854 - accuracy: 0.4207\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4846 - accuracy: 0.4069\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4650 - accuracy: 0.4621\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5577 - accuracy: 0.3655\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3777 - accuracy: 0.4276\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4365 - accuracy: 0.4345\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4627 - accuracy: 0.4000\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4738 - accuracy: 0.4276\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4133 - accuracy: 0.4345\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5142 - accuracy: 0.4276\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4297 - accuracy: 0.4276\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4174 - accuracy: 0.4000\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4300 - accuracy: 0.4069\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5258 - accuracy: 0.4276\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4552 - accuracy: 0.4207\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5192 - accuracy: 0.4069\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2518 - accuracy: 0.4690\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1809 - accuracy: 0.3784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.180905818939209, 0.37837839126586914]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add augmentation layers directly within the model\n",
    "augmented = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "augmented = MaxPooling2D((2, 2))(augmented)\n",
    "# Add more layers or augmentation techniques as needed\n",
    "\n",
    "# Rest of your model architecture\n",
    "# Example:\n",
    "augmented = Flatten()(augmented)\n",
    "augmented = Dense(128, activation='relu')(augmented)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(augmented)\n",
    "\n",
    "\n",
    "model_17 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_17.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "es = EarlyStopping(patience=3,\n",
    "                   restore_best_weights=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Rotate images by a wider range of degrees\n",
    "    width_shift_range=0.3,   # Shift images horizontally by a larger fraction of total width\n",
    "    height_shift_range=0.3,  # Shift images vertically by a larger fraction of total height\n",
    "    shear_range=0.3,         # Apply a larger shear-based transformation\n",
    "    zoom_range=0.3,          # Zoom in or out of images more aggressively\n",
    "    horizontal_flip=True,    # Flip images horizontally\n",
    "    vertical_flip=True,      # Flip images vertically\n",
    "    fill_mode='nearest'      # Fill points outside the boundaries using the nearest available value\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_17.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n",
    "\n",
    "model_17.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 104.2619 - accuracy: 0.2069\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16.2475 - accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.9138 - accuracy: 0.1655\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.7119 - accuracy: 0.2690\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6351 - accuracy: 0.2138\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6743 - accuracy: 0.1793\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6898 - accuracy: 0.2414\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6279 - accuracy: 0.2138\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5850 - accuracy: 0.2483\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6030 - accuracy: 0.1862\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5993 - accuracy: 0.2414\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5859 - accuracy: 0.2552\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5942 - accuracy: 0.2345\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5803 - accuracy: 0.2621\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5841 - accuracy: 0.2966\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5857 - accuracy: 0.2483\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6349 - accuracy: 0.2483\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5845 - accuracy: 0.2759\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6067 - accuracy: 0.2828\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5382 - accuracy: 0.2690\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5494 - accuracy: 0.2414\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5898 - accuracy: 0.3034\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5196 - accuracy: 0.2897\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5433 - accuracy: 0.2552\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5249 - accuracy: 0.3103\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5478 - accuracy: 0.2138\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5027 - accuracy: 0.3379\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5834 - accuracy: 0.2759\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5390 - accuracy: 0.3103\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5602 - accuracy: 0.2828\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5721 - accuracy: 0.2621\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5825 - accuracy: 0.2759\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5790 - accuracy: 0.2897\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5500 - accuracy: 0.3034\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5733 - accuracy: 0.2759\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5204 - accuracy: 0.2828\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5186 - accuracy: 0.2621\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5813 - accuracy: 0.3172\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5616 - accuracy: 0.2966\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5986 - accuracy: 0.3586\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5169 - accuracy: 0.2828\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5402 - accuracy: 0.2483\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5469 - accuracy: 0.3034\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5075 - accuracy: 0.2897\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5500 - accuracy: 0.2759\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5654 - accuracy: 0.2759\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5391 - accuracy: 0.2828\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5518 - accuracy: 0.2828\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5082 - accuracy: 0.2621\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5180 - accuracy: 0.3034\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5738 - accuracy: 0.3379\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5558 - accuracy: 0.3517\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5378 - accuracy: 0.2966\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5576 - accuracy: 0.2483\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5549 - accuracy: 0.2345\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5539 - accuracy: 0.2552\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5436 - accuracy: 0.2552\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5273 - accuracy: 0.2897\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6007 - accuracy: 0.2414\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5258 - accuracy: 0.2621\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5558 - accuracy: 0.2690\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5051 - accuracy: 0.2759\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6070 - accuracy: 0.2759\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5378 - accuracy: 0.2621\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5496 - accuracy: 0.2966\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4806 - accuracy: 0.3586\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5581 - accuracy: 0.2897\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5864 - accuracy: 0.3034\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5352 - accuracy: 0.2483\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5246 - accuracy: 0.3379\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5617 - accuracy: 0.2552\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5622 - accuracy: 0.2414\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5314 - accuracy: 0.2759\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5411 - accuracy: 0.2966\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4726 - accuracy: 0.3103\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5731 - accuracy: 0.2966\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6050 - accuracy: 0.3034\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5286 - accuracy: 0.3241\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5632 - accuracy: 0.2759\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5373 - accuracy: 0.2828\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5231 - accuracy: 0.2966\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5141 - accuracy: 0.3103\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5022 - accuracy: 0.3379\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4863 - accuracy: 0.3448\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.7230 - accuracy: 0.2690\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5830 - accuracy: 0.3034\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5918 - accuracy: 0.2621\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5420 - accuracy: 0.2897\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5061 - accuracy: 0.3310\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5335 - accuracy: 0.3034\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5148 - accuracy: 0.3103\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5357 - accuracy: 0.2828\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4864 - accuracy: 0.2966\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4942 - accuracy: 0.3103\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5136 - accuracy: 0.3310\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4691 - accuracy: 0.3310\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5407 - accuracy: 0.3034\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5132 - accuracy: 0.2966\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5296 - accuracy: 0.2690\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5172 - accuracy: 0.3103\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5141 - accuracy: 0.2703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5140997171401978, 0.2702702581882477]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the input shape for your images\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Define a Sequential model or Functional API model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add convolutional layers with pooling\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "# Flatten the output before feeding into dense layers\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Add dense layers with dropout for regularization\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1 = Dropout(0.5)(dense1)  # Dropout layer for regularization\n",
    "\n",
    "dense2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)  # Dropout layer for regularization\n",
    "\n",
    "# Output layer with softmax activation for multi-class classification\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model_18 = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model_18.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator with multiple augmentation techniques\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],  # Vary brightness\n",
    "    channel_shift_range=50,        # Vary channel shifts\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the ImageDataGenerator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Example of using the ImageDataGenerator during model training\n",
    "model_18.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100)\n",
    "\n",
    "model_18.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yassinebouaine/.pyenv/versions/3.10.6/envs/dynamic-players-insights/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 29ms/step - loss: 40.9099 - accuracy: 0.2138 - val_loss: 14.8091 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 9.4812 - accuracy: 0.2000 - val_loss: 5.8835 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.8014 - accuracy: 0.1793 - val_loss: 5.4768 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 5.4083 - accuracy: 0.2621 - val_loss: 5.3563 - val_accuracy: 0.1351 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.2932 - accuracy: 0.1931 - val_loss: 5.2414 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 5.2058 - accuracy: 0.2276 - val_loss: 5.1465 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 5.1006 - accuracy: 0.2414 - val_loss: 5.0622 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 5.0159 - accuracy: 0.2345 - val_loss: 5.0087 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.9594 - accuracy: 0.2690 - val_loss: 4.8974 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.8692 - accuracy: 0.2690 - val_loss: 4.8232 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.8245 - accuracy: 0.2069 - val_loss: 4.8720 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.7538 - accuracy: 0.2276 - val_loss: 4.7256 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.7794 - accuracy: 0.2483 - val_loss: 4.6706 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.6556 - accuracy: 0.2276 - val_loss: 4.6475 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.6087 - accuracy: 0.2621 - val_loss: 4.5693 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.5447 - accuracy: 0.3034 - val_loss: 4.4679 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.4897 - accuracy: 0.2828 - val_loss: 4.4367 - val_accuracy: 0.2703 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.4274 - accuracy: 0.3310 - val_loss: 4.4965 - val_accuracy: 0.0811 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.5011 - accuracy: 0.2000 - val_loss: 4.4826 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.4621 - accuracy: 0.2897 - val_loss: 4.4231 - val_accuracy: 0.1622 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.3989 - accuracy: 0.2483 - val_loss: 4.3716 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.3482 - accuracy: 0.2897 - val_loss: 4.3428 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.3910 - accuracy: 0.2138 - val_loss: 4.2808 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.2759 - accuracy: 0.2345 - val_loss: 4.6815 - val_accuracy: 0.1892 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.2587 - accuracy: 0.2828 - val_loss: 4.2508 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.2177 - accuracy: 0.2276 - val_loss: 4.2066 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.1950 - accuracy: 0.2345 - val_loss: 4.1276 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.1706 - accuracy: 0.2552 - val_loss: 4.0922 - val_accuracy: 0.4324 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.1286 - accuracy: 0.2138 - val_loss: 4.0411 - val_accuracy: 0.3784 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.0274 - accuracy: 0.2621 - val_loss: 3.9883 - val_accuracy: 0.2162 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 3.9576 - accuracy: 0.2759 - val_loss: 3.7902 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.0216 - accuracy: 0.2483 - val_loss: 3.9903 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 3.9813 - accuracy: 0.2345 - val_loss: 3.9404 - val_accuracy: 0.2973 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 3.9152 - accuracy: 0.3241 - val_loss: 4.0031 - val_accuracy: 0.2432 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 4.0454 - accuracy: 0.2207 - val_loss: 3.9700 - val_accuracy: 0.1892 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 3.9788 - accuracy: 0.2483 - val_loss: 3.9594 - val_accuracy: 0.2162 - lr: 1.0000e-04\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.7902 - accuracy: 0.4865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.790188789367676, 0.4864864945411682]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model_19 = Sequential()\n",
    "model_19.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_19.add(MaxPooling2D((2, 2)))\n",
    "model_19.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_19.add(MaxPooling2D((2, 2)))\n",
    "model_19.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_19.add(MaxPooling2D((2, 2)))\n",
    "model_19.add(Flatten())\n",
    "model_19.add(Dense(256, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_19.add(Dropout(0.5))  # Adding Dropout layer\n",
    "model_19.add(Dense(128, activation='relu', kernel_regularizer='l2'))  # Adding L2 regularization\n",
    "model_19.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Using Adam optimizer with a reduced learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_19.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding more callbacks, e.g., ReduceLROnPlateau\n",
    "callbacks = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             ReduceLROnPlateau(factor=0.1, patience=3)]\n",
    "\n",
    "# Fit the model with increased complexity and callbacks\n",
    "history = model_19.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "model_19.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "3/3 [==============================] - 1s 120ms/step - loss: 3.0575 - accuracy: 0.1862 - val_loss: 6.6435 - val_accuracy: 0.2162\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2.4267 - accuracy: 0.2276 - val_loss: 3.7690 - val_accuracy: 0.1622\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 2.7360 - accuracy: 0.1931 - val_loss: 7.7884 - val_accuracy: 0.1622\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.1700 - accuracy: 0.3241 - val_loss: 7.9802 - val_accuracy: 0.1351\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.6567 - accuracy: 0.2552 - val_loss: 6.1181 - val_accuracy: 0.1622\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.3267 - accuracy: 0.2828 - val_loss: 6.1946 - val_accuracy: 0.1351\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 2.6628 - accuracy: 0.2759 - val_loss: 4.7975 - val_accuracy: 0.1622\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.5704 - accuracy: 0.2690 - val_loss: 5.3121 - val_accuracy: 0.1892\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.3795 - accuracy: 0.2483 - val_loss: 5.0396 - val_accuracy: 0.1892\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 2.5113 - accuracy: 0.2828 - val_loss: 3.2452 - val_accuracy: 0.1892\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 2.6014 - accuracy: 0.3310 - val_loss: 4.6715 - val_accuracy: 0.1892\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2.5308 - accuracy: 0.2621 - val_loss: 4.0100 - val_accuracy: 0.2162\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 2.1228 - accuracy: 0.2966 - val_loss: 3.1419 - val_accuracy: 0.2432\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.9438 - accuracy: 0.3517 - val_loss: 2.8452 - val_accuracy: 0.2432\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 2.0831 - accuracy: 0.2483 - val_loss: 1.8347 - val_accuracy: 0.2973\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 1.8936 - accuracy: 0.3724 - val_loss: 1.4825 - val_accuracy: 0.5135\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.7531 - accuracy: 0.3655 - val_loss: 1.3922 - val_accuracy: 0.4595\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.7121 - accuracy: 0.3793 - val_loss: 1.3636 - val_accuracy: 0.4324\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 1.7896 - accuracy: 0.3931 - val_loss: 2.1533 - val_accuracy: 0.3243\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.0060 - accuracy: 0.3862 - val_loss: 2.7971 - val_accuracy: 0.3243\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.0807 - accuracy: 0.3517 - val_loss: 2.7415 - val_accuracy: 0.3784\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.8346 - accuracy: 0.3862 - val_loss: 2.3054 - val_accuracy: 0.3784\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.8398 - accuracy: 0.3172 - val_loss: 1.8505 - val_accuracy: 0.4054\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.8656 - accuracy: 0.3310 - val_loss: 1.5717 - val_accuracy: 0.3784\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.6563 - accuracy: 0.4207 - val_loss: 1.5628 - val_accuracy: 0.2973\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1.4554 - accuracy: 0.3931 - val_loss: 1.7877 - val_accuracy: 0.2703\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 1.5508 - accuracy: 0.4345 - val_loss: 1.7325 - val_accuracy: 0.2703\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.5516 - accuracy: 0.4621 - val_loss: 1.6353 - val_accuracy: 0.2973\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3636 - accuracy: 0.4324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3636188507080078, 0.4324324429035187]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "model_20 = Sequential()\n",
    "model_20.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_20.add(MaxPooling2D((2, 2)))\n",
    "model_20.add(BatchNormalization())  # Add BatchNormalization after each Conv layer\n",
    "model_20.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_20.add(MaxPooling2D((2, 2)))\n",
    "model_20.add(BatchNormalization())\n",
    "model_20.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_20.add(MaxPooling2D((2, 2)))\n",
    "model_20.add(BatchNormalization())\n",
    "model_20.add(Flatten())\n",
    "model_20.add(Dense(256))\n",
    "model_20.add(LeakyReLU(alpha=0.1))  # LeakyReLU activation\n",
    "model_20.add(Dropout(0.5))\n",
    "model_20.add(Dense(128))\n",
    "model_20.add(LeakyReLU(alpha=0.1))\n",
    "model_20.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_20.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model with adjusted architecture\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model_20.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=150,  # Train for more epochs\n",
    "                    callbacks=es,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "model_20.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import face_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def crop_video(input_directory, output_directory) :\n",
    "#      # Create the output directory if it doesn't exist\n",
    "#     if not os.path.exists(output_directory):\n",
    "#         os.makedirs(output_directory)\n",
    "\n",
    "#     for filename in os.listdir(input_directory):\n",
    "#         if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "#             file_path = os.path.join(input_directory, filename)\n",
    "\n",
    "#             # Load the image using face_recognition library\n",
    "#             image = face_recognition.load_image_file(file_path)\n",
    "#             face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "#             # Check if a face is detected\n",
    "#             if len(face_locations) > 0:\n",
    "#                 # Crop and save each face detected\n",
    "#                 for idx, face_location in enumerate(face_locations):\n",
    "#                     top, right, bottom, left = face_location\n",
    "#                     face_image = image[top:bottom, left:right]\n",
    "#                     pil_image = Image.fromarray(face_image)\n",
    "#                     cropped_file_name = f\"{os.path.splitext(filename)[0]}_face_{idx + 1}.jpg\"\n",
    "#                     cropped_file_path = os.path.join(output_directory, cropped_file_name)\n",
    "#                     pil_image.save(cropped_file_path)\n",
    "#                     print(f\"Face cropped and saved: {cropped_file_name}\")\n",
    "#             else:\n",
    "#                 print(f\"No face detected in {filename}, skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import face_recognition\n",
    "# from PIL import Image\n",
    "\n",
    "# def save_frames_with_face(video_path, dir_path, basename, ext='jpg', frames_per_second=1):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#     if not cap.isOpened():\n",
    "#         return\n",
    "\n",
    "#     os.makedirs(dir_path, exist_ok=True)\n",
    "#     base_path = os.path.join(dir_path, basename)\n",
    "\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     frame_count = 0\n",
    "\n",
    "#     frame_interval = int(fps / frames_per_second) if frames_per_second > 0 else 1\n",
    "\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if ret:\n",
    "#             if frame_count % frame_interval == 0:\n",
    "#                 # Convert frame to RGB for face recognition library\n",
    "#                 frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#                 # Detect face locations in the frame\n",
    "#                 face_locations = face_recognition.face_locations(frame_rgb)\n",
    "\n",
    "#                 if len(face_locations) > 0:\n",
    "#                     # Extract the first face detected (you can modify this logic)\n",
    "#                     top, right, bottom, left = face_locations[0]\n",
    "#                     face_image = frame[top:bottom, left:right]  # Crop the face\n",
    "#                     pil_image = Image.fromarray(face_image)\n",
    "\n",
    "#                     # Save the frame with the detected face\n",
    "#                     frame_path = f\"{base_path}_frame_{frame_count}_cropped_face.{ext}\"\n",
    "#                     pil_image.save(frame_path)\n",
    "#                     print(f\"Face detected and saved: {frame_path}\")\n",
    "\n",
    "#             frame_count += 1\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = \"/Users/yassinebouaine/Downloads/demo_1.mov\"\n",
    "# dir_path = \"../data_processing/raw_data/prediction\"\n",
    "# basename = \"prediction\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped_image = save_frames_with_face(video_path, dir_path, basename, ext='jpg', frames_per_second=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new, X_new = encode(\"../data_processing/raw_data/prediction/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05658385, 0.05945316, 0.14116952, 0.00836595, 0.00451716,\n",
       "        0.00508426, 0.00423702, 0.05495046, 0.07961128, 0.1930185 ,\n",
       "        0.3930089 ]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model_9.predict(X_new)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_index = np.argmax(pred)\n",
    "predicted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label = y_cat[predicted_index]\n",
    "predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'benzema'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_name = y[np.where((y_cat == predicted_label).all(axis=1))[0][0]]\n",
    "player_name\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
